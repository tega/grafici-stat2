%% LyX 1.6.5 created this file.  For more info, see http://www.lyx.org/.
%% Do not edit unless you really know what you are doing.
\documentclass[12pt,a4paper,italian]{report}
\usepackage[T1]{fontenc}
\usepackage[latin9]{inputenc}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{esint}

\makeatletter

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% LyX specific LaTeX commands.
%% Because html converters don't know tabularnewline
\providecommand{\tabularnewline}{\\}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% User specified LaTeX commands.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{amsfonts}\usepackage{amsthm}\usepackage{multicol}

\setcounter{MaxMatrixCols}{10}

\newcounter{ese}\newcounter{esr}\newcounter{def}\newcounter{domand}\theoremstyle{remark}\newcounter{theor}\newcounter{theorem}\newtheorem{esempio}[ese]{Esempio}\newtheorem{esercizio}[esr]{Esercizio}\newtheorem{definizione}[def]{Definizione}\newtheorem{remark}{Osservazione}\newtheorem{theorem}[theor]{Teorema}\newtheorem{domanda}[domand]{Domanda}



\makeatother

\usepackage{babel}



\makeatother

\usepackage{babel}

\begin{document}

\title{Statistica II\\
 Appunti del corso}


\author{Claudio Ortelli}


\date{Semestre Autunnale\\
 2010}

\maketitle
\tableofcontents{}


\chapter{Introduzione}


\section{Ricapitolazione}

Nel corso introduttivo di Statistica I sono stati trattati i concetti
fondamentali dell'analisi statistica e della teoria della probabilità.
In particolare avete visto


\subsubsection{Capitolo 1: introduzione}
\begin{enumerate}
\item Popolazione di riferimento di un'analisi statistica. 
\item Il campione. 
\end{enumerate}

\subsubsection{Capitolo 2: elementi di statistica descrittiva}
\begin{enumerate}
\item Le distribuzioni di frequenze (assolute o relative), istogrammi. 
\end{enumerate}

\subsubsection{Capitolo 3: misure empiriche di centralità e variabilità}
\begin{enumerate}
\item Indicatori di centralità (moda, media e mediana)\ e variabilità (range,
intervallo interquartile, deviazione standard). Regole di sommatoria
e relativa notazione.\[
\overline{x}\text{, }\sum_{i\text{ pari}}x_{i}\text{, }S^{2}=\frac{1}{n-1}\sum_{i=1}^{n}\left(x_{i}-\overline{x}\right)^{2}\]
 
\end{enumerate}

\subsubsection{Capitolo 4: Elementi di probabilità I}
\begin{enumerate}
\item Spazio campionario $\Omega$: insieme di tutti gli esiti di un esperimento
statistico. Evento $E\subset\Omega$: un particolare sottoinsieme
di $\Omega$. $E^{c}$: il complemento dell'evento $E$. Prime regole
di calcolo:\[
P(A)+P(A^{c})=1.\]
 
\end{enumerate}

\subsubsection{Capitolo 5: Elementi di probabilità II}
\begin{enumerate}
\item Intersezione di eventi.\ $A\cap B$: l'insieme degli esiti dell'esperimento
che appartengono sia all'evento $A$ che all'evento $B$. 
\item Eventi indipendenti: $A$ e $B$ sono indipendenti se vale la seguente
condizione\[
P(A\cap B)=P(A)P(B).\]

\item Probabilità condizionata \[
P(B\mid A)=\frac{P(A\cap B)}{P(A)}.\]

\item Unione di eventi. $A\cup B$: l'insieme degli esiti dell'esperimento
che appartengono all'evento $A$ o all'evento $B$ o ad entrambi. 
\item Eventi mutualmente esclusivi. $A$ e $B$ sono mutualmente esclusivi
se non hanno esiti in comune, ovvero se $A\cap B=\emptyset$. 
\item Probabilità di unioni di eventi $A$ e $B$ mutualmente esclusivi:\[
P(A\cup B)=P(A)+P(B)\]

\item Probabilità di unioni di eventi:\[
P(A\cup B)=P(A)+P(B)-P(A\cap B)\]

\item Diagrammi ad albero per la rappresentazione dei possibili esiti di
un esperimento e per il calcolo delle probabilità corrispondenti. 
\item Teorema di Bayes 
\end{enumerate}

\subsubsection{Capitolo 6: Introduzione alle variabili aleatorie}
\begin{enumerate}
\item Esperimento statistico: procedimento di osservazione di un dato fenomeno.
Variabile aleatoria ($V.A.$) $X$. Definizione di variabili aleatorie
discrete e continue. Distribuzioni e funzioni di probabilità. 
\item Valore atteso e varianza di una variabile $V.A$ discreta $X$:\begin{eqnarray*}
\mu & = & \sum_{i=1}^{n}x_{i}p(x_{i})\\
\sigma^{2} & = & \sum_{i=1}^{n}\left(x_{i}-\mu\right)^{2}p(x_{i})\end{eqnarray*}
 dove $p$ è la funzione di probabilità di $X$ e $x_{1},\ldots,x_{n}$
sono le possibili osservazioni di $X$. 
\item Regole di calcolo:\begin{eqnarray*}
\mu_{X+bY} & = & \mu_{X}+b\mu_{Y}\\
\sigma_{a+bX}^{2} & = & b\sigma_{X}^{2}\\
\sigma_{X}^{2} & = & \mu_{X^{2}}+\left(\mu_{X}\right)^{2}\end{eqnarray*}

\item Distribuzione di Bernoulli e distribuzione uniforme. 
\end{enumerate}

\subsubsection{Capitolo 7: alcune variabili aleatorie discrete}
\begin{enumerate}
\item Tecniche combinatorie:\ fattoriali, permutazioni e combinazioni. 
\item Esperimenti binomiali e distribuzioni binomiali. Valore atteso e varianza
di distribuzioni binomiali. 
\item Esperimenti e distribuzioni di Poisson. Valore atteso e varianza di
distribuzioni di Poisson. 
\end{enumerate}

\subsubsection{Capitolo 8: variabili aleatorie continue I}
\begin{enumerate}
\item Variabili aleatorie continue e funzione di densità. 
\item Distribuzione uniforme e triangolare. 
\end{enumerate}

\subsubsection{Capitolo 9: variabili aleatorie continue II}
\begin{enumerate}
\item Densità di una distribuzione normale. 
\item Valore atteso e varianza di distribuzioni normali. 
\item Aree e probabilità di densità normali. 
\end{enumerate}

\subsubsection{Capitolo 10: variabili aleatorie continue III}
\begin{enumerate}
\item Unità standard e distribuzione normale standard. 
\item Trasformazioni di variabili distribuite in modo normale. 
\item Aree sotto la densità normale standard. 
\item Aree sotto qualsiasi densità normale. 
\end{enumerate}

\subsubsection{Capitoli 11 e 12: tecnica di calcolo integrale}


\subsubsection{Capitolo 13: variabili aleatorie continue (continuazione)}
\begin{enumerate}
\item Funzione di ripartizione di una $V.A.$ 
\item Funzione di densità di una $V.A.$ continua. 
\item Proprietà della funzione di ripartizione. 
\item Valore atteso e varianza. 
\item Densità di funzioni biiettive e derivabili di $V.A.$ continue. 
\end{enumerate}

\subsubsection{Capitolo 14: Teorema del Limite Centrale}


\subsubsection{Capitolo 15: Distribuzioni Multivariate Discrete}
\begin{enumerate}
\item Variabili aleatorie multivariate discrete. 
\item Funzioni di probabilità congiunte, marginali, condizionate, indipendenza
stocastica. 
\item Valore atteso e varianza condizionata. 
\item Valore atteso di funzioni di variabili aleatorie multivariate, covarianza
e correlazione.\[
Cov(X,Y)=E\left[\left(X-E(X)\right)\left(Y-E(Y)\right)\right]\]

\item Covarianze e indipendenza, varianze di somme di $V.A.$. 
\end{enumerate}
\noindent Seguono infine i Capitoli 16, 17 e 18: distribuzioni multivariate
continue I\ e II, la distribuzione normale bivariata


\section{Fondamenti di probabilità}

Nella prima parte del corso (Statistica I) sono stati trattati quegli
elementi di statistica descrittiva che hanno in seguito permesso di
affrontare i temi propri della teoria della probabilità quali ad esempio 
\begin{itemize}
\item Lo spazio campionario 
\item La funzione di probabilità 
\item Le variabili aleatorie di cui avete visto

\begin{itemize}
\item la funzione di ripartizione 
\item la funzione di densità 
\item alcuni momenti teorici (valore atteso, varianza) 
\end{itemize}
\end{itemize}
\noindent In questa sezione desideriamo rivedere alcuni concetti e
definizioni ritenuti fondamentali per la comprensione dei prossimi
capitoli. Il primo tema che vogliamo affrontare riguarda il concetto
di \emph{esperimento aleatorio}%
\footnote{Rinominiamo il concetto di \emph{esperimento statistico} in \emph{esperimento
aleatorio}. Come avremo modo di discutere più avanti, all'espressione
{}``esperimento statistico\textquotedblright{}\ verrà assegnato
un significato diverso.%
}.


\subsection{Esperimento Aleatorio}

\begin{definizione} Un esperimento aleatorio consiste nell'osservazione
di un processo o procedimento aleatorio i cui esiti sono definiti
ma non prevedibili. \end{definizione}

\bigskip{}


\begin{definizione} L'insieme degli esiti di un esperimento aleatorio
è chiamato \emph{spazio campionario} ed è notato $\Omega$. \end{definizione}

\bigskip{}


\begin{definizione} Un qualsiasi sottoinsieme $E$ di $\Omega$ è
chiamato evento. \end{definizione}

\bigskip{}


\begin{esempio} Lancio di un dado. $\Omega=\{1,2,3,4,5,6\}$. $E=\{$osservo
un numero pari$\}=\{2,4,6\}.$ \end{esempio}

\bigskip{}


\noindent Tipicamente siamo interessati a calcolare la probabilità
di eventi tramite una legge o distribuzione o misura%
\footnote{Utilizzeremo questi tre termini quali sinonimi.%
} di probabilità $P$. Ad esempio, quando lo spazio campionario è discreto
e finito (cioè $\Omega$ contiene un numero finito di esiti) e gli
esiti sono equiprobabili avete imparato a calcolare la probabilità
di un evento $E$ tramite la formula\begin{equation}
P(E)=\frac{\#\text{ esiti in }E}{\#\text{ esiti in }\Omega}=\frac{\#\text{ esiti favorevoli}}{\#\text{ esiti totali}}.\label{formula esiti equiprobabili}\end{equation}
 Ci preme sottolineare che la formula (\ref{formula esiti equiprobabili})
ha validità limitata. Essa è applicabile solo al caso di uno spazio
campionario finito i cui esiti sono equiprobabili. Osserviamo inoltre
che la suddetta regola consente di assegnare una probabilità ad uno
qualsiasi dei $2^{6}=64$ diversi eventi%
\footnote{Il numero di eventi diversi fra loro di uno spazio campionario finito
$\Omega$ è dato dalla formula \[
2^{\#\text{ esiti in }\Omega}.\]
 %
} di $\Omega$. Quando lo spazio campionario $\Omega$ ha un numero
infinito di esiti le cose si complicano: in generale non è più possibile
calcolare la probabilità di un qualsiasi sottoinsieme di $\Omega$.

\bigskip{}


\noindent Lasciando i dettagli tecnici ai matematici indicheremo semplicemente
con $\mathcal{E}$ l'insieme degli eventi di cui desideriamo calcolare
la probabilità. Senza preoccuparci troppo della struttura dell'insieme
di eventi $\mathcal{E}$ ipotizzeremo che gli eventi in esso contenuti
siano sempre misurabili, nel senso che sia possibile assegnare loro
una probabilità in maniera {}``consistente\textquotedblright{}.

\bigskip{}


\noindent Il terzo ed ultimo oggetto fondamentale che vogliamo discutere
è la legge di probabilità $P$ per la quale utilizziamo la seguente
definizione.

\bigskip{}


\begin{definizione} \label{def legge di probabilita}La legge di
probabilità $P$ è una funzione il cui dominio è $\mathcal{E}$, l'insieme
degli eventi, con le seguenti proprietà 
\begin{enumerate}
\item $P(E)\geq0$ per ogni evento $E\in\mathcal{E}$. 
\item $P(\Omega)=1.$ 
\item Se $E_{1},E_{2},\ldots$ è una successione di eventi di $\mathcal{E}$
a due a due incompatibili (cioè $E_{i}\cap E_{j}=\varnothing$ per
$i\neq j$) allora \[
P\left(E_{1}\cup E_{2}\cup~\ldots\right)=\sum_{i=1}^{\infty}P\left(E_{i}\right).\]
 
\end{enumerate}
\end{definizione}

\noindent Della Definizione \ref{def legge di probabilita} è importante
notare una cosa:\ gli argomenti da inserire in $P$ non sono esiti
(elementi di $\Omega$) ma eventi (elementi di $\mathcal{E}$)!

\bigskip{}


\noindent Per concludere: un esperimento aleatorio è caratterizzato
da tre oggetti:\ uno spazio di probabilità $\Omega$, l'insieme degli
eventi $\mathcal{E}$ ed una legge di probabilità $P$. La tripla
$\left(\Omega,\mathcal{E},P\right)$ è chiamata \emph{spazio di probabilità}.


\subsection{Funzione di ripartizione e di densità}

Per qualsiasi esperimento aleatorio è possibile definire lo spazio
campionario $\Omega$ nonché l'insieme degli eventi $\mathcal{E}$
sul quale è definta una legge di probabilità $P$. Consideriamo ora
un esperimento aleatorio $\left(\Omega,\mathcal{E},P\right)$ in cui
lo spazio campionario $\Omega$ è sottoinsieme di $\mathbb{R}$. Questo
significa che gli esiti dell'esperimento saranno dei numeri. L'esempio
del lancio di un dado soddisfa questa condizione. In tal caso è possibile
definire la funzione di ripartizione della legge di probabilità $P$.

\bigskip{}


\begin{definizione} (Funzione di ripartizione di un esperimento aleatorio).
La funzione di ripartizione $F:\mathbb{R}\rightarrow\lbrack0,1]$
della legge di probabilità $P$ è definita come \begin{equation}
F(x):=P((-\infty,x])\text{ con }x\in\mathbb{R}\text{.}\label{definizione funzione di ripartizione}\end{equation}
 \end{definizione}

\noindent La funzione di ripartizione $F(x)$ è dunque la probabilità
dell'evento $E=(-\infty,x]$ di osservare un esito inferiore o al
massimo uguale ad $x$.

\bigskip{}


\begin{remark} Facciamo notare che $P$ ed $F$ sono funzioni diverse.
$F$ è una funzione definita su $\mathbb{R}$ mentre $P$ è\ una
funzione definita su $\mathcal{E}$, l'insieme degli eventi. È possibile
dimostrare come $P$ ed $F$ siano {}``le due facce della stessa
moneta\textquotedblright{}\ nel senso che da $P$ segue univocamente
$F$ e viceversa. \end{remark}

\pagebreak

\begin{esempio} Distribuzione uniforme discreta con $\Omega=\{0.2,0.4,0.6,0.8,1\}$.
\end{esempio}

\begin{center}
%
\begin{figure}
\begin{centering}
\includegraphics{grafici/funzioneRipartizioneUnivormeDiscreta}\caption{Distribuzione uniforme discreta}

\par\end{centering}


\end{figure}

\par\end{center}

\pagebreak

\begin{esempio} Distribuzione uniforme continua $U[0,1]$. \end{esempio}

\begin{definizione} \label{def funz rip assolutamente continua}Diciamo
che $F$ è assolutamente continua se esiste una funzione reale $f$
non negativa tale per cui \[
F(x)=\int_{-\infty}^{x}f(u)du\text{ per ogni }x\in\mathbb{R}\text{.}\]
 La funzione $f$ è chiamata funzione di densità di $F$. Vale inoltre
la relazione \[
F^{\prime}(x)=f(x).\]
 \end{definizione}


\section{Statistica descrittiva e teoria della pro\-ba\-bi\-li\-tà}

Nel corso di Statistica I avete studiato che il punto di partenza
di qualunque a\-na\-li\-si statistica è la definizione di una popolazione
obiettivo (o popolazione di riferimento) nonché della caratteristica
della popolazione a cui si è interessati. A titolo di esempio prendiamo
quale popolazione di riferimento l'insieme di studenti che lo scorso
anno ha seguito il corso di Statistica II. Quali caratteristiche sotto
esame scegliamo il sesso e il numero di scarpe di ciascun studente.
Riportiamo qui di seguito il grafico delle frequenze relative per
le due caratteristiche.

\noindent Notiamo che la seconda caratteristica è numerica. In questo
semplice e\-sem\-pio non abbiamo definito delle classi di valore:
tutti i numeri di scarpe osservati figurano nell'istogramma. Tuttavia
se avessimo studiato un'altra caratteristica quale ad esempio il peso
o la l'altezza ecco che molto probabilmente avremmo costruito delle
classi in cui inserire ciascun individuo della popolazione. La costruzione
di classi può però costituire un problema. Innanzi tutto è necessario
trovare una regola che a partire dalle singole osservazioni indichi
quante e quali classi costruire. Secondariamente il passaggio dall'insieme
della popolazione al suo istogramma di frequenze relative o assolute
genera una perdita di informazione. Ad esempio, anche se sapessimo
che 23 individui hanno un peso compreso tra 70 e 75 chilogrammi non
saremmo in grado di stabilire quanti di essi hanno un peso superiore
a 72 chilogrammi. Per tale motivo quando abbiamo a che fare con caratteristiche
numeriche preferiamo studiare la funzione di ripartizione della popolazione
obiettivo.

\pagebreak

\begin{definizione} (Funzione di ripartizione della popolazione obiettivo).
La funzione di ripartizione, notata $F$, di una caratteristica $x$
della popolazione obiettivo è una funzione di variabile reale definita
su tutto $\mathbb{R}$ e tale che per ogni $x\in\mathbb{R}$\begin{equation}
F(x)=\frac{\#\text{ unità con caratteristica }\leq x}{\#\text{ unità della popolazione}}\text{.}\label{funzione ripartizione popolazione}\end{equation}
 \end{definizione}

\noindent L'interpretazione è semplice ed è molto simile all'interpretazione
della funzione di ripartizione di un esperimento aleatorio. Infatti,
tornando al nostro esempio iniziale della popolazione di studenti
che hanno seguito il corso di Statistica II, $F(38)\ =0.24$ significa
che il $24\%$ della popolazione possiede un numero di scarpa inferiore
o uguale a 38. Come per un esperimento aleatorio, la funzione di ripartizione
racchiude tutta l'informazione disponibile sulla popolazione (confronta
la Definizione (\ref{definizione funzione di ripartizione})). Nel
caso della funzione di ripartizione di una popolazione obiettivo non
si parla di probabilità ma di frequenze relative in quanto non c'è
nulla di aleatorio nella popolazione. La popolazione esiste e l'attributo
è osservabile.\ $F$ descrive come l'attributo in esame è distribuito
all'interno della popolazione. La conoscenza di $F$ è equivalente
all'osservazione dell'attributo su tutta la popolazione obiettivo.

\bigskip{}


\noindent Lo scopo di molti studi empirici in economia (micro- e macroeconomia,
marketing ma anche in altre scienze sociali e non) è quello di determinare
la funzione di ripartizione di un determinato attributo o caratteristica
di una popolazione obiettivo%
\footnote{Parleremo semplicemente di \emph{distribuzione della popolazione}
quando è chiaro quali siano l'attributo e la popolazione obiettivo
in esame.%
} ed in seguito utilizzare questa informazione per giungere a delle
conclusioni di carattere generale. Per tale motivo uno dei temi dei
prossimi capitoli sarà proprio quello di studiare come ottenere un'approssimazione
della distribuzione dell'intera popolazione partendo da un sottoinsieme
di osservazioni della stessa (campione).

\bigskip{}


\noindent Le definizioni (\ref{definizione funzione di ripartizione})
e (\ref{funzione ripartizione popolazione}) di funzione di ripartizione
caratterizzano rispettivamente l'aspetto probabilistico di un esperimento
aleatorio e la struttura della popolazione obiettivo. Le due definizioni,
anche se concettualmente molto simili, non devono essere confuse.


\section{Famiglie parametriche di distribuzioni\label{famiglie parametriche di distribuzioni}}

Nel corso di Statistica I\ avete studiato alcune particolari distribuzioni
di probabilità con le relative funzioni di ripartizione, di densità
o di probabilità. La distribuzione Normale (caso continuo)\ e la
distribuzione di Poisson (caso discreto) sono due esempi a voi noti.
Per quanto riguarda la distribuzione Normale, essa è caratterizzata
da due $\emph{parametri}$ che come già sapete corrispondono al valore
atteso ed alla varianza della distribuzione.

\begin{remark} Attenzione a non generalizzare questa caratteristica
della distribuzione Normale. Durante questo corso incontreremo diverse
nuove distribuzioni di probabilità. Come nel caso della distribuzione
Normale o di Poisson la loro forma dipenderà da uno o più parametri
la cui interpretazione varierà da distribuzione a distribuzione. \end{remark}

\noindent Il grafico sottostante esplicita quanto affermato mostrando
la funzione di densità dalle distribuzione Normale per due diversi
valori di $(\mu,\sigma^{2})$.

\noindent Nella Figura \ref{graficoconfrontoDueNormali} la formula
della funzione di densità è invariata. Cambiano i valori dei due parametri
$\mu$ e $\sigma^{2}$. Per ogni possibile valore dei parametri si
ottiene una diversa distribuzione della famiglia Normale. Si è soliti
indicare col termine famiglia parametrica Normale l'insieme di tutte
le distribuzioni che si possono ottenere facendo variare i due parametri
$\mu$ e $\sigma^{2}$. In generale si parlerà di famiglia parametrica
di distribuzioni per indicare un preciso insieme di distribuzioni
la cui funzione di probabilità, funzione di ripartizione o funzione
di densità è identica\ a meno di un numero finito di parametri. I
parametri assumono valori in $\mathbb{R}$ o in sottoinsiemi di $\mathbb{R}$.
Nel caso della famiglia parametrica Normale $\mu\in\mathbb{R}$ mentre
$\sigma^{2}>0$. L'insieme dei valori che i parametri di una famiglia
parametrica di distribuzioni possono assumere è chiamato spazio parametrico
ed è indicato con il simbolo $\Theta$. Per la famiglia parametrica
Normale $\Theta=\mathbb{R\times R}^{+}$. Riportiamo alcuni esempi
di famiglie parametriche di distribuzioni discrete e continue. Nella
loro definizione appare la \emph{funzione indicatrice} $I_{A}(x)$,
dove $A$ rappresenta un sottoinsieme di $\mathbb{R}$.

\bigskip{}


\noindent Ricordiamo che per qualsiasi sottoinsieme $A$ di $\mathbb{R}$
la funzione $I_{A}:$ $\mathbb{R\rightarrow\{}0,1\mathbb{\}}$ è definita
nel seguente modo \[
I_{A}(x)=\left\{ \begin{array}{cl}
1 & \text{ se }x\in A\\
0 & \text{ altrimenti}\end{array}\right..\]
 Prendendo quale esempio la distribuzione discreta uniforme, l'insieme
$A$ corrisponde all'insieme dei numeri interi compresi da $1$ a
$n$, ovvero $\{1,...,n\}$. Se poniamo $n=5$ avremo che $I_{\{1,...,5\}}$(20)=
0, $I_{\{1,...,5\}}$(2.6)= 0, $I_{\{1,...,5\}}$(4)= 1.

\bigskip{}
 \begin{tabular}{|c|c|c|}
\hline 
 & \textbf{Uniforme}  & \textbf{Bernoulli} \tabularnewline
\hline 
$f(x)=$  & $\frac{1}{n}I_{\{1,...,n\}}(x)$  & $p^{x}(1-p)^{1-x}I_{\{0,1\}}(x)$ \tabularnewline
\hline 
$F(x)=$  & $\min(\frac{\lfloor x\rfloor}{n},1)I_{[1,\infty)}(x)$  & $(1-p)I_{[0,\infty)}(x)+pI_{[1,\infty)}(x)$ \tabularnewline
\hline 
\multicolumn{1}{|l|||}{Spazio parametrico $\Theta$} & $n=1,2,\ldots$  & $0\leq p\leq1$ \tabularnewline
\hline 
\multicolumn{1}{|l|||}{Valore atteso} & $\frac{n+1}{2}$  & $p$ \tabularnewline
\hline 
\multicolumn{1}{|l|||}{Varianza} & $\frac{n^{2}-1}{12}$  & $p(1-p)$ \tabularnewline
\hline
\end{tabular}

\bigskip{}
 \hspace*{-2cm}\begin{tabular}{|c|c|c|}
\hline 
 & \textbf{Binomiale}  & \textbf{Binomiale negativa} \tabularnewline
\hline 
$f(x)=$  & $\left(\begin{array}{c}
n\\
x\end{array}\right)p^{x}(1-p)^{n-x}I_{\{0,...,n\}}(x)$  & $\left(\begin{array}{c}
r+x-1\\
x\end{array}\right)p^{r}(1-p)^{x}I_{\{0,1,...\}}(x)$ \tabularnewline
\hline 
$F(x)=$  & $\sum\limits _{i=0}^{\lfloor x\rfloor}f(i)$  & $\sum\limits _{i=0}^{\lfloor x\rfloor}f(i)$ \tabularnewline
\hline 
\multicolumn{1}{|l|||}{Spazio parametrico $\Theta$} & $0\leq p\leq1\ ;\ n=1,2,\ldots$  & $0<p\leq1\ ;\ r=1,2,\ldots$ \tabularnewline
\hline 
\multicolumn{1}{|l|||}{Valore atteso} & $np$  & $\frac{r\left(1-p\right)}{p}$ \tabularnewline
\hline 
\multicolumn{1}{|l|||}{Varianza} & $np(1-p)$  & $\frac{r\left(1-p\right)}{p^{2}}$ \tabularnewline
\hline
\end{tabular}

\bigskip{}
 \hspace*{-2.3cm}\begin{tabular}{|c|c|c|}
\hline 
 & \textbf{Geometrica}  & \textbf{Ipergeometrica} \tabularnewline
\hline 
$f(x)=$  & $p(1-p)^{x}I_{\{0,...,n\}}(x)$  & $\frac{\left(\begin{array}{c}
K\\
x\end{array}\right)\left(\begin{array}{c}
M-K\\
n-x\end{array}\right)}{\left(\begin{array}{c}
M\\
n\end{array}\right)}I_{\{0,1,...,n\}}(x)$ \tabularnewline
\hline 
$F(x)=$  & $\left(1-(1-p)^{\lfloor x+1\rfloor}\right)I_{[0,\infty)}(x)$  & $\sum\limits _{i=0}^{\lfloor x\rfloor}f(i)$ \tabularnewline
\hline 
\multicolumn{1}{|l|||}{Spazio parametrico $\Theta$} & $0<p\leq1$  & $M=1,2,\ldots\ ;\ K=0,\ldots,M\ ;\ n=1,2,\ldots$ \tabularnewline
\hline 
\multicolumn{1}{|l|||}{Valore atteso} & $\frac{1-p}{p}$  & $n\frac{K}{M}$ \tabularnewline
\hline 
\multicolumn{1}{|l|||}{Varianza} & $\frac{1-p}{p^{2}}$  & $n\frac{K}{M}\frac{M-K}{M}\frac{M-n}{M-1}$ \tabularnewline
\hline
\end{tabular}

\begin{center}
\bigskip{}
 \begin{tabular}{|c|c|c|}
\hline 
 & \textbf{Uniforme}  & \textbf{Normale} \tabularnewline
\hline 
$f(x)=$  & $\frac{1}{b-a}I_{[a,b]}(x)$  & $\frac{1}{\sqrt{2\pi}\sigma}\exp(-\frac{1}{2}\left(\frac{x-\mu}{\sigma}\right)^{2})$ \tabularnewline
\hline 
$F(x)=$  & $\min(\frac{x-a}{b-a},1)I_{\left[a,\infty\right)}(x)$  & $\int_{-\infty}^{x}f(u)du$ \tabularnewline
\hline 
\multicolumn{1}{|l|||}{Spazio parametrico $\Theta$} & $-\infty<a<b<\infty$  & $-\infty<\mu<\infty\ ;\ \sigma>0$ \tabularnewline
\hline 
\multicolumn{1}{|l|||}{Valore atteso} & $(a+b)/2$  & $\mu$ \tabularnewline
\hline 
\multicolumn{1}{|l|||}{Varianza} & $(b-a)^{2}/12$  & $\sigma^{2}$ \tabularnewline
\hline
\end{tabular}
\par\end{center}

\begin{center}
\bigskip{}
 \begin{tabular}{|c|c|c|}
\hline 
 & \textbf{Logistica}  & \textbf{Pareto} \tabularnewline
\hline 
$f(x)=$  &  & $f(x)=\frac{\theta k^{\theta}}{x^{\theta+1}}I_{(k,\infty)}(x)$ \tabularnewline
\hline 
$F(x)=$  & $\left[1+\exp(-(x-\alpha)/\beta\right]^{-1}$  & \tabularnewline
\hline 
\multicolumn{1}{|l|||}{Spazio parametrico $\Theta$} & $\beta>0\ ;\ -\infty<\alpha<\infty$  & $k>0\ ;\ \theta>0$ \tabularnewline
\hline 
\multicolumn{1}{|l|||}{Valore atteso} & $\alpha+\beta\gamma\ $con $\gamma\approx0.577216$  & $\frac{\theta k}{\theta-1}$ quando $\theta>1$ \tabularnewline
\hline 
\multicolumn{1}{|l|||}{Varianza} & $\frac{\pi^{2}\beta^{2}}{6}$  & $\frac{\theta k^{2}}{\left(\theta-1\right)^{2}\left(\theta-2\right)}$
quando $\theta>2$ \tabularnewline
\hline
\end{tabular}
\par\end{center}

\noindent Le famiglie appena presentate sono solo alcune delle numerose
famiglie parametriche di distribuzioni. Come potete verificare voi
stessi il numero di parametri e la loro interpretazione varia da famiglia
a famiglia.


\section{Contenuto del corso}

\noindent Nella seconda parte del corso (Statistica II) verranno affrontati
i temi propri dell'induzione statistica, ovvero 
\begin{itemize}
\item La teoria del campionamento


La teoria del campionamento trae la sua ragion d'essere dalla necessità
di raccogliere in maniera appropriata le informazioni (dati) necessari
allo studio del fenomeno a cui siamo interessati.

\item La teoria della stima


La teoria della stima utilizza le informazioni così raccolte (più
eventuali altre informazioni) per trarre delle conclusioni o dare
delle risposte alle domande relative al fonomeno sotto esame.

\item La verifica d'ipotesi


A causa dell'incompleta informazione e alla natura aleatoria di molti
fenomeni studiati in economia e nelle scienze sociali tali conclusioni
non saranno vere in assoluto. Tuttavia, se lo studio è stato condotto
seguendo certi principi, il grado di incertezza potrà essere quantificato.
La verifica d'ipotesi tramite dei test statistici e la construzione
di intervalli di confidenza relativi ai parametri stimati permettono
di misurare l'attendibilità dei risultati.

\end{itemize}
\begin{esempio} \label{esempio pino1}Pino, il responsabile del settore
marketing di una grossa azienda, desidera conoscere il grado di visibilità
sul mercato di un proprio prodotto. Il motivo di questo interesse
consiste nel fatto che si vuole capire se lo scarso successo commerciale
sia dovuto alla scarsa qualità del prodotto o al fatto che il prodotto
non sia sufficientemente conosciuto. La dirigenza dell'azienda decide
di quantificare il grado di visibilità tramite la percentuale $p$
di consumatori che conoscono (ma non necessariamente acquistano o
hanno acquistato in passato)\ il prodotto in questione. Essa valuta
il livello attuale di $p$ secondo la seguente tabella\[
\begin{tabular}{ccc}
 \ensuremath{p<30\%} &  \ensuremath{30\%\leq p<60\%} &  \ensuremath{60\%\leq p}\\
insufficiente  &  discreto  &  buono\end{tabular}\]
 La quantità in esame è dunque $p$. Poiché è praticamente impossibile
(e troppo oneroso) intervistare tutta la popolazione dei consumatori
sarà necessario selezionare ed intervistare\ un sottoinsieme di tale
popolazione che chiameremo campione. 
\begin{itemize}
\item Come si dovrà costruire il campione da intervistare? 
\item Sulla base di quali criteri dovranno essere selezionate le persone
(o unità) da intervistare:\ l'età, il reddito, la provenienza geografica,
il sesso? 
\item Quante persone dovranno essere intervistate? 
\end{itemize}
\noindent La teoria del campionamento si occupa di trovare una risposta
a queste domande.\\
 \medskip{}


\noindent Una volta effettuato il campionamento si potrà stimare \[
0\leq p\leq1.\]
 La teoria della stima consente di effettuare due tipi di stime: una
stima puntuale di $p$ ed una stima per intervallo. La stima puntuale
di $p$, notata semplicemente $\widehat{p}$, fornisce quella che
noi riteniamo essere la migliore approssimazione o alternativa al
valore sconosciuto $p$. Poiché il calcolo è effettuato sulla base
di un campione di consumatori e non sull'intera popolazione (l'informazione
è incompleta), il valore di $\widehat{p}$ sarà molto probabilmente
diverso da $p$. Si è dunque confrontati con un errore di stima.

\medskip{}
 La stima per intervallo affronta il problema di stima in maniera
diversa. Essa infatti fornisce un intervallo di valori nel quale noi
confidiamo che $p$ sia incluso. Tale intervallo è chiamato \emph{intervallo
di confidenza}. La forza o intensità con cui noi crediamo nella nostra
affermazione è chiamata \emph{livello di confidenza.} Il livello di
confidenza corrisponde alla probabilità ex-ante che l'intervallo costruito
sulla base delle osservazioni disponibili contenga $p$. Un esempio
di una realizzazione di intervallo di confidenza potrebbe essere:\[
\lbrack0.2,0.4].\]
 La teoria della stima si occupa dunque di come calcolare $\widehat{p}$
o come costruire l'intervallo di confidenza utilizzando le informazioni
disponibili (dati). \end{esempio}

\begin{esempio} Continuiamo l'Esempio \ref{esempio pino1}. Supponiamo
che, nel caso in cui $p$ fosse insufficiente, Pino abbia intenzione
di condurre una vasta campagna pubblicitaria e che il valore stimato
di $p$ sia $\widehat{p}=29\%$. A questo punto dobbiamo chiederci
se la campagna pubblicitaria (ed i relativi costi) sia veramente necessaria.
Infatti, potrebbe essere che il vero valore di $p$ sia superiore
al $30\%$ ma per semplice {}``sfortuna\textquotedblright{}\ nella
scelta del campione la nostra stima risulti inferiore a questa soglia.
Il grado di visibilità è realmente insufficiente?\ Ci troviamo qui
confrontati col terzo tema dell'inferenza statistica: la verifica
d'ipotesi. Valori di $\widehat{p}$ inferiori al $30\%$ sono evidenza
a favore dell'ipotesi di un $p$ insufficiente e contro l'ipotesi
di un $p$ discreto o buono. Tenendo conto dell'aleatorietà nella
stima di $p$ e del relativo errore, quanto bassa deve essere la stima
$\widehat{p}$ per decidere di effettuare la campagna pubblicitaria
e quindi rifiutare l'ipotesi che $p$ sia discreto o buono? Per dare
una risposta a questa domanda si costruirà un test statistico. Sarà
innanzi tutto necessario una formalizzazione matematica della nostra
ipotesi. Per Pino, che non ha seguito nessun corso di statistica ed
è uomo d'azione, $\widehat{p}=29\%$ è un valore più che sufficiente
per eseguire la campagna pubblicitaria e spendere un sacco di soldi.

\medskip{}
 Sappiamo che tanto più la campagna pubblicitaria sarà efficace, tanto
più aumenterà il grado di visibilità. Il manager dell'azienda non
è soddisfatto del modo come Pino ha condotto la campagna pubblicitaria
e desidera verificarne immediatamente l'efficacia. Ordina quindi ad
una società indipendente e specializzata in sondaggi di intervistare
un nuovo campione da cui stimare il nuovo grado di visibilità del
prodotto che indicheremo ora con \[
0\leq p_{new}\leq1.\]
 $p_{new}$ è il grado di visibilità \emph{dopo} la campagna pubblicitaria.
Il manager utilizzerà la seguente regola per decidere la sorte di
Pino:\[
\begin{array}{cc}
p_{new}=p & p_{new}\geq p\\
\text{licenzio Pino} & \text{non licenzio pino}\end{array}\]
 La stima puntuale di $p_{new}$, notata $\widehat{p}_{new}$ risulta
essere del $34\%$, un valore di poco superiore al precedente $29\%$
calcolato prima della campagna pubblicitaria. Pino è felice. Il suo
capo gli fa però notare che l'esiguo aumento del $5\%$ rispetto alla
precedente stima potrebbe essere semplicemente dovuta al caso. Pino
vi chiede allora di quantificare sulla base dei dati a disposizione
il livello di evidenza per cui l'ipotesi $p=p_{new}$ (licenzio Pino)
possa essere rigettata. È compito della verifica d'ipotesi fornire
una risposta a questa domanda. \end{esempio}

\begin{esempio} Un produttore di mele deve fissare anticipatamente
la quantità di mele da consegnare al suo acquirente. Sappiamo che
la quantità $q$ prodotta dipende tra le altre cose da fattori climatici,
difficilmente prevedibili ed assai variabili. Da ricerche effettuate
si sa che la produzione di mele $q$ è distribuita secondo la distribuzione
Normale%
\footnote{Per la precisione la distribuzione Normale assegna probabilità positive
all'evento di produrre una quantità negativa di mele. Tuttavia tale
probabilità è trascurabile per dati valori di sigma.%
} che sapete essere univocamente identificata dai parametri $\mu$
e $\sigma^{2}$. Purtroppo i due parametri $\mu$ e $\sigma^{2}$
in questo caso sono sconosciuti e dovranno essere stimati sulla base
dei valori della produzione osservati negli ultimi $20$ anni. È questo
un problema legato alla teoria della stima. Infine, potremmo chiederci
se l'assunzione della distribuzione normale si addice alla variabile
aleatoria $q$ o se tale assunzione è fondamentalmente sbagliata.
In questo frangente si tratta quindi di verificare l'ipotesi concernente
la distribuzione di una variabile aleatoria per la quale si osservano
un certo numero di realizzazioni. \end{esempio}


\section{Domande di fine capitolo}

\begin{domanda} Cosa rappresenta il simbolo $\Omega$? Esplicitate
il suo contenuto facendo un nuovo esempio non visto in classe. \end{domanda}

\begin{domanda} Che relazione sussiste tra $\Omega$, $\mathcal{E}$
e $E$? \end{domanda}

\begin{domanda} Quali sono i tre elementi fondamentali che costituiscono
un esperimento aleatorio? \end{domanda}

\begin{domanda} Costruite un esperimento aleatorio per cui $\Omega\nsubseteq\mathbb{R}$
($\Omega$ \emph{non} è l'insieme dei numeri reali o un suo qualsiasi
sottoinsieme). \end{domanda}

\begin{domanda} Cos'è la funzione di ripartizione? Dato un qualsiasi
esperimento aleatorio $\left(\Omega,\mathcal{E},P\right)$ è sempre
possibile definire la funzione di ripartizione della legge di probabilità
$P$? Se non fosse sempre possibile costruite un semplice esempio
di esperimento aleatorio per cui non è possibile definire la funzione
di ripartizione. \end{domanda}

\begin{domanda} Che differenza c'è tra $P$ ed $F$? \end{domanda}

\begin{domanda} Che differenza c'è tra la funzione di probabilità
e la funzione di densità? \end{domanda}

\begin{domanda} Cos'è una famiglia parametrica di distribuzioni?
Cosa rappresenta $\Theta$? \end{domanda}

\begin{domanda} Per due famiglie parametriche di distribuzioni discrete
e due famiglie parametriche di distribuzioni continue a scelta indicate 
\begin{enumerate}
\item il numero di parametri 
\item la funzione di probabilità o di densità o di ripartizione 
\item lo spazio parametrico 
\end{enumerate}
\end{domanda}

\noindent che le contraddistingue. Scegliete in seguito dei valori
appropriati per i parametri ed eseguite il grafico della funzione
di probabilità o di densità o di ripartizione a dipendenza dalla scelta
effettuata.

\begin{domanda} Ripetete lo stesso esercizio della domanda precedente
con altre due famiglie parametriche di distribuzioni (una discreta
e l'altra continua) che non siano già elencate in questo capitolo.
\end{domanda}


\chapter{\label{A ind stat}Induzione statistica}


\section{Introduzione}

Il processo di apprendimento e di creazione di nuova conoscenza è
possibile grazie a procedimenti di carattere deduttivo e induttivo.
L'acquisizione per via deduttiva permette, partendo da delle premesse
generali la cui validità è garantita, di giungere a delle conclusioni
particolari. Un esempio di ragionamento deduttivo è il seguente: 
\begin{itemize}
\item Premessa maggiore: Tutti gli uomini sono mortali 
\item Premessa minore: Socrate è un uomo 
\item Conclusione: Socrate è mortale 
\end{itemize}
\noindent Per contro, l'apprendimento per via induttiva consiste nel
trovare delle leggi universalmente valide partendo da osservazioni
particolari. Il processo di estensione dal particolare al generale
è chiamato inferenza induttiva. Questo tipo di estensione della conoscenza
è tuttavia soggetto ad incertezza: l'induzione non dimostra niente,
essa è corretta solo nella totalità dei casi in cui è confermata la
sua validità.

\noindent In statistica ci troviamo tipicamente nella situazione di
dover inferire qualcosa circa la 
\begin{enumerate}
\item \emph{distribuzione} di una o più caratteristiche di una certa popolazione
obiettivo, dove per \emph{popolazione obiettivo} si intende la totalità
degli elementi (individui, aziende, famiglie, cantoni, regioni, ...)
per i quali desideriamo ottenere tali informazioni. In questo caso
la popolazione obiettivo è finita ed indicheremo con la lettera $N$
il numero dei suoi elementi. 
\item legge o distribuzione di probabilità di un esperimento aleatorio. 
\end{enumerate}
\noindent Per quanto riguarda il caso di una popolazione finita, avete
visto nel corso di statistica I come è possibile ottenere la distribuzione
di un determinato carattere della popolazione in termini assoluti
o relativi (percentuali) a partire dall'osservazione di ogni singolo
elemento o unità della popolazione stessa. La conoscenza della distribuzione
statistica è fondamentale in quanto essa descrive in maniera univoca
e completa la caratteristica sotto esame. Purtroppo però solo in rare
occasioni l'informazione disponibile è rappresentata dalla distribuzione
statistica di \emph{tutta} la popolazione obiettivo. Anzi è interessante
osservare come ci siano situazioni dove la numerosità stessa della
popolazione obiettivo non è conosciuta. Si pensi ad esempio ad un'analisi
sul numero di sigarette che un fumatore consuma giornalmente. Quanto
vale $N$, il numero di fumatori? Non solo la distribuzione del numero
giornaliero di sigarette consumate da un fumatore è sconosciuta ma
anche il numero stesso di fumatori che in questo esempio costituiscono
la popolazione obiettivo.

\bigskip{}


\noindent Nel caso di un esperimento aleatorio formalizzato tramite
uno spazio di probabilità $(\Omega,\mathcal{E},P)$ l'interesse è
posto sulla legge o distribuzione di probabilità $P$. Essa racchiude
l'informazione disponibile sull'esperimento e le sue caratteristiche
aleatorie. Vista la natura casuale dell'esperimento il risultato o
esito $\omega\in\Omega$ dell'esperimento non è conosciuto a priori:
quello che possiamo fare è assegnare delle probabilità agli eventi
$E\in\mathcal{E}$. La conoscenza della legge di probabilità $P$
permette di quantificare l'incertezza sul risultato dell'esperimento.

\bigskip{}


\noindent Per studiare la legge di probabilità di un dato esperimento
aleatorio è necessario ripetere l'esperimento ed osservarne un certo
numero di risultati . La teoria della stima si occupa di come utilizzare
l'informazione disponibile per risalire alla legge di probabilità
$P$ o equivalentemente%
\footnote{Nell'arco di questo corso tratteremo unicamente spazi di probabilità
ed esperimenti aleatori per i quali l'esistenza di una funzione di
ripartizione è assicurata.%
} alla funzione di ripartizione $F$. Se invece l'attenzione è rivolta
allo studio di una certa caratteristica di una popolazione obiettivo,
allora sarà necessario osservare un certo numero di individui/unità
della popolazione ed in seguito stimare la distribuzione dell'intera
popolazione obiettivo. È questo dunque il carattere induttivo della
statistica inferenziale: da un numero \emph{limitato} di osservazioni
ottenere delle conclusioni di carattere \emph{generale}.


\section{\label{modello parametrico}Modelli parametrici}

\noindent La stima di $F$ risulta particolarmente difficile in quanto
occorre stimare un'intera funzione: è necessario conoscere non solo
il valore che $F$ assume in un determinato punto, ma in tutti i punti
dello spazio campione! È questa un'impresa estremamente difficile.
Sappiamo che $F$ ha una caratteristica particolare:\ è una funzione
monotona crescente. Tuttavia esite un'infinità di funzioni del genere.
Per tale motivo lo statistico spesso restringe la sua ricerca ad un
sottoinsieme ben preciso di funzioni di ripartizione. Ad esempio,
si potrebbe pensare di limitarsi a quelle funzioni di ripartizione
$F$ che sono continue, o a quelle che posseggono una funzione di
densità $f$ (chiamate distribuzioni assolutamente continue, vedi
Definizione \ref{def funz rip assolutamente continua})\begin{equation}
F(x)=\int_{-\infty}^{x}f(t)dt\ \ \text{con }f\text{ non negativa.}\label{integrale tipo 1}\end{equation}
 Questo in parte può aiutare a semplificare la scelta (stima) di $F$
ma non risolve tutti i problemi. La funzione di ripartizione di esperimento
aleatorio il cui spazio campione è discreto, ad esempio, non è continua
e tanto meno può essere rappresentata tramite un integrale del tipo
(\ref{integrale tipo 1}). Inoltre, pur restringendo l'insieme dal
quale stimare $F$, la scelta risulta ancora assai vasta. Una strada
diversa e a volte complementare a quella appena esposta consiste nel
limitare la ricerca di $F$ ad un particolare insieme di distribuzioni
parametriche. Come trattato nella Sezione \ref{famiglie parametriche di distribuzioni},
una famiglia parametrica di distribuzioni è un insieme di distribuzioni.
Da ora in poi noteremo con la lettera $\mathcal{P}$ una qualsiasi
famiglia parametrica di distribuzioni. I parametri sconosciuti associati
a tale famiglia saranno indicati%
\footnote{In generale e a dipendenza della distribuzione si utilizzano diversi
altri simboli, quali ad esempio $\mu,\ \sigma$ o $\lambda$.%
} con $\theta_{1}$, $\theta_{2}$ $...$ $\theta_{K}$. Utilizzeremo
semplicemente la notazione $\theta$ quando desideriamo indicare l'insieme
dei $K$ parametri posti in una lista ordinata che chiameremo semplicemente
vettore $\theta=\left(\theta_{1},\theta_{2},...\theta_{K}\right)$.
La funzione di ripartizione verrà quindi indicata con $F(\cdot;\theta)$
e se esiste la funzione di densità (caso continuo) o di probabilità
(caso discreto) scriveremo analogamente $f(\cdot;\theta)$. In generale
si assumerà che a due diversi parametri $\theta$ e $\widetilde{\theta}$
corrispondano due diverse leggi di probabilità. Infine, l'insieme
dei valori ammissibili per $\theta$ è indicato col simbolo $\Theta$.
Come osservato in precedenza, nel corso introduttivo di Statistica
I avete incontrato diverse famiglie di distribuzioni parametriche
sia discrete che continue (si vedano le dispense riguardanti alcune
delle distribuzioni di probabilità parametriche più comuni). Utilizzeremo
la seguente notazione per definire una famiglia parametrica di distribuzioni
\[
\mathcal{P}=\left\{ F(\cdot;\theta):\ \theta\in\Theta\right\} \]
 oppure, nel caso in cui la famiglia parametrica venga definita indirettamente
tramite la funzione di probabilità (caso discreto) o la funzione di
densità (caso continuo) \[
\mathcal{P}=\left\{ f(\cdot;\theta):\ \theta\in\Theta\right\} .\]


\begin{esempio} La distribuzione continua uniforme è caratterizzata
da due parametri che notiamo con $a$ e $b$ e che corrispondono rispettivamente
all'estremo inferiore e superiore della funzione di densità. Formalmente
questa famiglia può essere scritta come \[
\mathcal{P}=\left\{ f(x;\theta)=\frac{1}{b-a}I_{[a,b]}(x);\ \theta=(a,b)\in\mathbb{R}^{2}\text{, con }a<b\right\} .\]
 In questo esempio a qualsiasi coppia di numeri reali $(a,b)$ tali
per cui $a<b$ associamo una funzione di densità definita da\begin{equation}
f(x;\theta)=\left\{ \begin{array}{cl}
\frac{1}{b-a} & \text{ se }x\in\lbrack a,b]\\
0 & \text{ altrimenti}\end{array}\right..\label{funzione indicatrice uniforme}\end{equation}
 Nel caso della distribuzione uniforme $A=[a,b]$. È facile dimostrare
applicando la definizione di funzione indicatrice che la funzione
di densità (\ref{funzione indicatrice uniforme}) è riscrivibile più
semplicemente come \[
f(x;\theta)=\frac{1}{b-a}I_{[a,b]}(x)\ .\]
 L'insieme dei possibili valori di $\theta$, notato in precedenza
con $\Theta,$ è dunque uguale al sottoinsieme dei punti del piano
la cui prima coordinata è minore della seconda, formalmente \[
\Theta=\left\{ (a,b)\in\mathbb{R}^{2}\mid a<b\right\} .\]
 \end{esempio}

\begin{esercizio} Consideriamo la distribuzione parametrica di Poisson.
Rispondete alle seguenti domande. 
\begin{enumerate}
\item La distribuzione di Poisson è una distribuzione discreta o continua? 
\item Qual è\ o quali sono i parametri che la caratterizzano. Che valori
possono assumere i/il parametro/i di una distribuzione di Poisson?
Definite il contenuto di $\theta$ nonché l'insieme $\Theta$. Definite
$\mathcal{P}$. 
\item Assegnate dei valori al/ai parametro/i. In Excel o Openoffice eseguite
i grafici della funzione di densità e della funzione di ripartizione.
Calcolate la probabilità degli eventi $E_{1}=$ $[0,1]$ ed $E_{2}=(1,2)$. 
\item Scegliete nuovi valori per il/i parametri e col medesimo programma
confrontate i grafici delle due funzioni di densità e delle due funzioni
di ripartizione. Sia $S$ il sottoinsieme di $\mathbb{R}$ definito
da quei punti per cui la funzione di densità è maggiore di 0, cioè
\[
S=\left\{ x\in\mathbb{R}\mid f(x)>0\right\} .\]
 Rispetto al valore assegnato al punto precedente cambia l'insieme
$S$ con i nuovi valori? Siete in grado di generalizzare la vostra
conclusione? 
\item Cosa implica un cambiamento dei valori assegnati al/ai parametro/i
rispetto alle probabilità degli eventi $E_{1}$ ed $E_{2}$ definiti
in precedenza? Notate delle differenze? Spiegate? 
\end{enumerate}
\end{esercizio}

\begin{esercizio} Consideriamo la distribuzione parametrica di Pareto.
Rispondete alle seguenti domande. 
\begin{enumerate}
\item La distribuzione di Pareto è una distribuzione discreta o continua? 
\item Qual è\ o quali sono i parametri che la caratterizzano. Che valori
possono assumere i/il parametro/i di una distribuzione di Pareto?
Definite il contenuto di $\theta$ nonché l'insieme $\Theta$. Definite
$\mathcal{P}$. 
\item Assegnate dei valori al/ai parametro/i ed eseguite i grafici della
funzione di densità e della funzione di ripartizione. Calcolate la
probabilità degli eventi $E_{1}=$ $[0,3]$ ed $E_{2}=\left\{ -1,0,2,3\right\} $. 
\item Trovate l'insieme $S$ per i valori dei parametri da voi scelti. 
\item È possibile trovare dei nuovi valori dei parametri in maniera tale
da modificare l'insieme $S$? Trovate un esempio del genere e confrontate
i grafici delle due funzioni di densità e delle due funzioni di ripartizione. 
\end{enumerate}
\end{esercizio}


\section{Esperimento statistico}

È stato detto che la teoria della stima si occupa di giungere a delle
conclusioni generali riguardo 
\begin{itemize}
\item alla legge di probabilità di un esperimento aleatorio, oppure 
\item alla distribuzione di una variabile aleatoria, oppure 
\item alla distribuzione statistica di una popolazione obiettivo 
\end{itemize}
\noindent partendo da un numero limitato di osservazioni di un certo
esperimento aleatorio o di elementi/unità della popolazione. Da un
punto di vista formale, ripetere $n$ volte in maniera indipendente
un esperimento aleatorio $(\Omega,\mathcal{E},P)$ costituisce un
nuovo tipo di esperimento a cui è dato il nome di $\emph{esperimento}$
$\emph{statistico}$.

\begin{definizione} (Esperimento statistico). Un esperimento statistico
di ampiezza $n$ è costituito da un numero $n$ di ripetizioni indipendenti
dello stesso esperimento aleatorio $(\Omega,\mathcal{E},P)$. \end{definizione}

\bigskip{}


\noindent Quali saranno i possibili esiti di un esperimento statistico?
Sappiamo che ad ogni ripetizione dell'esperimento aleatorio lo spazio
campione è sempre $\Omega$. Potremmo pensare di raccogliere gli esiti
delle $n$ ripetizioni e creare una \emph{lista ordinata} di valori.
Il primo valore della lista corrisponde all'esito della prima esecuzione
dell'esperimento aleatorio, il secondo valore corrisponde all'esito
della seconda esecuzione e via dicendo. La nostra lista conterrà gli
$n$ esiti che indicheremo con $(x_{1},x_{2},...,x_{n})$. Attenzione
a non confondere la lista così costruita con lo spazio campione $\Omega$.
Infatti, per ciascun $i=1,...,n$ l'$i$-esimo elemento $x_{i}$ della
lista è un elemento di $\Omega$ ma $(x_{1},x_{2},...,x_{n})\neq\Omega$.
Lo spazio campione può contenere un numero infinito non numerabile
di esiti. Pensate ad esempio all'esperimento aleatorio di registrare
il tempo d'attesa ad uno sportello postale. In tal caso $\Omega=\left[0,\infty\right\} $
mentre $(x_{1},x_{2},...,x_{n})$ sarà sempre un insieme finito.

\begin{esempio} \label{lancio due dadi}L'esperimento statistico
corrisponde a lanciare 2 volte un dado. L'esperimento aleatorio è
il lancio di un dado. $\Omega=\{1,...,6\}$ mentre $P$ è la distribuzione
uniforme discreta (dado non truccato). Gli esiti dell'esperimento
statistico possono essere rappresentati graficamente come segue \end{esempio}

\begin{esempio} Indicando con $\Omega_{1}$ lo spazio campionario
della prima esecuzione dell'esperimento aleatorio e con $\Omega_{2}$
lo spazio campionario della seconda esecuzione, l'esperimento statistico
avrà quale spazio campionario l'insieme delle coppie di esiti $(x_{1},x_{2})$
con $x_{1}\in\Omega_{1}$ e $x_{2}\in\Omega_{2}$.

Un esito di questo particolare esperimento statistico potrebbe essere
$(3,4)$. Poiché l'ordine conta, l'esito $(3,4)$ è da considerarsi
diverso dall'esito $(4,3)$. \end{esempio}

\noindent In generale chiameremo \emph{spazio campionario prodotto}
l'insieme di tutte le coppie $(x_{1},x_{2})$ dove $x_{1}\in\Omega_{1}$
e $x_{2}\in\Omega_{2}$. Esso verrà notato con $\Omega\times\Omega$
o $\Omega^{2}$. Nel caso di un numero $n$ qualsiasi di ripetizioni
scriveremo semplicemente $\Omega^{n}$ e un esito dell'esperimento
statistico sarà rappresentato tramite la lista $(x_{1},x_{2},...,x_{n})$.

\bigskip{}


\noindent Avendo definito lo spazio campionario di un esperimento
statistico dovremo ora definire gli eventi ad esso associati. Come
per la definizione di evento di un esperimento aleatorio, l'evento
di un esperimento statistico è un sottoinsieme di $\Omega^{n}$. Indicheremo
con $\overset{n}{\underset{i=1}{\otimes}}\mathcal{E}_{i}$ l'insieme
degli eventi definiti su $\Omega^{n}$.Le Figure \ref{esitiEsperimentoStatistico2}
e \ref{esitiEsperimentoStatistico3} rappresentano graficamente due
eventi dell'esperimento statistico discusso nell'Esempio \ref{lancio due dadi}.
Come potete notare nella Figura \ref{esitiEsperimentoStatistico2},
l'evento definito dall'area colorata corrisponde al prodotto cartesiano
$E_{1}\times E_{2}$ dei due eventi $E_{1}=\{2,3,4\}$ ed $E_{2}=\{2,3\}$
definiti rispettivamente sul primo e sul secondo lancio. Lo spazio
$\overset{n}{\underset{i=1}{\otimes}}\mathcal{E}_{i}$ degli eventi
definiti su $\Omega^{n}$ è molto vasto . La Figura \ref{esitiEsperimentoStatistico3}
ci mostra infatti che esso comprende eventi che non sono semplicemente
riconducibili ad un prodotto cartesiano $E_{1}\times E_{2}$ di eventi
di $\Omega_{1}$ e $\Omega_{2}$. Ancora una volta evitiamo di addentrarci
in dettagli tecnici. Considereremo lo spazio degli eventi $\overset{n}{\underset{i=1}{\otimes}}\mathcal{E}_{i}$
come un {}``particolare\textquotedblright{}\ insieme i cui \emph{elementi}
sono \emph{sottoinsiemi} di $\Omega^{n}$.

\medskip{}
 Grazie alla proprietà di indipendenza tra le varie ripetizioni dell'esperimento
aleatorio varrà che la legge di probabilità di un esperimento statistico
è semplicemente il prodotto delle singole leggi di probabilità $P$.
Infatti, chiamando $Q$ la legge di probabilità di un esperimento
statistico (definita quindi su $\overset{n}{\underset{i=1}{\otimes}}\mathcal{E}_{i}$),
avremo per qualsiasi evento\[
E_{1}\times E_{2}\times\ldots\times E_{n}\]
 appartenente a $\overset{n}{\underset{i=1}{\otimes}}\mathcal{E}_{i}$
che la sua probabilità è uguale \[
Q(E_{1}\times E_{2}\times\ldots\times E_{n})=P\left(E_{1}\right)\ P\left(E_{2}\right)\ \cdots\ P\left(E_{n}\right)\ .\]
 Un esperimento statistico può quindi essere rappresentato dalla tripla\begin{equation}
\left(\Omega^{n},\overset{n}{\underset{i=1}{\otimes}}\mathcal{E}_{i},Q=\overset{n}{\underset{i=1}{\otimes}}P_{i}\right).\label{spazio prodotto}\end{equation}
 Chiariamo subito il concetto con un esempio.

\noindent \begin{esempio} Consideriamo l'esperimento aleatorio che
riguarda la misurazione della durata di vita di una lampadina: $\Omega=\mathbb{R}$
mentre quale distribuzione parametrica per la legge di probabilità
$P$ prendiamo la distribuzione esponenziale\[
\mathcal{P}=\left\{ f(x;\lambda)=\lambda e^{-\lambda x}I_{(0,\infty)}(x):\right\} .\]
 Definiamo ora l'esperimento statistico costituito dalla misurazione
della durata di vita di $n=3$ lampadine prodotte in maniera indipendente
l'una dall'altra. Il nuovo esperimento avrà quale spazio campionario
$\mathbb{R}^{3}$. Un evento di questo spazio potrebbe essere il seguente
sottoinsieme di $\mathbb{R}^{3}$ \[
E_{1}\times E_{2}\times E_{3}\]
 dove 
\begin{itemize}
\item $E_{1}=\{\text{\textquotedblleft La prima lampadina si spegne dopo 3 ore\textquotedblright}\}$, 
\item $E_{2}=\{${}``La seconda lampadina dura meno di 20 minuti\textquotedblright{}$\},$ 
\item $E_{3}=\{${}``La terza lampadina prima o poi si spegne\textquotedblright{}$\}.$ 
\end{itemize}
\noindent Grazie all'ipotesi d'indipendenza nell'esecuzione dei tre
esperimenti la legge di probabilità su $\overset{3}{\underset{i=1}{\otimes}}\mathcal{E}_{i}$
non è altro che il prodotto di $P$ sui rispettivi eventi, ovvero
\[
Q(E_{1}\times E_{2}\times E_{3})=P(E_{1})P(E_{2})P(E_{3}).\]
 Il modello parametrico della legge di probabilità $Q$ sarà semplicemente
\begin{eqnarray*}
\mathcal{P} & = & \left\{ g(\left(x_{1},x_{2},x_{3}\right);\lambda)=f\left(x_{1};\lambda\right)\ f\left(x_{2};\lambda\right)\ f\left(x_{3};\lambda\right):\ \lambda>0\right\} \\
 & = & \left\{ g(\left(x_{1},x_{2},x_{3}\right);\lambda)=\lambda^{3}e^{-\lambda(x_{1}+x_{2}+x_{3})}I_{(0,\infty)}(x_{1})I_{(0,\infty)}(x_{2})I_{(0,\infty)}(x_{3}):\ \lambda>0\right\} .\end{eqnarray*}
 \end{esempio}

\noindent Come potete constatare, la difficoltà è più formale (cioè
nella forma e nella notazione) che concettuale.

\bigskip{}


\noindent La stessa argomentazione è applicabile nell'ambito delle
variabili aleatorie. Prendiamo una variabile aleatoria $X$ a valori
in $\mathbb{R}$ definita su uno spazio di probabilità $(\Omega,\mathcal{E},P)$.
Come visto in classe, la $V.A.$ $X$ possiede una propria legge di
probabilità $P_{X}$. Consideriamo ora un campione di $n$ variabili
aleatorie $X_{1},X_{2},...,X_{n}$ mutualmente indipendenti e distribuite
identicamente a $X$. Questo $n$-campione estratto da $X$ induce
uno spazio prodotto notato \begin{equation}
\left(\mathbb{R}^{n},\overset{n}{\underset{i=1}{\otimes}}\mathcal{E}_{i},Q_{X_{1,...,}X_{n}}=\overset{n}{\underset{i=1}{\otimes}}P_{X,i}\right).\label{spazio prodotto X}\end{equation}
 Se la legge di probabilità $P_{X}$ appartiene ad una famiglia parametrica
di distribuzioni con funzione di densità $f_{X}(\cdot;\theta)$, varrà
per lo stesso discorso fatto in precedenza che la distribuzione $Q_{X_{1,...,}X_{n}}$
apparterrà alla famiglia \[
\mathcal{P}=\left\{ g(\left(x_{1},...,x_{n}\right);\theta)=\overset{n}{\underset{i=1}{\Pi}}f_{X_{i}}\left(x_{i};\theta\right):\ \theta\in\Theta\right\} .\]
 Come in precedenza la densità di $Q_{X_{1,...,}X_{n}}$ altro non
è che il prodotto delle $n$ funzioni di densità $f_{X_{i}}(\cdot;\theta)$.
Poiché le $V.A.$ $X_{1},X_{2},...,X_{n}$ sono identicamente distribuite,
la forma delle funzione di densità $f_{X_{i}}\left(x_{i};\theta\right)$
è la stessa per ogni $i$.

\begin{definizione} Data una variabile aleatoria reale $X$ definita
su uno spazio di probabilità $(\Omega,\mathcal{E},P)$ definiamo esperimento
statistico la terna $(\mathbb{R},\mathcal{E},\mathcal{P})$ dove $\mathcal{P}$
rappresenta la famiglia parametrica di leggi di probabilità per $P_{X}$,
$\mathcal{P=}\left\{ f(\cdot;\theta):\ \theta\in\Theta)\right\} $.
\end{definizione}

\begin{definizione} Dato un esperimento statistico $(\mathbb{R},\mathcal{E},\mathcal{P})$
diremo che $\mathcal{P}$ è correttamente specificata se esiste almeno
un valore $\theta_{0}\in\Theta$ tale per cui $f(\cdot;\theta_{0})$
è la vera funzione di densità/probabilità di $X$. \end{definizione}


\section{Campione}

Chiamiamo \emph{campione} un particolare sottoinsieme di numerosità
$n$ della popolazione obiettivo utilizzato ai fini dell'inferenza.
Nel caso di un esperimento statistico con $\emph{campione}$ intendiamo
l'osservazione di un $n$-campione (inteso come la realizzazione di
$n$ variabili aleatorie%
\footnote{D'ora innanzi utilizzeremo semplicemente l'abbreviazione $i.i.d.$
per indicare variabili aleatorie indipendenti ed identicamente distribuite.%
} $i.i.d$).

\bigskip{}


\noindent Ci sono due osservazioni a questo punto su cui vale la pena
chinarci. La prima riguarda il caso di un esperimento statistico,
ovvero quando si desidera stimare la distribuzione di una variabile
aleatoria $X$ tramite un $n$-campione. È fondamentale ai fini della
comprensione di quanto seguirà rendersi conto che l'$n$-campione
$X_{1},...,X_{n}$ è una collezione di variabili aleatorie che generano
su $\mathbb{R}^{n}$ uno spazio di probabilità. Così come una variabile
aleatoria $X$ induce una legge di probabilità $P_{X}$ su $(\mathbb{R},\mathcal{E})$,
anche $X_{1},X_{2},...,X_{n}$ induce una legge di probabilità su
$\left(\mathbb{R}^{n},\overset{n}{\underset{i=1}{\otimes}}\mathcal{E}_{i}\right)$
che abbiamo indicato con $Q_{X_{1,...,}X_{n}}$. Eseguito l'esperimento,
il ricercatore avrà a disposizione le realizzazioni di $X_{1},...,X_{n}$
che sono dei numeri e che potremo disporre in una lista che chiameremo
vettore $(x_{1},...,x_{n})$. La notazione maiuscola denota la variabile
aleatoria (funzione!) mentre la notazione minuscola ne indica il valore
realizzato $x=X(\omega)$.

\begin{esempio} Lanciamo 3 volte una moneta. In un singolo lancio
la probabilità di ottenere croce è $p$ con $0\leq p\leq1.$ Per un
singolo lancio utilizzeremo la convenzione di indicare con $0$ l'esito
testa e con $1$ l'esito croce. Modelliamo questo esperimento con
lo spazio campionario $\Omega$ contenente gli 8 possibili esiti \[
\begin{array}{cccc}
\omega_{1}=(0,0,0) & \omega_{2}=(1,0,0) & \omega_{3}=(0,1,0) & \omega_{4}=(0,0,1)\\
\omega_{5}=(0,1,1) & \omega_{6}=(1,0,1) & \omega_{7}=(0,1,1) & \omega_{8}=(1,1,1)\end{array}.\]
 È immediato verificare che sotto l'ipotesi di indipendenza tra un
lancio e l'altro la probabilità di ogni singolo esito è data da \[
P(\left\{ \omega_{i}\right\} )=p^{\#\ 1}(1-p)^{\#\ 0}\]
 dove {}``$\#\ 1$\textquotedblright{}\ indica il numero di {}``$1$\textquotedblright{}\ in
$\omega_{i}$. La tripla $(\Omega,\mathcal{E},P)$ forma quindi uno
spazio di probabilità.

\vspace{4cm}


\noindent Su questo spazio definiamo ora la $V.A.$ reale $X:\Omega$
$\rightarrow\mathbb{R}$, $\omega\mapsto\ ${}``il numero di croci
ottenute diviso 2\textquotedblright{}\ che in pratica consiste nel
contare il numero di {}``$1$\textquotedblright{}\ in $\omega$
e dividere per 2. Vale dunque \[
\begin{array}{cccc}
X(\omega_{1})=0 & X(\omega_{2})=\frac{1}{2} & X(\omega_{3})=\frac{1}{2} & X(\omega_{4})=\frac{1}{2}\\
X(\omega_{5})=1 & X(\omega_{6})=1 & X(\omega_{7})=1 & X(\omega_{8})=\frac{3}{2}\end{array}.\]
 La $V.A.$ $X$ assumerà dunque i valori $0,1/2,1,3/2$. Con che
probabilità la variabile aleatoria $X$ sarà uguale a $0$? Andando
a guardare la tabella dei possibili valori deduciamo che $X=0$ se
e solo se $\omega=\omega_{1}$, quindi $P(X=0)=P(\left\{ \omega_{1}\right\} )$.
Allo stesso modo dato un qualsiasi evento $E\subset\mathbb{R}$ diremo
che $E$ si è realizzato se $X(\omega)\in E$, dove $\omega$ denota
la realizzazione su $\Omega$. La probabilità che $E$ si realizzi
è uguale a $P(X^{-1}(E)).$ Ad esempio, la probabilità dell'evento
$E=\{0,\frac{3}{2}\}$ è uguale a $P(\{\omega_{1},\omega_{8}\})$
e la probabilità di $E=[0,1)$ è semplicemente uguale a $P(\{\omega_{1},\omega_{2},\omega_{3},\omega_{4}\})$.
Per questo motivo diciamo che la variabile aleatoria $X$ induce una
legge di probabilità su $(\mathbb{R}$,$\mathcal{E})$ che chiameremo
$P_{X}$. La tripla $(\mathbb{R},\mathcal{E},P_{X})$ è dunque uno
spazio di probabilità. In particolare, $P_{X}$ è la distribuzione
Binomiale $Bin(3,p)$.

\noindent Domanda: siete in grado di modellare l'esperimento statistico
corrispondente alla variabile aleatoria $X$ e selezionare un $n$-campione
di numerosità $n=2$? \end{esempio}

La seconda osservazione riguardante il concetto di $campione$ concerne
la stima della distribuzione statistica di una caratteristica della
popolazione obiettivo. In tal caso il campione è stato definito come
un sottoinsieme della popolazione obiettivo. Questa definizione non
considera il modo come si è costruito questo sottoinsieme. Che regola
di selezione è stata adottata? Su che principio sono stati selezionati
gli $n$ individui o le $n$ unità? Vedremo che applicando dei criteri
aleatori è possibile ricondure il problema del campionamento da una
popolazione campione a quello relativo alla costruzione di un $n$-campione
in un esperimento statistico. Affronteremo però questo tema nel corso
del prossimo capitolo dove analizzeremo le varie tecniche di campionamento.
Per il momento basterà ricordare che anche nel caso di una popolazione
obiettivo la cui distribuzione statistica è sconosciuta il $campione$
osservato è il risultato di un procedimento aleatorio e quindi è da
considerarsi anch'esso come la realizzazione di $n$ variabili aleatorie.

\bigskip{}


\noindent Ma perché, nell'analisi di una popolazione obiettivo, effettuare
un'indagine campionaria e non un'indagine esaustiva? I motivi sono
diversi; fra i principali annoveriamo: 
\begin{itemize}
\item una rilevazione completa è impossibile (costi troppo elevati, impossibilita
di raggiungere tutti gli individui); 
\item determinare le caratteristiche delle unità campionate ne determina
la distruzione (ad esempio, misurare la durata di vita di una lampadina); 
\item La popolazione non è definibile in termini della sua numerosità e
quindi non ha senso parlare di indigine esaustiva (ad esempio una
data tecnologia permette di produrre lampadine la cui durata di vita
è aleatoria. Quanto vale $N$ in questo caso?). 
\item è necessaria una particolare accuratezza nella rilevazione e quindi
a causa delle risorse limitate solo un numero ristretto di unità può
essere osservato; 
\item tempi d'esecuzione elevati se confrontati alla necessità d'informazione
(sondaggi elettorali). 
\end{itemize}

\section{Distribuzione campionaria, statistica, stimatore corretto}

Il concetto di distribuzione di una $V.A.$ (caso univariato) o di
un insieme di $V.A.$ (caso multivariato)\ ci accompagnerà per tutta
la durata di questo corso. Abbiamo visto nei paragrafi precedenti
il concetto di esperimento statistico e di $n$-campione ad esso associato.
Affrontiamo ora la definizione di distribuzione campionaria che altro
non è che la distribuzione congiunta $Q_{X_{1},...,X_{n}}$ delle
$n$ variabili aleatorie $X_{1},...,X_{n}$ vista in precedenza.

\begin{definizione} Distribuzione campionaria. Sia $X_{1},X_{2},...,X_{n}$
un campione aleatorio di numerosità $n$. Si dice distribuzione campionaria
di $X_{1},X_{2},...,X_{n}$ la distribuzione \underline{congiunta}
di $X_{1},X_{2},...,X_{n}$. \end{definizione}

\noindent Una volta definito il modello di probabilità, l'esperimento
statistico ad esso associato e ricavato la distribuzione campionaria
dei dati in nostro possesso si passa alla fase di stima. Lo scopo
della teoria della stima è quello di costruire statistiche $T(X_{1},...,X_{n})$
chiamate stimatori con cui produrre delle stime puntuali $T(x_{1},...,x_{n})$\ del
vettore di parametri%
\footnote{Come già accennato in precedenza, il nome assegnato ai vari parametri
sconosciuti cambia a seconda delle circostanze. Ad esempio, il valore
atteso di una $V.A.$ è generalmente indicato con il simbolo $\mu$.
Se il parametro sconosciuto da stimare fosse la varianza si utilizzerebbe
$\sigma^{2}$.%
} sconosciuti $\theta$. Ancora una volta è fondamentale fare la distinzione
fra il campione $X_{1},...,X_{n}$ quale insieme ordinato di variabili
aleatorie ed il campione osservato $x_{1},...,x_{n}$. La sequenza
$x_{1},...,x_{n}$ contiene dei \emph{numeri} e raccoglie le rispettive
realizzazioni delle $V.A.$ $X_{1},...,X_{n}$, cioè\[
x_{1}=X_{1}(\omega),\ x_{2}=X_{2}(\omega),\ ...,x_{n}=X_{n}(\omega).\]


\bigskip{}


\begin{definizione} Statistica. Una statistica $T$ è una funzione
di variabili aleatorie osservabili (e quindi a sua volta variabile
aleatoria osservabile) che non dipende da alcun parametro incognito.
\end{definizione}

\bigskip{}


\begin{esempio} Alcuni esempi di statistiche sono 
\begin{enumerate}
\item La media $\overline{X}=\frac{1}{n}\sum_{i=1}^{n}X_{i}.$ 
\item $X_{\max}=\max\left\{ X_{1},X_{2},...,X_{n}\right\} .$ 
\item Lo stimatore corretto della varianza $S^{2}=\frac{1}{n-1}\sum_{i=1}^{n}\left(X_{i}-\overline{X}\right)^{2}.$ 
\item Siano $X_{1},...,X_{n}\sim i.i.d.\ N(3,\sigma^{2})$. La variabile
aleatoria\[
Z=\frac{\overline{X}-3}{\sigma}\]
 non è una statistica in quanto la varianza $\sigma^{2}$ (e quindi
anche $\sigma)$ non è nota. 
\end{enumerate}
\end{esempio}

\bigskip{}


\begin{remark} Ci preme sottolineare che una statistica è una variabile
aleatoria. La distribuzione di $\overline{X}$ ad esempio, dipende
dalla distribuzione congiunta di $X_{1},...,X_{n}$. Lo stesso vale
per $X_{\max}$, $S^{2}$ e qualsiasi altra funzione di $X_{1},...,X_{n}$.
\end{remark}

\vspace{4cm}


\begin{definizione} \label{definizione di stimatore corretto}Stimatore
corretto. Sia $\theta$ un parametro sconosciuto. Diremo che $T(X_{1},...,X_{n})$
è uno stimatore corretto di $\theta$ se\[
E\left(T(X_{1},...,X_{n})\right)=\theta\text{.}\]
 \end{definizione}

\bigskip{}


\begin{esempio} Sia $X_{1},...,X_{n}$ un campione di variabili aleatorie
$i.i.d.$ $(\mu,\sigma^{2}).$\\
 La media campionaria è uno stimatore corretto di $\mu$ in quanto\[
E\left(\frac{1}{n}\sum_{i=1}^{n}X_{i}\right)=\frac{1}{n}E\left(\sum_{i=1}^{n}X_{i}\right)=\frac{1}{n}\sum_{i=1}^{n}E(X_{i})=\frac{1}{n}n\mu=\mu.\]
 Anche \[
S^{2}=\frac{1}{n-1}\sum_{i=1}^{n}\left(X_{i}-\overline{X}\right)^{2}\]
 è uno stimatore corretto di $\sigma^{2}$. Per contro, ammettiamo
che $\mu$ sia conosciuto, \[
\widetilde{S}^{2}=\frac{1}{n-1}\sum_{i=1}^{n}\left(X_{i}-\mu\right)^{2}\]
 non è uno stimatore corretto di $\sigma^{2}$. \end{esempio}

\bigskip{}


\noindent Terminiamo il capitolo con due ulteriori esempi di modelli
parametrici.

\bigskip{}


\begin{esempio} \label{Rendimenti azionari}Rendimenti azionari.
Sia $P_{t}$ il prezzo di una certa azione il giorno%
\footnote{In questo caso viene naturale utilizzare l'indice $t$ anziché l'indice
$i$ per indicare la successione di osservazioni di $R$.%
} $t$. Il rendimento logaritmico giornaliero è definito come\[
R_{t}=\ln\frac{P_{t}}{P_{t-1}}\text{.}\]
 Assumiamo che \[
\mathcal{P}=\left\{ f_{\theta}(R)=\frac{1}{\sqrt{2\pi\sigma^{2}}}\exp\left(-\frac{1}{2\sigma^{2}}\left(R-\mu\right)^{2}\right),\ \theta=(\mu,\sigma^{2})\in\mathbb{R}\times\mathbb{R}^{+}\right\} .\]
 Supponiamo di avere un campione comprendente gli ultimi 100 rendimenti
logaritmici giornalieri $R_{t},R_{t-1},...,R_{t-99}$ e che i rendimenti
a date diverse siano fra loro indipendenti. Vogliamo calcolare \[
P\left(R_{t+1}\leq-5\%\right).\]
 \end{esempio}

\bigskip{}


\begin{esempio} \label{esempio cobb-douglas}Funzione di produzione
Cobb-Douglas. Definiamo la seguente relazione\begin{equation}
Y:=\ln Q_{t}=\beta_{1}+\beta_{2}\ln L_{t}+\beta_{3}\ln K_{t}+U_{t}\label{equazione cobb douglas stocastica}\end{equation}
 dove 
\begin{enumerate}
\item $Q_{t}$ rappresenta la quantità prodotta l'anno $t$ di un certo
bene. 
\item $L_{t}$ rappresenta le ore di lavoro utilizzate per la produzione
di $Q_{t}.$ 
\item $K_{t}$ rappresenta la quantità di capitale utilizzato. 
\item $U_{t}$ è una variabile aleatoria, non osservabile che racchiude
tutti quei fattori non sistematici che non sono stati inclusi nel
modello. Assumiamo:\ $U_{t}\sim i.i.d.\ N(0,\sigma^{2})$. 
\end{enumerate}
\noindent La famiglia parametrica $\mathcal{P}$\ è uguale a \[
\mathcal{P}=\left\{ \begin{array}{l}
f_{\theta}(y)=\frac{1}{\sqrt{2\pi\sigma^{2}}}\exp\left(-\frac{1}{2\sigma^{2}}\left(\ln q_{t}-\beta_{1}-\beta_{2}\ln l_{t}-\beta_{3}\ln k_{t}\right)^{2}\right),\\
\theta=(\beta_{1},\beta_{2},\beta_{3},\sigma^{2})\in\mathbb{R}^{3}\times\mathbb{R}^{+}\end{array}\right\} .\]
 In quest'ultimo esempio la funzione di produzione Cobb-Douglas\begin{equation}
Q=\exp(\beta_{1})L^{\beta_{2}}K^{\beta_{3}}\label{equazione deterministica cobb douglas}\end{equation}
 ci è stata suggerita dalla teoria economica. Ne segue che i risultati
empirici ottenuti sono interpretabili nel contesto dei modelli (micro-)
economici ben conosciuti. Ad esempio è possibile interpretare i coefficienti
$\beta_{2}$ e $\beta_{3}$ come le elasticità della produzione:\[
\frac{\partial Q}{\partial L}/\frac{Q}{L}=...\]
 L'equazione (\ref{equazione deterministica cobb douglas}) è deterministica.
In essa la produzione $Q$ è una funzione deterministica delle quantità
di lavoro $L$ e capitale $K$. Nel modello (\ref{equazione cobb douglas stocastica})
invece, $Q$ è una variabile aleatoria in quanto funzione del termine
d'errore%
\footnote{È bene non confondere il concetto di osservabilità di una variabile
con il concetto di aleatorietà. Una variabile può essere deterministica
ma non osservabile, deterministica osservabile, aleatoria non osservabile
o aleatoria ed osservabile. Nel modello (\ref{equazione cobb douglas stocastica})
gli $U_{t}$ \ sono aleatori e non osservabili.%
} $U$.

\noindent È bene fare presente quanto segue. Affinché il modello sia
utilizzabile sono state fatte numerose ipotesi semplificatrici: 
\begin{enumerate}
\item [(a)] forma funzionale della relazione tra le variabili $Q$, $L$
e $K$: lineare nei logaritmi, 
\item [(b)] costanza delle elasticità $\beta_{2}$ e $\beta_{3}$ nel
tempo (progresso tecnologico?), 
\item [(c)] assenza di errori di misurazione in $Q$, $L$ e $K.$ 
\end{enumerate}
\end{esempio}

\bigskip{}


\noindent Raramente la teoria economica ci permette di specificare
completamente un modello. Generalmente altre ipotesi, non motivabili
economicamente, sono necessarie. 
\begin{itemize}
\item La normalità del termine d'errore $U_{t}$ nell'Esempio (\ref{esempio cobb-douglas})
non è sostenibile in modo naturale usando esclusivamente la teoria
economica. 
\item Questo implica la necessità di verificare tramite opportuni test statistici
le ipotesi assunte. 
\item Talvolta l'analisi esplorativa dei dati ci aiuta nella comprensione
del fenomeno in esame e ci permette di ottenere dei modelli più prossimi
alla realtà. 
\end{itemize}
\vspace{0.5cm}
 Concludendo:\ le informazioni utilizzate nella specificazione dei
modelli fanno capo alla 
\begin{itemize}
\item teoria della probabilità, 
\item teoria economica, 
\item analisi esplorativa (si veda l'articolo distribuito riguardante il
premio Nobel 2003 per l'economia Robert F. Engle). 
\end{itemize}

\chapter{Campionamento\label{capitolo campionamento}}

\noindent In questo capitolo studieremo come ottenere un campione
aleatorio estratto da una popolazione obiettivo finita di numerosità
$N$. Con piano o disegno di campionamento si intende il procedimento
utilizzato per costruire il campione partendo da una popolazione finita
o infinita. Del disegno di campionamento possiamo evidenziare 
\begin{itemize}
\item la struttura del campione (liste, sottoliste, attributi, strati); 
\item le regole seguite per identificare gli insiemi di unità da inserire
nel campione; 
\item la probabilità di inclusione delle singole unità; 
\item il modo con cui si determina la numerosità ottima del campione e la
relativa frazione di campionamento. $``$... la numerosità ottima
di un campione è quella che permette di ottenere gli obiettivi dell'indagine
al minimo costo, e sarà \ il più piccolo numero in base al quale
le stime ragiungono il livello di attendibilità atteso dal ricercatore''
(Fabbris, p. 26). 
\end{itemize}
\noindent La conoscenza della tecnica di campionamento utilizzata
è essenziale ai fini della determinazione delle proprietà probabilistiche
(distribuzione congiunta) del campione nonché della validità e correttezza
dei risultati. Un piano di campionamento può infatti essere 
\begin{itemize}
\item probabilistico, in tal caso le unità vengono estratte secondo un meccanismo
aleatorio; 
\item deterministico o non probabilistico, le unità sono scelte dalla popolazione
tramite una regola \emph{deterministica}. 
\end{itemize}
\noindent Un esempio di piano di campionamento deterministico è il
seguente: dall'elenco telefonico estraggo, per ciascuna lettera dell'alfabeto,
i primi 10 individui. Se da un lato risulta evidente la sua semplicità
di implementazione, il metodo deterministico di campionamento presenta
alcuni svantaggi non indifferenti. Esso non permette di calcolare
il grado di precisione con cui viene eseguita la stima. Inoltre, la
validità dei risultati ottenuti è fortemente legata alle informazioni
utilizzate a priori per la scelta del campione. Se tali informazioni
sono sbagliate oppure obsolete e non corrispondono più alla realtà,
i risultati della ricerca saranno distorti. Per tale motivo in questo
corso tratteremo esclusivamente piani di campionamento basati sulla
selezione casuale delle unità (individui) della popolazione obiettivo.
In particolare vedremo le tecniche di campionamento casuale semplice,
di campionamento stratificato, di cam\-pio\-na\-men\-to sistematico.
Tutti questi tipi di campionamento si basano su delle tecniche di
selezione.


\section{Campionamento tramite selezione con re\-in\-se\-ri\-men\-to}

Supponiamo di avere quale popolazione obiettivo l'insieme delle automobili
immatricolate in Svizzera ad una certa data. La numerosità della popolazione
è indicata come al solito con la lettera $N$. Una casa automobilistica
potrebbe essere interessata alla distribuzione del colore dell'automobile
così da poi prevedere il consumo di vernice dei vari colori. Per semplicità
supponiamo che i colori siano solo tre:\ nero, bianco e rosso e che
la distribuzione sia tale per cui il $45\%$ delle auto immatricolate
è nero, il $25\%$ è bianco ed il $30\%$ è rosso. Definiamo ora il
seguente esperimento aleatorio definito sull'insieme $\Omega=\{1,2,...N\}$
che consiste nel scegliere a caso in maniera \emph{equiprobabile}
un numero compreso tra $1$ e $N$. Lo spazio di probabilità è dunque
composto dalla solita tripla $\left(\Omega,\mathcal{E},P\right)$
con \[
P(\{i\})=\frac{1}{N}\text{ per ogni }i\in\Omega\ .\]
 Assegnamo ora in modo univoco a ciascuna automobile un numero $i\in\Omega$
e definiamo la variabile aleatoria (funzione!)$\ X$ da $\Omega$
verso l'insieme dei co\-lo\-ri $\left\{ \text{\textquotedblleft nero\textquotedblright,\textquotedblleft bianco\textquotedblright,\textquotedblleft rosso\textquotedblright}\right\} $
in modo tale che per ogni $i\in\Omega$ la $V.A.$ $X$ restituisca
il colore della $i$-esima automobile\[
i\mapsto X(i)=\text{\textquotedblleft il colore della }i\text{-esima automobile\textquotedblright\ .}\]


\vspace{0.5cm}
 Domanda 1: Qual è la legge di probabilità indotta dalla variabile
aleatoria $X$, notata $P_{X}$, sull'insieme dei tre colori?\vspace{0.5cm}


\noindent Risposta: la legge di probabilità $P_{X}$ non è altro che
la distribuzione statistica della caratteristica in esame della popolazione
obiettivo. Inoltre, se la caratteristica in esame fosse la cilindrata
in $cm^{3}$ dell'automobile anziché il suo colore, la variabile aleatoria
$X$ avrebbe una funzione di ripartizione $F_{X}$ identica alla funzione
di ripartizione della cilindrata della popolazione obiettivo.

\bigskip{}


È dunque possibile, partendo da un semplice spazio di probabilità
discreto, definire una variabile aleatoria $X$ la cui distribuzione
$P_{X}$ è uguale alla distribuzione dell'intera popolazione obiettivo.
Si potrebbe allora pensare di ripetere l'esperimento $n$ volte in
maniera indipendente l'una dall'altra, reinserendo nell'urna il numero
scelto dopo ogni estrazione e mescolando nuovamente molto bene. Il
nuovo spazio campionario consiste ora nei vettori (liste) di lunghezza
$n$ i cui elementi appartengono all'insieme $\{1,2,...N\}$. Scriviamo
semplicemente $\Omega^{n}=\{1,2,...N\}^{n}$. Il numero di elementi
di $\Omega^{n}$ che corrisponde al numero di esiti\ possibili è
$N^{n}$. Poiché il numero selezionato ad ogni estrazione è reinserito
nell'urna, è possibile osservare vettori in cui un numero si ripete
più volte. Ad esempio, per $N=5$ e $n=3$ un possibile esito potrebbe
essere $\omega=(2,5,2)$. Qual è la probabilità di osservare un qualsiasi
esito%
\footnote{Ora $\omega$ denota un qualsiasi elemento di $\Omega^{n}$ ed avrà
quindi la forma\[
\omega=\underset{n\text{ numeri tra }1\text{ e }N}{\underbrace{\left(5,12,...,4\right)}}\]
 di un vettore a $n$ componenti.%
} $\omega\in\Omega^{n}$? Poiché le estrazioni sono indipendenti l'una
dall'altra e ad ogni estrazione la probabilità di estrarre un qualsiasi
numero è pari a $1/N$ vale\[
Q\left(\omega\right)=\frac{1}{N^{n}}\ \text{per ogni }\omega\in\Omega^{n}\ .\]
 Ecco così definito lo spazio di probabilità $\left(\Omega^{n},\overset{n}{\underset{i=1}{\otimes}}\mathcal{E}_{i},Q=\overset{n}{\underset{i=1}{\otimes}}P_{i}\right)$
relativo al nostro nuovo esperimento. Possiamo ora definire le $n$
variabili aleatorie che notiamo con $X_{i}$, $i=1,...,n$ tramite
la procedura \[
X_{i}(\omega):=\left\{ \begin{array}{l}
\text{1)\ Estraggo l' }i-\text{esimo numero da }\omega\text{, notato }j_{i}\in\{1,2,...N\}\text{.}\\
\text{2) Associo la cilindrata dell'}j_{i}-\text{esima automobile.}\end{array}\right.\]
 Continuando con l'esempio dove $N=5$ e $n=3$, data una realizzazione
$\omega=(2,5,2)$ avremmo $j_{1}=2$, $j_{2}=5$, $j_{3}=2$ (praticamente
abbiamo selezionato due volte la seconda automobile ed una volta la
quinta). Il valore che la $V.A.$ $X_{i}$ assume dipende \emph{esclusivamente}
dall'esito parziale della $i$-esima estrazione. Poiché le $n$ estrazioni
sono per costruzione indipendenti anche le variabili aleatorie $X_{i}$
lo saranno e la legge di probabilità $Q_{X_{1},...,X_{n}}$ indotta
da $X_{1},...,X_{n}$ su $\mathbb{R}^{n}$ è semplicemente il prodotto
delle singole leggi di probabilità $Q_{X_{i}}$.

\bigskip{}


Quando la distribuzione statistica della popolazione obiettivo è sconosciuta
possiamo pensare di stimare $P_{X}$ andando a pescare da una particolare
famiglia parametrica di distribuzioni $\mathcal{P}$ la distribuzione
che riteniamo migliore rispetto all'evidenza empirica (le $n$ osservazioni)
in nostro possesso. È quindi possibile ricondurre il problema della
stima della distribuzione della popolazione obiettivo alla definizione
di esperimento statistico e di $n$-campione ad esso associato. In
altre parole, le $n$ variabili aleatorie $i.i.d.$ $X_{1},...,X_{n}$
costruite estraendo a caso con reimmissione $n$ unità dalla popolazione
obiettivo costituiscono un $n$-campione di un esperimento statistico
$(\mathbb{R},\mathcal{E},\mathcal{P})$. La problematica della non
conoscenza della distribuzione statistica della popolazione obiettivo
risulta quindi identica alla problematica della stima della legge
di probabilità di un esperimento aleatorio o di una variabile aleatoria.

\vspace{8cm}


La tecnica di selezione casuale con reinserimento utilizzata precedentemente
per la costruzione di un $n$-campione a partire da una data popolazione
obiettivo di numerosità $N$ è riassunta nel modo seguente. 
\begin{enumerate}
\item A ciascuna delle $N$ unità della popolazione viene assegnato univocamente
un numero da $1$ a $N$. 
\item Si estrae a caso una sola pallina da un'urna contenente $N$ palline
numerate da $1$ a$\ N$. Il numero indicato sulla pallina corrisponde
all'unità del campione da selezionare per l'osservazione della caratteristica
o attributo in esame. 
\item Si reintroduce la pallina estratta e si mescola nuovamente. 
\item Si ripetono i punti $2.$ e $3.$ per un totale di $n$ volte. 
\end{enumerate}
Le $n$ osservazioni, raccolte in un vettore $(x_{1},...,x_{n}),$
costituiscono una realizzazione delle $n$ variabili aleatorie $i.i.d.$
$X_{1},...,X_{n}$ distribuite secondo la legge di probabilità definita
dalla distribuzione della popolazione obiettivo.


\section{Campionamento tramite selezione senza re\-in\-se\-ri\-men\-to}

Questa tecnica è identica alla precedente con l'unica differenza che
le palline estratte non vengono reinserite nell'urna. Cosa cambia
rispetto al paragrafo precedente?\ Possiamo ancora parlare di esperimento
statistico? Quali sono le proprietà della nuova legge di probabilità
$Q$ che con $\Omega^{n}$ e $\overset{n}{\underset{i=1}{\otimes}}\mathcal{E}_{i}$
definisce il nuovo spazio di probabilità? Per rispondere a queste
domande partiamo dalla definizione del nuovo spazio campione. Supponiamo
per semplicità di utilizzare ancora $\Omega^{n}$. Poiché la tecnica
di estrazione è senza reinserimento lo spazio $\Omega^{n}$ conterrà
esiti che non osserveremo mai. Ad esempio, prendiamo nuovamente $N=5$
e $n=3$ e l'esito $\omega=(2,5,2)$. Ovviamente un simile $\omega$
non sarà mai osservabile e potremmo escluderlo dallo spazio campione.
Tuttavia per semplicità nella definizione del nostro spazio campionario
lo lasciamo. Gli esiti in cui un numero si ripete due o più volte
avranno semplicemente probabilità nulla. Dobbiamo ora calcolare la
probabilità di un qualsiasi esito $\omega$ le cui componenti sono
tutte diverse. Tenendo conto dell'ordine (disposizioni), ci sono $D_{N}^{n}=N!/(N-n)!$
modi diversi per estrarre $n$ elementi da un insieme di $N$ elementi.\ Se
l'esperimento è condotto correttamente gli esiti con probabilità positiva
saranno tutti equiprobabili. La probabilità di osservare un esito
$\omega$ a componenti tutte diverse è dunque \[
\frac{1}{\#\text{ esiti a componenti diverse}}=\frac{(N-n)!}{N!}\ .\]
 La nuova legge di probabilità $Q$ è dunque diversa dalla legge di
probabilità vista nel caso di un'estrazione con reinserimento. Applichiamo
la definizione delle $n$ variabili aleatorie $X_{i}$, $i=1,...,n$
al nuovo spazio di probabilità: \[
X_{i}(\omega):=\left\{ \begin{array}{l}
\text{1)\ Estraggo l' }i-\text{esimo numero da }\omega\text{, notato }j_{i}\in\{1,2,...N\}\text{.}\\
\text{2) Associo la cilindrata dell'}j_{i}-\text{esima automobile.}\end{array}\right.\]
 Il nome delle variabili aleatorie è lo stesso ma la loro distribuzione
è cambiata. In particolare, $X_{1},...,X_{n}$ non sono più indipendenti.
Questo perché l'esito della variabile aleatoria $X_{i}$ dipende dall'esito
delle precedenti $V.A.$ $X_{1},...,X_{i-1}$. Facciamo un esempio
prendendo quale popolazione obiettivo il colore delle automobili immatricolate.
Supponiamo che ci siano $k$ automobili rosse. Calcoliamo \[
P(X_{2}=\text{\textquotedblleft}rosso\text{\textquotedblright}\mid X_{1}=\text{\textquotedblleft}rosso\text{\textquotedblright})=\frac{k-1}{N-1}\]
 mentre\[
P(X_{2}=\text{\textquotedblleft}rosso\text{\textquotedblright}\mid X_{1}\neq\text{\textquotedblleft}rosso\text{\textquotedblright})=\frac{k}{N-1}.\]
 Se $X_{1}$ e $X_{2}$ fossero indipendenti le due probabilità condizionate
appena calcolate dovrebbero essere uguali fra loro e uguali a $P(X_{2}=${}``$rosso$\textquotedblright{}$)$.
Esse sono fra loro diverse e da ciò concludiamo che non sono indipendenti.
Per tale motivo le $n$ variabili aleatorie $X_{1},...,X_{n}$ così
costruite, sebbene utili ai fini dell'inferenza statistica, non sono
$i.i.d.$ e non costituiscono un $n$-campione di un esperimento statistico
$(\mathbb{R},\mathcal{E},\mathcal{P})$. Per quanto riguarda questo
corso utilizzeremo quindi il termine $n$\emph{-campione di un esperimento
statistico} solo in referimento a osservazioni di variabili aleatorie
$i.i.d..$


\section{Campionamento tramite selezione siste\-ma\-ti\-ca\label{selezione sistematica}}

La selezione sistematica si effettua nella maniera seguente. 
\begin{enumerate}
\item A ciascuna delle $N$ unità della popolazione assegnamo univocamente
un numero da $1$ a $N$. 
\item Calcoliamo il passo di campionamento, notato $k$, definito come il
rapporto tra $N$ (la numerosità della popolazione) e $n$ (la numerosità
del campione): \[
k=\frac{N}{n}.\]

\item Selezioniamo un numero a caso $r$ compreso tra $1$ e $k$:\begin{equation}
1\leq r\leq k.\label{selezione sistematica k intero}\end{equation}

\item Includiamo nel campione le $n$ unità aventi posizioni\[
r,\ r+k,\ r+2k,\ldots,r+(n-1)k\text{.}\]
 
\end{enumerate}
\begin{remark} Il salto che si effettua tra due unità consecutive
selezionate si chiama \emph{passo di campionamento}. In pratica la
selezione sistematica consiste nel partizionare%
\footnote{Una partizione di un insieme $\Omega$ si può definire come una collezione
di sottoinsiemi di $\Omega$ non vuoti, mutuamente disgiunti e tali
che la loro unione è l'insieme $\Omega$ stesso. (Definizione tratta
da Wikipedia, Partizione (teoria degli insiemi)).%
} la popolazione in $k$ sottoinsiemi di numerosità $n$ per poi selezionarne
uno a caso. All'interno di ogni sottoinsieme la distanza tra le unità
è costante ed uguale $k.$ \end{remark}

\begin{esercizio} Costruite lo spazio di probabilità che utilizzereste
per eseguire un campionamento sistematico. Come sono definite le variabili
aleatorie $X_{1},...,X_{n}$? Sono indipendenti? Quanto vale la probabilità
di estrarre un qualsiasi elemento della popolazione? \end{esercizio}

Quando $N/n$ non è un numero intero, utilizzeremo la tecnica della
\emph{lista circolare}. In pratica, la procedura sarà modificata nel
modo seguente. 
\begin{enumerate}
\item Calcoliamo $k^{\ast}$, il numero intero più vicino a $\frac{N}{n}$. 
\item Estraiamo un numero casuale compreso tra $1$ e $N$ (si noti la differenza
con (\ref{selezione sistematica k intero})):\[
1\leq r\leq N.\]

\item Includiamo nel campione le $n$ unità aventi posizioni\[
r,\ r+k^{\ast},\ r+2k^{\ast},\ldots,r+(n-1)k^{\ast}\]
 dove, una volta esaurita la lista all'unità $N$-esima senza aver
estratto tutte le $n$ unità campionarie, si continuerà a contare
dalla prima unità (da qui il termine lista circolare). 
\end{enumerate}

\section{Varianza di - e covarianza fra - somme pesate di variabili aleatorie}

Molti stimatori in statistica ed econometria si possono rappresentare
come particolari \emph{somme pesate} di variabili aleatorie. Al fine
di studiare alcune delle loro caratteristiche quali ad esempio la
correttezza (Definizione \ref{definizione di stimatore corretto}),
la varianza o la covarianza con altre statistiche sarà necessario
utilizzare le proprietà del valore atteso, della varianza e della
covarianza di somme di variabili aleatorie.

\begin{esempio} \label{Rendimenti di scala costanti}Rendimenti di
scala costanti. Nell'Esempio \ref{esempio cobb-douglas} abbiamo visto
come si potrebbe stimare una funzione di produzione di tipo Cobb-Douglas.
I parametri $\beta_{2}$ e $\beta_{3}$ corrispondono alle elasticità
della produzione rispetto al lavoro e rispettivamente al capitale.
Potremmo chiederci se una simile tecnologia possiede rendimenti di
scala costanti. In termine dei coefficienti $\beta_{2}$ e $\beta_{3}$
tale ipotesi implica \begin{equation}
\beta_{2}+\beta_{3}=1.\label{test di rendimenti di scala costanti}\end{equation}
 Tuttavia $\beta_{2}$ e $\beta_{3}$ sono dei parametri sconosciuti
che andranno stimati tramite opportune statistiche $\widehat{\beta}_{i}=T_{i}(Q_{1},L_{1},K_{1},...,Q_{n},L_{n},K_{n})$
$i=1,2,3$. $\widehat{\beta}_{2}$ e $\widehat{\beta}_{3}$ sono quindi
delle variabili aleatorie, generalmente correlate fra loro in quanto
funzioni delle medesime osservazioni. Per verificare tramite un opportuno
test d'ipotesi la validità dell'ipotesi di rendimenti di scala costanti
procederemo come segue: 
\begin{enumerate}
\item sostituiremo i parametri sconosciuti $\beta_{2}$ e $\beta_{3}$ nella
(\ref{test di rendimenti di scala costanti}) con i rispettivi valori
stimati, $\widehat{\beta}_{2}$ e $\widehat{\beta}_{3}$. 
\item calcoleremo la differenza (o scarto)\ tra il valore osservato $\widehat{\beta}_{2}+\widehat{\beta}_{3}$
ed il valore teorico che in questo caso è $1$. 
\item Se la differenza in valore assoluto risulterà essere \textquotedbl{}grande\textquotedbl{}
rifiuteremo l'ipotesi di rendimenti di scala costanti altrimenti non
la rifiuteremo. 
\end{enumerate}
\noindent Per stabilire se la differenza così calcolata è significativa
(\textquotedbl{}grande\textquotedbl{}) o non significativa (\textquotedbl{}piccola\textquotedbl{})
sarà necessario calcolare la varianza di $\widehat{\beta}_{2}+\widehat{\beta}_{3}$
che come già sapete è pari a \[
V\left(\widehat{\beta}_{2}+\widehat{\beta}_{3}\right)=V\left(\widehat{\beta}_{2}\right)+V\left(\widehat{\beta}_{3}\right)+2Cov(\widehat{\beta}_{2},\widehat{\beta}_{3}).\]
 Poiché $\widehat{\beta}_{2}$ e $\widehat{\beta}_{3}$ risulteranno
essere delle particolari somme pesate%
\footnote{I termini $a_{i}$ e $b_{i}$ sono dei pesi deterministici (dei numeri).%
} delle $V.A.$ $Q_{1},...,Q_{n}$ e cioè \[
\widehat{\beta}_{2}=\sum_{i=1}^{n}a_{i}Q_{i}\ \ \text{e}\ \ \widehat{\beta}_{3}=\sum_{j=1}^{n}b_{j}Q_{j}\]
 dovremo essere in grado di calcolare espressioni del tipo \[
Cov(\widehat{\beta}_{2},\widehat{\beta}_{3})=Cov(\sum_{i=1}^{n}a_{i}Q_{i},\sum_{j=1}^{n}b_{j}Q_{j}).\]
 \end{esempio}


\subsection{Definizione della varianza e della covarianza}

Rivediamo brevemente alcune definizioni. Consideriamo le due variabili
aleatorie reali $X$ e $Y$ la cui funzione di densità%
\footnote{Consideriamo il caso di variabili aleatorie continue. Il caso discreto
è del tutto identico.%
} congiunta è notata $f_{x,y}(x,y)$ mentre le funzioni di densità
marginali sono notate rispettivamente $f_{x}(x)$ e $f_{y}(y)$. La
varianza di $X$ e definita come il valore atteso ... del quadrato
... degli scarti di $X$ dal proprio valore atteso$\ \mu_{X}$:\begin{equation}
V(X):=E\left((X-\mu_{X})^{2}\right)=\int_{\mathbb{R}}(x-\mu_{X})^{2}f_{x}(x)dx\ .\end{equation}
 Quale formula alternativa vale anche \begin{equation}
V(X)=E\left(X^{2}\right)-\left(\mu_{X}\right)^{2}=\int_{\mathbb{R}}x^{2}f_{x}(x)dx-\left(\mu_{X}\right)^{2}\ .\label{definizione alternativa varianza}\end{equation}
 La covarianza fra $X$ e $Y$ è definita come il valore atteso ...
del prodotto ... degli scarti di $X$ e $Y$ dai rispettivi valori
attesi:\begin{equation}
Cov(X,Y):=E\left((X-\mu_{X})(Y-\mu_{Y})\right)=\int_{\mathbb{R}}\int_{\mathbb{R}}(x-\mu_{X})(y-\mu_{Y})f_{x,y}(x,y)dx\ dy\ .\label{definizione di covarianza}\end{equation}
 Come per la varianza abbiamo una formula equivalente\[
Cov(X,Y)=E\left(XY\right)-\mu_{X}\mu_{Y}=\int_{\mathbb{R}}\int_{\mathbb{R}}xy\ f_{x,y}(x,y)dx\ dy-\mu_{X}\mu_{Y}\ .\]
 Guardando alla definizione (\ref{definizione di covarianza}) di
covarianza notiamo che abbiamo il prodotto di due termini $x-\mu_{X}$
il primo e $y-\mu_{Y}$ il secondo. Questo prodotto è ulteriormente
moltiplicato per la rispettiva%
\footnote{Ricordiamo che nel caso di variabili aleatorie continue la funzione
di densità non indica la probabilità di un esito.%
} {}``probabilità\textquotedblright{}. Poiché la funzione di densità
è sempre maggiore o uguale a zero ma mai negativa il prodotto \[
(x-\mu_{X})(y-\mu_{Y})f_{x,y}(x,y)\]
 sarà negativo quando $(x-\mu_{X})$ e $(y-\mu_{Y})$ possiedono segno
diverso ($+\ -$ oppure $-$ $+$) e positivo quando $(x-\mu_{X})$
e $(y-\mu_{Y})$ hanno lo stesso segno ($+$ $+$ o $-$ $-$). La
covarianza è la {}``somma\textquotedblright{}\ su tutti i possibili
esiti pesati per la rispettiva {}``probabilità\textquotedblright{}.
Essa sarà dunque positiva se, mediamente, quando $X$ è sopra o sotto
il suo valore atteso lo è anche $Y$. La covarianza sarà invece negativa
se, mediamente, quando $X$ è sopra (sotto)\ il proprio valore atteso
$Y$ sarà sotto (sopra) $\mu_{Y}$. Intuitivamente, sapendo ad esempio
che $X$ e $Y$ sono correlate negativamente e che il valore osservato
di $X$ è maggiore al suo valore atteso mi aspetto che la realizzazione
di $Y$ sia inferiore a $\mu_{Y}$.


\subsection{Tecnica di calcolo (difficoltà pari alla battaglia navale)}

Iniziamo questo paragrafo prendendo due $V.A.$ che chiameremo $X$
e $Y$ per le quali vale la seguente relazione\begin{equation}
X=\sum_{i=1}^{n}a_{i}X_{i}\text{ e }Y=\sum_{j=1}^{m}b_{j}Y_{j}\text{,}\label{X e Y come somme pesate}\end{equation}
 dove $X_{1},...,X_{n}$ e $Y_{1},...,Y_{m}$ sono delle $V.A.$ tali
per cui $Cov(X_{i},Y_{j})=c_{ij}$. $c_{ij}$ rappresenta la covarianza
(un numero quindi)\ fra la variabile aleatoria $X_{i}$ e $Y_{j}$.
Sottolineamo nuovamente che la variabile aleatoria $X$ è semplicemente
una somma pesata (si dice anche combinazione lineare) delle variabili
aleatorie $X_{1},...X_{n}$. I pesi di tale somma sono i coefficienti
$a_{i}$ e sono dei numeri.

\begin{esempio} Prendiamo $n=3$, $m=2$ ed i seguenti valori degli
$a_{i}$ e $b_{j}$:\[
\begin{array}{cccc}
\text{Indice }i\text{:} & a_{1}=2 & a_{2}=-3 & a_{3}=1\\
\text{Indice }j\text{:} & b_{1}=1 & b_{2}=-2\end{array}\]
 Abbiamo dunque \begin{eqnarray*}
X & = & 2X_{1}-3X_{2}+X_{3}\ ,\\
Y & = & Y_{1}-2Y_{2}\ .\end{eqnarray*}
 \end{esempio}

\noindent Supponiamo che le covarianze $c_{ij}$ siano conosciute.
Come possiamo calcolare $Cov(X,Y)$ in funzione delle covarianze $c_{ij}$?
Per spiegare come fare (la dimostrazione è data in appendice) facciamo
un passo indietro e rivediamo la proprietà di linearità del valore
atteso. Dal corso di analisi matematica sapete che una funzione $f:\mathbb{R}\rightarrow\mathbb{R}$
è lineare se soddisfa le seguenti due condizioni: 
\begin{enumerate}
\item Per qualsiasi $x_{1},x_{2}\in\mathbb{R}$ vale che\begin{equation}
f(x_{1}+x_{2})=f(x_{1})+f(x_{2}),\label{PL1}\end{equation}

\item Per qualsiasi $\lambda,x\in\mathbb{R}$ vale che \begin{equation}
f(\lambda x)=\lambda f(x).\label{PL2}\end{equation}
 
\end{enumerate}
\noindent L'operatore valore atteso, notato $E$, che associa ad una
$V.A.$ $X$ il suo valore atteso\[
E(X)=\sum_{k=1}^{N}x_{k}p(x_{k})\text{ oppure }E(X)=\int_{-\infty}^{\infty}xf(x)dx\]
 è anch'esso lineare. Infatti, come visto nel corso di Statistica
I, le proprietà (\ref{PL1}) (\ref{PL2}) sono soddisfatte per qualsiasi
$V.A.$ $X,$ $X_{1}$ e $X_{2}$ nonché scalare $\lambda\in\mathbb{R}$:\begin{equation}
E(X_{1}+X_{2})=E(X_{1})+E(X_{2})\text{ e }E(\lambda X)=\lambda E(X)\ .\end{equation}
 Dalla proprietà di linearità del valore atteso segue in maniera immediata
che \begin{equation}
E\left(\sum_{i=1}^{n}a_{i}X_{i}\right)=\sum_{i=1}^{n}a_{i}E\left(X_{i}\right)\text{.}\end{equation}
 A parole possiamo dire che \textquotedbl{}il valore atteso di una
somma pesata è uguale alla somma pesata dei valori attesi\textquotedbl{}.

\begin{esempio} (continuato) Supponiamo che i valori attesi di $X_{1},\ X_{2}$
e $X_{3}$ siano rispettivamente uguali a $1,-2,\ 3$. Il valore atteso
di $X$ sarà pertanto uguale a \begin{eqnarray*}
E\left(X\right) & = & E(2X_{1}-3X_{2}+X_{3})\\
 & = & 2E(X_{1})-3E(X_{2})+E(X_{3})\\
 & = & 2+6+3=11.\end{eqnarray*}
 \end{esempio}

\noindent Torniamo ora al calcolo della covarianza fra (e alla varianza
di) somme pesate di $V.A.$. Questo calcolo risulta estremamente semplice
se si considera che la covarianza è una funzione (operatore) \emph{bilineare}.
Cosa significa bilineare? La spiegazione è molto semplice.

\noindent Innanzi tutto osserviamo che la funzione di covarianza ha
due argomenti: quando calcoliamo la covarianza lo facciamo fra due
$V.A.$\[
Cov\left(\underset{1^{\circ}\text{ argomento}}{X},\underset{2^{\circ}\text{ argomento}}{Y}\right)\ .\]
 Una funzione a due variabili $f(x,y)$ è detta bilineare se, fissato
il secondo (primo)\ argomento risulta essere lineare nel primo (secondo).
In pratica deve valere che 
\begin{enumerate}
\item Per qualsiasi $x_{1},x_{2}\in\mathbb{R}$ e $y\in\mathbb{R}$ vale
che\begin{equation}
f(x_{1}+x_{2},y)=f(x_{1},y)+f(x_{2},y),\end{equation}



Per qualsiasi $\lambda,x\in\mathbb{R}$ e $y\in\mathbb{R}$ vale che
\begin{equation}
f(\lambda x,y)=\lambda f(x,y).\end{equation}


\item Per qualsiasi $y_{1},y_{2}\in\mathbb{R}$ e $x\in\mathbb{R}$ vale
che\begin{equation}
f(x,y_{1}+y_{2})=f(x,y_{1})+f(x,y_{2}),\end{equation}



Per qualsiasi $\lambda,y\in\mathbb{R}$ e $x\in\mathbb{R}$ vale che
\begin{equation}
f(x,\lambda y)=\lambda f(x,y).\end{equation}


\end{enumerate}
\begin{esempio} La funzione $f(x,y)=xy$ è bilineare. La dimostrazione
è lasciata come esercizio. \end{esempio}

\noindent Ora, si può dimostrare (si veda l'appendice) che la covarianza
è un operatore bilineare. Da ciò risulta che la covarianza si comporta
in maniera simile al valore atteso quando noi \textquotedbl{}fissiamo\textquotedbl{}
uno dei due argomenti. Ad esempio, supponiamo di voler calcolare $Cov\left(2X_{1}-3X_{2}+X_{3},Y_{1}-2Y_{2}\right)$.
Partiamo considerando \textquotedbl{}fisso\textquotedbl{} il secondo
argomento che in questo caso è dato da $Y_{1}-2Y_{2}$. Per semplicità
chiamiamo $Z=Y_{1}-2Y_{2}$ l'argomento fisso.\begin{eqnarray*}
Cov\left(2X_{1}-3X_{2}+X_{3},Z\right) & = & Cov\left(2X_{1},Z\right)+Cov\left(-3X_{2},Z\right)+Cov\left(X_{3},Z\right)\\
 & = & 2Cov\left(X_{1},Z\right)-3Cov\left(X_{2},Z\right)+Cov\left(X_{3},Z\right)\end{eqnarray*}
 Grazie alla bilinearità della covarianza possiamo ora sviluppare
ciascuno dei tre termini rispetto al secondo argomento, $Z$, che
riscriviamo nuovamente in funzione di $Y_{1}$ e $Y_{2}$:\begin{eqnarray*}
Cov\left(X_{1},Y_{1}-2Y_{2}\right) & = & Cov\left(X_{1},Y_{1}\right)+Cov\left(X_{1},-2Y_{2}\right)\\
 & = & Cov\left(X_{1},Y_{1}\right)-2Cov\left(X_{1},Y_{2}\right)\ ,\end{eqnarray*}
 \begin{eqnarray*}
Cov\left(X_{2},Y_{1}-2Y_{2}\right) & = & Cov\left(X_{2},Y_{1}\right)+Cov\left(X_{2},-2Y_{2}\right)\\
 & = & Cov\left(X_{2},Y_{1}\right)-2Cov\left(X_{2},Y_{2}\right)\ ,\end{eqnarray*}
 \begin{eqnarray*}
Cov\left(X_{3},Y_{1}-2Y_{2}\right) & = & Cov\left(X_{3},Y_{1}\right)+Cov\left(X_{3},-2Y_{2}\right)\\
 & = & Cov\left(X_{3},Y_{1}\right)-2Cov\left(X_{3},Y_{2}\right)\end{eqnarray*}
 Quale risultato finale otteniamo la seguente espressione\begin{eqnarray*}
Cov\left(2X_{1}-3X_{2}+X_{3},Y_{1}-2Y_{2}\right) & = & 2Cov\left(X_{1},Y_{1}\right)-4Cov\left(X_{1},Y_{2}\right)\\
 &  & -3Cov\left(X_{2},Y_{1}\right)+6Cov\left(X_{2},Y_{2}\right)\\
 &  & +Cov\left(X_{3},Y_{1}\right)-2Cov\left(X_{3},Y_{2}\right)\\
 & = & 2c_{11}-4c_{12}-3c_{21}+6c_{22}+c_{31}-2c_{32}.\end{eqnarray*}
 Come potete vedere il calcolo della covarianza fra somme di variabili
aleatorie è semplice ma laborioso. È tuttavia possibile aiutarsi utilizzando
una tabella che ricorda la battaglia navale. La tabella consiste in
$n$ righe e $m$ colonne, dove $n$ è il numero di $V.A.$ che figurano
nella sommatoria della $X$ (primo argomento)\ e $m$ in numero di
quelle della $Y$ (secondo argomento). All'esempio precedente possiamo
associare una tabella $3\times2$ come questa:\[
\begin{tabular}{l|cc}
  &  \ensuremath{Y_{1}} &  \ensuremath{Y_{2}}\\
\hline \ensuremath{X_{1}} &  \ensuremath{c_{11}} &  \ensuremath{c_{12}}\\
\ensuremath{X_{2}} &  \ensuremath{c_{21}} &  \ensuremath{c_{22}}\\
\ensuremath{X_{3}} &  \ensuremath{c_{31}} &  \ensuremath{c_{32}}\end{tabular}\]
 Questa tabella è anche chiamata tabella (o matrice) delle covarianze
fra $X_{1},X_{2},X_{3}$ e $Y_{1},Y_{2}$. Per il calcolo della covarianza
aggiungiamo dapprima i coefficienti della somma pesata (combinazione
lineare) davanti ad ogni variabile \[
\begin{tabular}{l|cc}
  &  \ensuremath{1Y_{1}} &  \ensuremath{-2Y_{2}}\\
\hline \multicolumn{1}{r|}{\ensuremath{2X_{1}}}  &  \ensuremath{c_{11}} &  \ensuremath{c_{12}}\\
\multicolumn{1}{r|}{\ensuremath{-3X_{2}}}  &  \ensuremath{c_{21}} &  \ensuremath{c_{22}}\\
\multicolumn{1}{r|}{\ensuremath{1X_{3}}}  &  \ensuremath{c_{31}} &  \ensuremath{c_{32}}\end{tabular}\]
 ed in seguito all'interno della tabella:\[
\begin{tabular}{l|cc}
  &  \ensuremath{1Y_{1}} &  \ensuremath{-2Y_{2}}\\
\hline \multicolumn{1}{r|}{\ensuremath{2X_{1}}}  &  \multicolumn{1}{|r}{\ensuremath{2\cdot1\cdot c_{11}}}  &  \multicolumn{1}{r}{\ensuremath{2\cdot(-2)\cdot c_{12}}} \\
\multicolumn{1}{r|}{\ensuremath{-3X_{2}}}  &  \multicolumn{1}{|r}{\ensuremath{\left(-3\right)\cdot1\cdot c_{21}}}  &  \multicolumn{1}{r}{\ensuremath{\left(-3\right)\cdot(-2)\cdot c_{22}}} \\
\multicolumn{1}{r|}{\ensuremath{1X_{3}}}  &  \multicolumn{1}{|r}{\ensuremath{1\cdot1\cdot c_{31}}}  &  \multicolumn{1}{r}{\ensuremath{1\cdot(-2)\cdot c_{32}}}\end{tabular}\]
 Per terminare sommiamo tutti i termini della tabella ottenendo così
la covarianza fra le due somme di $V.A.$:\[
Cov\left(2X_{1}-3X_{2}+X_{3},Y_{1}-2Y_{2}\right)=2c_{11}-4c_{12}-3c_{21}+6c_{22}+c_{31}-2c_{32}.\]
 Per completezza d'informazione diamo la formula generale per il calcolo
della covarianza fra due combinazioni lineari qualsiasi di $V.A.$:\[
Cov(\sum_{i=1}^{n}a_{i}X_{i},\sum_{j=1}^{m}b_{j}Y_{j})=\sum_{i=1}^{n}\sum_{j=1}^{m}a_{i}b_{j}Cov(X_{i},Y_{j})\ .\]



\subsection{Varianza di una somma di variabili aleatorie}

La varianza di una somma di variabili aleatorie, ad esempio\[
V\left(2X_{1}-3X_{2}+X_{3}\right)\ ,\]
 si calcola in maniera del tutto simile alla covarianza fra somme
di $V.A.$. È infatti immediato verificare che per una qualsiasi $V.A.$
$X$\[
V\left(X\right)=E\left[\left(X-E(X)\right)^{2}\right]=E\left[\left(X-E(X)\right)\left(X-E(X)\right)\right]=Cov(X,X)\text{.}\]
 Da quest'ultima osservazione notiamo che la varianza di una somma
pesata di $V.A.$ altro non è che la somma debitamente pesata della
varianze di e delle covarianze fra le $V.A.$ che costituiscono la
trasformazione lineare.

\begin{esempio} Varianza di $2X_{1}-3X_{2}+X_{3}$

Costruiamo la tabella delle covarianze fra $X_{1},X_{2},X_{3}$ e
\ldots{}\ $X_{1},X_{2},X_{3}$:\[
\begin{tabular}{l|ccc}
  &  \ensuremath{X_{1}} &  \ensuremath{X_{2}} &  \ensuremath{X_{3}}\\
\hline \multicolumn{1}{r|}{\ensuremath{X_{1}}}  &  \multicolumn{1}{|r}{\ensuremath{c_{11}}}  &  \multicolumn{1}{r}{\ensuremath{c_{12}}}  &  \multicolumn{1}{r}{\ensuremath{c_{13}}} \\
\multicolumn{1}{r|}{\ensuremath{X_{2}}}  &  \multicolumn{1}{|r}{\ensuremath{c_{21}}}  &  \multicolumn{1}{r}{\ensuremath{c_{22}}}  &  \multicolumn{1}{r}{\ensuremath{c_{23}}} \\
\multicolumn{1}{r|}{\ensuremath{X_{3}}}  &  \multicolumn{1}{|r}{\ensuremath{c_{31}}}  &  \multicolumn{1}{r}{\ensuremath{c_{32}}}  &  \multicolumn{1}{r}{\ensuremath{c_{33}}}\end{tabular}\]
 Notiamo dapprima che la tabella delle covarianze ha in questo caso
lo stesso numero di righe e di colonne. Inoltre, sulla diagonale principale
(cioè in posizione $(1,1)$, $(2,2)$ e $(3,3)$) abbiamo i termini
$c_{ii}$ che corrispondono a $Cov(X_{i},X_{i})=V(X_{i})$. Queste
covarianze non sono altro che le varianze degli $X_{i}$! Per tale
motivo questa tabella è chiamata la tabella (o matrice) delle \emph{varianze-covarianze}
delle $V.A.$ $X_{1},X_{2},X_{3}$. Fuori dalla diagonale troviamo
le covarianze fra $X_{i}$ e $X_{j}$, con $i\neq j$. Poiché (verificatelo
dalla definizione e dalla proprietà di commutatività della moltiplicazione)
$Cov(X_{i},X_{j})=Cov(X_{j},X_{i})$ la tabella delle varianze-covarianze
è \emph{simmetrica}, cioè vale\[
c_{ij}=c_{ji}.\]
 Per il calcolo della varianza procediamo come per il calcolo della
covarianza fra somme di $V.A.$, andando ad aggiungere alla tabella
(matrice) delle varianze-covarianze i coefficienti della trasformazione
lineare (somma pesata)\[
\begin{tabular}{l|ccc}
  &  \ensuremath{2X_{1}} &  \ensuremath{-3X_{2}} &  \ensuremath{1X_{3}}\\
\hline \multicolumn{1}{r|}{\ensuremath{2X_{1}}}  &  \multicolumn{1}{|r}{\ensuremath{2^{2}\cdot c_{11}}}  &  \multicolumn{1}{r}{\ensuremath{2\cdot(-3)\cdot c_{12}}}  &  \multicolumn{1}{r}{\ensuremath{2\cdot1\cdot c_{13}}} \\
\multicolumn{1}{r|}{\ensuremath{-3X_{2}}}  &  \multicolumn{1}{|r}{\ensuremath{(-3)\cdot2\cdot c_{21}}}  &  \multicolumn{1}{r}{\ensuremath{(-3)^{2}\cdot c_{22}}}  &  \multicolumn{1}{r}{\ensuremath{\left(-3\right)\cdot1\cdot c_{23}}} \\
\multicolumn{1}{r|}{\ensuremath{1X_{3}}}  &  \multicolumn{1}{|r}{\ensuremath{1\cdot2\cdot c_{31}}}  &  \multicolumn{1}{r}{\ensuremath{1\cdot(-3)\cdot c_{32}}}  &  \multicolumn{1}{r}{\ensuremath{1^{2}\cdot c_{33}}}\end{tabular}\]
 Le varianze sono moltiplicate per il quadrato del coefficiente della
trasformazione lineare. Fuori dalla diagonale troviamo le covarianze
fra le rispettive $V.A.$ moltiplicate per i pesi corrispondenti.
La varianza di questa trasformazione lineare è uguale alla somma di
tutti gli elementi della tabella, ovvero\begin{eqnarray}
V(2X_{1}-3X_{2}+X_{3}) & = & 4c_{11}+9c_{22}+c_{33}+\label{varianza di una somma 1}\\
 &  & -6c_{12}+2c_{13}+\notag\\
 &  & -6c_{21}-3c_{23}+\notag\\
 &  & +2c_{13}-3c_{32}\notag\end{eqnarray}
 Infine, grazie alla simmetria della matrice delle varianze-covarianze
($c_{ij}=c_{ji}$) la (\ref{varianza di una somma 1}) può essere
riscritta come \begin{eqnarray}
V(2X_{1}-3X_{2}+X_{3}) & = & 4c_{11}+9c_{22}+c_{33}+\\
 &  & -12c_{12}+4c_{13}-6c_{23}\notag\end{eqnarray}
 \end{esempio}

\noindent In generale, data una qualsiasi trasformazione lineare delle
$n$ $V.A.$ $X_{1},\ldots,X_{n}$ la varianza è calcolata tramite
la seguente formula\begin{eqnarray}
V\left(\sum_{i=1}^{n}a_{i}X_{i}\right) & = & \sum_{i=1}^{n}\sum_{j=1}^{n}a_{i}a_{j}Cov(X_{i},X_{j})\label{formula varianza di comb lineare}\\
 & = & \sum_{i=1}^{n}a_{i}^{2}V(X_{i})+\underset{i\neq j}{\sum_{i=1}^{n}\sum_{j=1}^{n}}a_{i}a_{j}Cov(X_{i},X_{j})\notag\\
 & = & \sum_{i=1}^{n}a_{i}^{2}V(X_{i})+2\underset{i>j}{\sum_{i=1}^{n}\sum_{j=1}^{n}}a_{i}a_{j}Cov(X_{i},X_{j})\ .\notag\end{eqnarray}
 Caso particolare: variabili non correlate

\noindent Quando le $V.A.$ $X_{1},\ldots,X_{n}$ sono non correlate,
cioè\[
Cov(X_{i},X_{j})=0\ \text{per }i\neq j\]
 la formula (\ref{formula varianza di comb lineare}) per il calcolo
della varianza di una combinazione lineare di $V.A.$ si semplifica
notevolmente in \begin{equation}
V\left(\sum_{i=1}^{n}a_{i}X_{i}\right)=\sum_{i=1}^{n}a_{i}^{2}V\left(X_{i}\right)\text{.}\end{equation}
 In pratica, nel caso di variabili non correlate, la varianza di una
somma è la somma delle varianze pesate per il \emph{quadrato} dei
coefficienti della combinazione lineare. Ricordate che la varianza
è il valore atteso \textquotedbl{}di un quadrato\textquotedbl{}:
per tale motivo i coefficienti sono al quadrato!


\section{Il campionamento casuale semplice}

Consideriamo una popolazione di numerosità $N$. Chiameremo campione
casuale semplice un campione di numerosità $n$ dove ciascuna unità
possiede, \emph{ad ogni passo}, una probabilità pari a $1/N$ di essere
estratta.

\begin{esercizio} Mostrate che entrambe le tecniche di campionamento
con e senza reinserimento soddisfano la condizione imposta dalla definizione
di campione casuale semplice. Suggerimento:\ per quanto riguarda
la selezione senza reinserimento, aiutatevi utilizzando la proprietà
condizionata. \end{esercizio}

\noindent È dunque possibile ottenere un campione casuale semplice
applicando una delle due tecniche di selezione casuale con o senza
reinserimento viste in precedenza. $``$Il campionamento casuale semplice
è raramente applicato nelle indagini statistiche, sia perché la selezione
è completamente affidata al caso e non incorpora le informazione note
a priori sulla popolazione o sulle caratteristiche distributive delle
variabili, sia perché nelle indagini su vasta scala è pesante quanto
a costi di relevazione dei dati e a organizzazione del lavoro{}``sul
campo\textquotedblright{}\ ... Il campionamento casuale semplice
è invece quello che si assume nella teoria dell'inferenza statistica
quando non è precisato il disegno adottato. Per questo tipo di campionamento
sono, infatti proposte \emph{metodiche} di \emph{stima} e di \emph{verifica}
della significatività statistica di ipotesi sui più disparati parametri
delle distribuzioni, anche multivariate, di indici di relazione tra
variabili, di dati organizzati in serie temporali ecc.\textquotedblright{}\ (Fabbris,
pp. 53-54). Il campionamento casuale semplice è lo standard verso
il quale confrontare gli altri tipi di campionamento. Per tale motivo
sarà quello da noi maggiormente trattato.


\subsection{Valore atteso e varianza della media campionaria}

In questo e nei prossimi paragrafi desideriamo studiare le proprietà
di correttezza e di \textquotedbl{}precisione\textquotedbl{} della
media campionaria $\overline{X}_{n}$ quale stimatore del valore medio
$\mu$ della popolazione. In questo caso scalziamo dal trono la distribuzione
statistica $P_{p}$ della popolazione campione quale principale oggetto
di studio. Con modestia ci accontentiamo di stimare il valore medio
$\mu$ della popolazione. Supponiamo quindi che la popolazione sia
composta da $N$ unità. Denotiamo con $a_{i}$ il valore della caratteristica
studiata dell'$i$-esima unità. Ad esempio, se decidessimo di studiare
la distribuzione del reddito della popolazione svizzera $a_{i}$ rappresenterebbe
il reddito dell'$i$-esimo individuo alla data in cui è eseguito lo
studio. Il parametro sconosciuto da stimare è dunque uguale a \[
\mu=\sum_{i=1}^{N}a_{i}\frac{1}{N}\]
 mentre la varianza della distribuzione del reddito è\[
\sigma^{2}=\sum_{i=1}^{N}\left(a_{i}-\mu\right)^{2}\frac{1}{N}\ .\]
 $\mu$ e $\sigma^{2}$ sono quantità che potrebbero essere calcolate
se avessimo a disposizione i dati sull'intera popolazione. In realtà
entrambe queste quantità sono sconosciute e pertanto dovranno essere
stimate. Poiché non desideriamo stimare la distribuzione della popolazione
ma solo il primo momento (valore atteso o valore medio) e la varianza
per questa volta eviteremo di specificare una famiglia parametrica
di distribuzioni.

\begin{definizione} Frazione di campionamento. Chiameremo la quantità
\begin{equation}
f:=\frac{n}{N}\label{frazione campionamento}\end{equation}
 frazione di campionamento. Essa indica semplicemente la \% di unità
estratte rispetto al totale della popolazione. \end{definizione}

\noindent Ci interessiamo ora alla media del campione quale stimatore
di $\mu$.


\subsubsection{Campionamento con reinserimento\label{camp con reins}}

Supponiamo di estrarre un campione di numerosità $n$ utilizzando
la tecnica di selezione con reinserimento. Indichiamo con $X_{1},X_{2},\ldots X_{n}$
le $n$ variabili aleatorie indipendenti ed identicamente distribuite
che descrivono il risultato della prima, seconda, ... $n$-esima estrazione.
È immediato verificare%
\footnote{Potete verificare applicando le proprietà della sommatoria che $V(X_{i})$
è anche uguale a \[
\sum_{j=1}^{N}a_{j}^{2}\frac{1}{N}-\mu^{2}\]
 che corrisponde alla formula alternativa (\ref{definizione alternativa varianza})
della varianza data da\[
V(X_{i})=E(X_{i}^{2})-\left(E(X_{i})\right)^{2}\text{.}\]
 %
} che per un qualsiasi $i\in(1,\ldots,n)$ \[
E(X_{i})=\sum_{j=1}^{N}a_{j}\frac{1}{N}=\mu\]
 e \[
V(X_{i})=E\left(\left(X_{i}-\mu\right)^{2}\right)=\sum_{j=1}^{N}\left(a_{j}-\mu\right)^{2}\frac{1}{N}=\sigma^{2}\text{.}\]
 Per quanto riguarda la media campionaria $\overline{X}_{n}=\frac{1}{n}\sum_{i=1}^{n}X_{i}$
avremo quindi \begin{eqnarray}
E(\overline{X}_{n}) & = & E\left(\frac{1}{n}\sum_{i=1}^{n}X_{i}\right)=\frac{1}{n}\sum_{i=1}^{n}E\left(X_{i}\right)=\mu\notag\\
V(\overline{X}_{n}) & = & V\left(\frac{1}{n}\sum_{i=1}^{n}X_{i}\right)=\frac{1}{n^{2}}V\left(\sum_{i=1}^{n}X_{i}\right)\notag\\
 & = & \frac{1}{n^{2}}\sum_{i=1}^{n}V\left(X_{i}\right)=\frac{\sigma^{2}}{n}.\label{varianza media con reimmissione}\end{eqnarray}
 La media campionaria è uno stimatore corretto del valore atteso della
popolazione. La sua precisione, valutata utilizzando la varianza quale
misura di dispersione, dipende da due fattori. 
\begin{enumerate}
\item La numerosità del campione: la varianza della media $\overline{X}_{n}$
decresce in maniera inversamente proporzionale al numero di osservazioni
nel campione. 
\item La varianza della popolazione: il recercatore non ha alcun influsso
su questo parametro. 
\end{enumerate}
\bigskip{}


Da ultimo sottolineamo ancora che $\overline{X}_{n}$ è una variabile
aleatoria la cui distribuzione dipende indirettamente dalla distribuzione
della popolazione campione. Purtroppo vale la seguente osservazione.
Anche quando la distribuzione della popolazione obiettivo è conosciuta
la forma della distribuzione della media $\overline{X}_{n}$ non è
derivabile analiticamente. Ci sono però delle eccezioni. Una fra queste
è la distribuzione normale. Infatti, se le variabili aleatorie $X_{1},...,X_{n}$
sono $i.i.d.$ e distribuite secondo la legge normale $N(\mu,\sigma^{2})$,
allora anche la loro media è una variabile aleatoria normale.

\begin{esercizio} simulazione e studio dei risultati \end{esercizio}


\subsubsection{Campionamento senza reinserimento}

In questo caso l'estrazione degli $n$ individui dalla popolazione
avviene utilizzando la tecnica di selezione senza reinserimento. Da
un punto di vista teorico il campionamento senza reinserimento appare
giustificato dal fatto che l'osservazione ripetuta dello stesso individuo
(unità) non aumenta l'informazione disponibile sull'intera popolazione.
Appare quindi sensato togliere dall'urna gli individui già osservati
e procedere solo con la parte restante della popolazione. Vedremo
che tale intuizione è corretta: la media di un campione estratto con
la tecnica di selezione senza reinserimento possiede una varianza
inferiore alla media di un campione estratto con reinserimento%
\footnote{Il prezzo da pagare consiste in una maggiore difficoltà nel calcolo
di $V(\overline{X}_{n}).$%
}. Come in precedenza abbiamo che \begin{equation}
\overline{X}_{n}=\frac{1}{n}\sum_{i=1}^{n}X_{i}\text{.}\label{def media x}\end{equation}
 Le variabili $X_{i}$ sono ora definite nel seguente modo:\begin{equation}
X_{i}=\sum_{j=1}^{N}a_{j}U_{ij}\label{x funzione di u}\end{equation}
 dove la variabile aleatoria \[
U_{ij}=\left\{ \begin{array}{ll}
1 & \text{se lo }j\text{-esimo individuo è estratto alla }i\text{-esima estrazione,}\\
0 & \text{altrimenti.}\end{array}\right.\]


\begin{esercizio} Per $N=5$ e $n=3$ è dato lo spazio di probabilità
$\left(\Omega^{3},\overset{3}{\underset{i=1}{\otimes}}\mathcal{E}_{i},Q\right)$
sul quale definiamo le variabili aleatorie $U_{13}$, $U_{21}$ e
$U_{35}.$

\noindent 1) Definite a parole le tre variabili $U_{13}$, $U_{21}$
e $U_{35}.$

\noindent 2) Sono dati gli esiti $\omega_{1}=(1,2,5)$, $\omega_{2}=(5,2,1)$
e $\omega_{3}=(1,1,1)$. Calcolate per ciascuna delle tre variabili
$U$ il valore che esse assumono in $\omega_{i}$, $i=1,2,3.$ \end{esercizio}

Possiamo riassumere il tutto nella seguente tabella\[
\begin{tabular}{ccccccccc}
  &   &  Indiv. \ensuremath{1} &   &  Indiv. \ensuremath{2} &   &   &   &  Indiv. \ensuremath{N}\\
\ensuremath{X_{1}} &  \ensuremath{=} &  \ensuremath{a_{1}U_{11}} &  \ensuremath{+} &  \ensuremath{a_{2}U_{12}} &  \ensuremath{+} &  \ensuremath{\ldots} &  \ensuremath{+} &  \ensuremath{a_{N}U_{1N}}\\
\ensuremath{X_{2}} &  \ensuremath{=} &  \ensuremath{a_{1}U_{21}} &  \ensuremath{+} &  \ensuremath{a_{2}U_{22}} &  \ensuremath{+} &   &  \ensuremath{+} &  \ensuremath{a_{N}U_{2N}}\\
\ensuremath{\vdots} &   &   &   &   &   &   &   &  \ensuremath{\vdots}\\
\ensuremath{X_{n}} &  \ensuremath{=} &  \ensuremath{a_{1}U_{n1}} &  \ensuremath{+} &  \ensuremath{a_{2}U_{n2}} &  \ensuremath{+} &   &  \ensuremath{+} &  \ensuremath{a_{N}U_{nN}}\\
\hline \ensuremath{\sum_{i=1}^{n}X_{i}} &  \ensuremath{=} &  \ensuremath{a_{1}\underset{T_{1}}{\underbrace{\sum_{i=1}^{n}U_{i1}}}} &  \ensuremath{+} &  \ensuremath{a_{2}\underset{T_{2}}{\underbrace{\sum_{i=1}^{n}U_{i2}}}} &  \ensuremath{+} &  \ensuremath{\ldots} &  \ensuremath{+} &  \ensuremath{a_{N}\underset{T_{N}}{\underbrace{\sum_{i=1}^{n}U_{iN}}}}\end{tabular}\]
 Questa tabella possiede più colonne che righe ($n\leq N$: non posso
estrare più di $N$ individui). Le $N$ variabili aleatorie $T_{j}$
sono la somma rispetto al numero di estrazioni $(i)$ delle variabili
$U_{ij}$. In pratica $T_{j}$ assumerà il valore $1$ o $0$ a seconda
che lo $j$-esimo individuo sia stato sorteggiato o meno.

\bigskip{}


\noindent Inserendo la relazione (\ref{x funzione di u}) nella (\ref{def media x})
possiamo riscrivere la media come una somma pesata delle $V.A.$ $T_{j}$:\begin{eqnarray}
\overline{X}_{n} & = & \frac{1}{n}\sum_{i=1}^{n}X_{i}=\frac{1}{n}\sum_{i=1}^{n}\sum_{j=1}^{N}a_{j}U_{ij}=\frac{1}{n}\sum_{j=1}^{N}\sum_{i=1}^{n}a_{j}U_{ij}\notag\\
 & = & \frac{1}{n}\sum_{j=1}^{N}a_{j}\sum_{i=1}^{n}U_{ij}=\frac{1}{n}\sum_{j=1}^{N}a_{j}T_{j}.\label{x medio come somma pesata dei T}\end{eqnarray}
 A questo punto è necessario calcolare valore atteso, varianza di
- e covarianza fra - variabili aleatorie $T_{j}$.

\bigskip{}


\noindent Per quanto riguarda il valore atteso di $T_{j}$ abbiamo\[
E(T_{j})=0\ P(T_{j}=0)+1\ P(T_{j}=1)=P(T_{j}=1)\]
 $P(T_{j}=1)$ è la probabilità che sull'arco delle $n$ estrazioni
lo $j$-esimo individuo venga sorteggiato. Poiché gli esiti sono tutti
equiprobabili, è possibile calcolare $P(T_{j}=1)$ semplicemente come\[
P(T_{i}=1)=\frac{\#\text{ esiti favorevoli}}{\#\text{ esiti possibili}}\text{.}\]
 Il numero di esiti possibili è già stato calcolato in precedenza
ed è uguale a\[
D_{N}^{n}=\frac{N!}{(N-n)!}\text{.}\]
 Il numero degli esiti favorevoli è uguale al numero di esiti con
probabilità positiva%
\footnote{Ricordiamo che gli elementi $\omega$ di $\Omega^{n}$ in cui un numero
si ripete più volte non vanno tenuti in considerazione in quanto non
si realizzeranno mai (estrazione senza ripetizione!).%
} contenenti il numero $j$. Tale numero è la risposta alla seguente
domanda: in quanti modo posso disporre gli $N$ numeri $1,...,N$
in $n$ scatole, sapendo che una scatola sarà occupata dal numero
$j$? Abbiamo $n$ possibilità per disporre il numero $j$ nelle $n$
scatole e successivamente resteranno $n-1$ scatole libere che dovranno
essere riempite scegliendo da $N-1$ elementi. Il risultato è dunque
\[
\frac{n\ \left(N-1\right)!}{(N-1-(n-1))!}.\]
 Otteniamo così \begin{equation}
P(T_{j}=1)=\frac{\frac{n\ \left(N-1\right)!}{(N-1-(n-1))!}}{\frac{N!}{(N-n)!}}=\frac{n}{N}.\label{probabilita inserimento nel campione con reimm}\end{equation}


\noindent Per quanto riguarda la varianza di $T_{j}$, essa è uguale
a \[
V(T_{j})=E(T_{j}^{2})-(E(T_{j}))^{2}=\frac{n}{N}-\left(\frac{n}{N}\right)^{2}=\frac{n(N-n)}{N^{2}}\text{.}\]
 La covarianza fra $T_{j}$ e $T_{k}$ è invece uguale a\begin{eqnarray}
Cov(T_{j},T_{k}) & = & E(T_{j}T_{k})-E(T_{j})E(T_{k})\label{covarianza T1 T2 tmp}\\
 & = & E(T_{j}T_{k})-\left(\frac{n}{N}\right)^{2}.\notag\end{eqnarray}
 Quanto vale $E(T_{j}T_{k})$? Il prodotto $T_{j}T_{k}$ è sempre
uguale a $0$ salvo quando entrambi gli individui $j$ e $k$ figurano
nel campione. In tal caso $T_{j}T_{k}=1.$ Quindi\begin{eqnarray*}
E(T_{j}T_{k}) & = & 0P(T_{j}=0,T_{k}=0)+0P(T_{j}=1,T_{k}=0)\\
 & + & 0P(T_{j}=0,T_{k}=1)+1P(T_{j}=1,T_{k}=1)\\
 & = & P(T_{j}=1,T_{k}=1)\end{eqnarray*}
 Per calcolare $P(T_{j}=1,T_{k}=1)$ utilizziamo nuovamente la combinatoria: 
\begin{enumerate}
\item Esiti favorevoli


Degli $n$ posti $2$ sono occupati: uno dall' individuo $j$ e l'altro
dall'individuo $k$. Abbiamo $n(n-1)$ modi per disporre i nostri
due individui nelle $n$ scatole. Rimangono $n-2$ posti liberi che
possono essere riempiti dagli altri $N-2$ individui. Abbiamo quindi\[
\#\text{ esiti favorevoli}=n(n-1)D_{N-2}^{n-2}\ .\]


\item Esiti possibili (calcolati in precedenza)$\frac{N!}{(N-n)!}\ .$ 
\end{enumerate}
\noindent Abbiamo quindi

\[
P(T_{j}=1,T_{k}=1)=\frac{n(n-1)\frac{(N-2)!}{(N-2-(n-2))!}}{\frac{N!}{(N-n)!}}=\frac{n(n-1)}{N(N-1)}\text{.}\]
 Inserendo quest'ultimo risultato nella (\ref{covarianza T1 T2 tmp})
otteniamo (si noti il segno dell'espressione finale) \begin{equation}
Cov(T_{j},T_{k})=\frac{n(n-1)}{N(N-1)}-\left(\frac{n}{N}\right)^{2}=-\frac{n(N-n)}{N^{2}(N-1)}.\notag\end{equation}
 Siamo ora pronti a calcolare il valore atteso e la varianza di $\overline{X}_{n}$.


\paragraph{Il valore atteso di $\overline{X}_{n}$}

\begin{eqnarray*}
E(\overline{X}_{n}) & = & E\left(\frac{1}{n}\sum_{j=1}^{N}a_{j}T_{j}\right)=\frac{1}{n}\sum_{j=1}^{N}a_{j}E\left(T_{j}\right)\\
 & = & \frac{1}{n}\sum_{j=1}^{N}a_{j}\frac{n}{N}=\frac{1}{N}\sum_{j=1}^{N}a_{j}=\mu\text{.}\end{eqnarray*}
 Quando il campionamento è effettuato senza reinserimento la media
campionaria è uno stimatore corretto del valore atteso della popolazione.
Questo risultato è\ identico a quello ottenuto nel caso di campionamento
con reinserimento. Sarà dunque interessante confrontare le varianze
della media campionaria nei due casi per vedere quale delle due tecniche
di campionamento fornisce i risultati migliori in termini di precisione.


\paragraph{La varianza di $\overline{X}_{n}$}

Dall'equazione (\ref{x medio come somma pesata dei T}) otteniamo
che\begin{eqnarray*}
V(\overline{X}_{n}) & = & V(\frac{1}{n}\sum_{j=1}^{N}a_{j}T_{j})=\frac{1}{n^{2}}V(\sum_{j=1}^{N}a_{j}T_{j})\\
 & = & \frac{1}{n^{2}}\sum_{j=1}^{N}\sum_{s=1}^{N}a_{j}a_{s}Cov(T_{j},T_{s})\\
 & = & \frac{1}{n^{2}}\left(\sum_{j=1}^{N}a_{j}^{2}V(T_{j})+\underset{j\neq s}{\sum_{j=1}^{N}\sum_{s=1}^{N}}a_{j}a_{s}Cov(T_{j},T_{s})\right).\end{eqnarray*}
 Utilizzando i risultati sulla varianza e covarianza delle $V.A.$
$T_{j}$ \begin{eqnarray}
V(\overline{X}_{n}) & = & \frac{1}{n^{2}}\left(\frac{n(N-n)}{N^{2}}\sum_{j=1}^{N}a_{j}^{2}-\frac{n(N-n)}{N^{2}(N-1)}\underset{j\neq s}{\sum_{j=1}^{N}\sum_{s=1}^{N}}a_{j}a_{s}\right)\notag\\
 & = & \frac{1}{n^{2}}\frac{n(N-n)}{N^{2}(N-1)}\left((N-1)\sum_{ij=1}^{N}a_{j}^{2}-\underset{j\neq s}{\sum_{j=1}^{N}\sum_{s=1}^{N}}a_{j}a_{s}\right)\notag\end{eqnarray}
 \begin{eqnarray}
 & = & \frac{1}{n}\frac{N-n}{N^{2}(N-1)}\left(N\sum_{j=1}^{N}a_{j}^{2}-\sum_{j=1}^{N}\sum_{s=1}^{N}a_{j}a_{s}\right)\notag\\
 & = & \frac{1}{n}\frac{N-n}{N^{2}(N-1)}\left(N\sum_{j=1}^{N}a_{j}^{2}-\left(\sum_{j=1}^{N}a_{i}\right)\left(\sum_{s=1}^{N}a_{s}\right)\right)\notag\\
 & = & \frac{1}{n}\frac{N-n}{N-1}\left(\frac{1}{N}\sum_{j=1}^{N}a_{j}^{2}-\mu^{2}\right)\label{equazione d'esempio}\end{eqnarray}
 Ma $\sum_{ij=1}^{N}a_{j}^{2}\frac{1}{N}-\mu^{2}$ è la formula alternativa
della varianza della popolazione. Per tale motivo otteniamo quale
risultato finale\begin{equation}
V(\overline{X}_{n})=\frac{N-n}{N-1}\frac{\sigma^{2}}{n}.\label{varianza media senza reimmissione}\end{equation}
 Confrontando le due formule (\ref{varianza media con reimmissione})
e (\ref{varianza media senza reimmissione}) ottenute per la varianza
dello stimatore $\overline{X}_{n}$ notiamo che il campionamento senza
reinserimento è più efficiente. Infatti la quantità $\frac{N-n}{N-1}$
è sempre minore di uno salvo nel caso particolare (in pratica non
rilevante) in cui $n=1$. Questo risultato conferma la nostra intuizione
riguardo all'inutilità di reinserire l'unità osservata al fine di
acquisire informazioni sulla popolazione. In questo caso la tecnica
di reinserimento si rivela persino \textquotedbl{}dannosa\textquotedbl{}
in termini della varianza di $\overline{X}_{n}$.


\subsubsection{Campionamento sistematico}

\noindent Supponiamo che il campione di numerosità $n$ sia stato
scelto utilizzando la tecnica di selezione sistematica (si veda il
paragrafo \ref{selezione sistematica}) e per semplicità che $k=\frac{N}{n}$
sia un numero intero. Ricordiamo che $k$ corrisponde al numero di
gruppi in cui l'intera popolazione è partizionata. La probabilità
di includere un particolare individuo nel campione è uguale alla probabilità
di selezionare il suo gruppo d'appartenenza:\ poiché in totale ci
sono $k$ gruppi ed ogni individuo appartiene ad esattamente un solo
gruppo tale probabilità è $\frac{1}{k}$. Tutti gli individui hanno
la medesima probabilità di essere estratti. Tale probabilità è però
diversa da $\frac{1}{n}$ a meno che la numerosità $N$ della popolazione
non sia tale per cui $N=n^{2}$. La media campionaria $\overline{X}_{n}$
è come al solito uguale alla somma dei redditi degli individui selezionati
divisa per $n$, il numero di individui selezionati. Tuttavia, mentre
nei casi della tecnica di selezione con e senza reinserimento avevamo
potuto definire le variabili aleatorie $X_{i}$ come il reddito dell'individuo
estratto all'$i$-esima estrazione, ora ci troviamo di fronte ad un'unica
estrazione in cui tutti gli $n$ individui sono estratti simultaneamente.
In pratica è come se estraessimo in un unico colpo la somma $\sum_{i=1}^{n}X_{i}$
che, nel caso del campionamento sistematico, corrisponde alla somma
dei redditi degli $n$ individui appartenenti al gruppo selezionato.
Definiamo per ciascun gruppo $i\in\left(1,...,k\right)$ la quantità\[
g_{i}=\sum_{j=1}^{n}a_{ij}\]
 dove $a_{ij}$ corrisponde per definizione alla $j$-esima persona
dell' $i$-esimo gruppo. Le quantità $g_{i}$ non sono aleatorie ma
\emph{sono dei numeri }in quanto il partizionamento della popolazione
in $k$ gruppi è avvenuto in maniera deterministica. La casualità
viene introdotta definendo le variabili aleatorie $T_{i}$ nel modo
seguente\[
T_{i}=\left\{ \begin{array}{ll}
1 & \text{l'}i\text{-esimo gruppo è selezionato}\\
0 & \text{altrimenti}\end{array}\right.\text{.}\]
 Come calcolato in precedenza è facile dimostrare che\begin{eqnarray*}
E(T_{i}) & = & \frac{1}{k},\\
V(T_{i}) & = & \left(\frac{1}{k}-\frac{1}{k^{2}}\right),\\
Cov(T_{i},T_{s}) & = & -\frac{1}{k^{2}}.\end{eqnarray*}
 A questo punto è semplice convincersi che la media campionaria di
un campionamento sistematico altro non è che \[
\overline{X}_{n}=\frac{1}{n}\sum_{i=1}^{k}g_{i}T_{i}\text{.}\]



\paragraph{Il valore atteso di $\overline{X}_{n}$}

Utilizziamo le proprietà ormai note del valore atteso:\begin{eqnarray*}
E\left(\overline{X}_{n}\right) & = & E\left(\frac{1}{n}\sum_{i=1}^{k}g_{i}T_{i}\right)=\frac{1}{n}\sum_{i=1}^{k}g_{i}E\left(T_{i}\right)=\frac{1}{n}\frac{1}{k}\sum_{i=1}^{k}g_{i}\\
 & = & \frac{1}{N}\underset{\text{somma sull'intera pop.}}{\underbrace{\sum_{i=1}^{k}\sum_{j=1}^{n}a_{ji}}}=\mu\text{.}\end{eqnarray*}
 La media campionaria è dunque uno stimatore corretto del valore atteso
della popolazione anche quando la tecnica di campionamento è quella
del campionamento sistematico. Veniamo ora alla calcolo del suo grado
di precisione.


\paragraph{La varianza di $\overline{X}_{n}$}

\begin{eqnarray*}
V(\overline{X}_{n}) & = & \frac{1}{n^{2}}V(\sum_{i=1}^{k}g_{i}T_{i})=\frac{1}{n^{2}}\sum_{i=1}^{k}\sum_{s=1}^{k}g_{i}g_{s}Cov(T_{i},T_{s})\\
 & = & \frac{1}{n^{2}}\left(\sum_{i=1}^{k}g_{i}^{2}V(T_{i})+\underset{i\neq s}{\sum_{i=1}^{k}\sum_{s=1}^{k}}g_{i}g_{s}Cov(T_{i},T_{s})\right)\\
 & = & \frac{1}{n^{2}}\left(\left(\frac{1}{k}-\frac{1}{k^{2}}\right)\sum_{i=1}^{k}g_{i}^{2}-\frac{1}{k^{2}}\underset{i\neq s}{\sum_{i=1}^{k}\sum_{s=1}^{k}}g_{i}g_{s}\right)\\
 & = & \frac{1}{n^{2}}\left(\frac{1}{k}\sum_{i=1}^{k}g_{i}^{2}-\frac{1}{k^{2}}\sum_{i=1}^{k}\sum_{s=1}^{k}g_{i}g_{s}\right).\end{eqnarray*}
 Continuando esattamente come visto nella (\ref{equazione d'esempio})
si ottiene\[
V(\overline{X}_{n})=\frac{1}{n^{2}}\frac{1}{k}\sum_{i=1}^{k}\left(g_{i}-\overline{g}\right)^{2}\text{.}\]
 \textbf{Interpretazione}: la varianza di $\overline{X}_{n}$ dipenderà
quindi dall'eterogeneità dei $k$ gruppi rispetto alla caratteristica
in esame. Se ad esempio $g_{1}$ contiene prevalentemente redditi
bassi, $g_{2}$ prevalentemente redditi medi e $g_{3}$ prevalentemente
redditi alti avremo una varianza elevata. Se invece $g_{1},$ $g_{2}$
e $g_{3}$ contengono tutti redditi bassi/medi/alti avremo che $g_{1}\approx g_{2}\approx g_{3}$
e la varianza dello stimatore sarà quindi più bassa.


\section{Campionamento stratificato}

Stratificare una popolazione consiste nel creare una partizione della
stessa sulla base di determinati criteri. Ogni sottoinsieme è detto
\textquotedbl{}strato\textquotedbl{}. I criteri utilizzati per
definire gli strati dipendono dalle caratteristiche della popolazione
nonché dall'obiettivo dello studio. Possibili criteri sono il sesso,
l'età, il reddito, l'appartenenza ad una regione linguistica, la dimensione
dell'azienda in termini di numero di dipendenti o cifra d'affari,
il settore in cui opera l'azienda, ecc. Ovviamente gli strati non
avranno quasi mai lo stesso numero di unità. Fabbris (p. 71) identifica
i seguenti obiettivi che possono indurre ad effettuare una stratificazione
della popolazione. 
\begin{enumerate}
\item Evidenziare insiemi di unità significative per la ricerca. 
\item Separare dalle altre le sottopopolazioni fisicamente isolate e con
caratteristiche speciali. 
\item Individuare certe unità che si vogliono osservare con tecniche particolari. 
\item Introdurre sulla selezione il massimo controllo, pur mantenendola
casuale. 
\item Individuare sottopopolazioni al massimo omogenee rispetto alla variabile
o alle variabili da rilevare e ricavare così stime più efficienti
di quelle ottenibili con un campione casuale semplice. 
\end{enumerate}
\noindent Supponiamo per un istante di osservare l'intera popolazione.
Potremmo suddividere gli uomini dalle donne e calcolare per ciascun
strato i rispettivi valori medi $\mu_{d}$ e $\mu_{u}$. Qual è la
relazione tra il valore medio $\mu$ dell'intera popolazione e quello
dei due strati? Indichiamo con $N_{d}$ e $N_{u}$ il numero di donne
e uomini contenuti nelle rispettive sottopopolazioni. Ovviamente varrà
che $N=N_{d}+N_{u}$. Avremo dunque\begin{eqnarray*}
\mu & = & \frac{1}{N}\left(\sum_{i=1}^{N}a_{i}\right)=\frac{1}{N}\left(\sum_{i=1}^{N_{d}}a_{d,i}+\sum_{j=1}^{N_{u}}a_{u,j}\right)\\
 & = & \frac{1}{N}\sum_{i=1}^{N_{d}}a_{d,i}+\frac{1}{N}\sum_{j=1}^{N_{u}}a_{u,j}=\frac{N_{d}}{N}\frac{1}{N_{d}}\sum_{i=1}^{N_{d}}a_{d,i}+\frac{N_{u}}{N}\frac{1}{N_{u}}\sum_{j=1}^{N_{u}}a_{u,j}\\
 & = & \frac{N_{d}}{N}\mu_{d}+\frac{N_{u}}{N}\mu_{u}=\pi_{d}\mu_{d}+\pi_{u}\mu_{u}.\end{eqnarray*}
 Il reddito medio della popolazione è dunque la \emph{somma pesata}
dei redditi medi dei due strati. Generalizzando al caso con $H$ strati,
varrà la seguente formula\begin{equation}
\mu=\sum_{h=1}^{H}\pi_{h}\mu_{h}\label{strato media scomposta come somma pesata}\end{equation}
 dove 
\begin{itemize}
\item $\pi_{h}$ corrisponde al \emph{peso} assegnato all'$h$-esimo strato
e sarà uguale alla frazione di individui (unità) appartenenti allo
strato $h$ rispetto al numero totale di individui (unità)\ della
popolazione\begin{equation}
\pi_{h}=\frac{N_{h}}{N}.\label{peso h strato sulla popolazione}\end{equation}

\item $\mu_{h}$ è il valore medio dell' $h$-esimo strato, ovvero\[
\mu_{h}=\frac{1}{N_{h}}\sum_{j=1}^{N_{h}}a_{h,j}\text{.}\]
 
\end{itemize}
\noindent L'idea fondamentale del campionamento stratificato è quella
di stimare i valori medi $\mu_{h}$ delle sottopopolazioni (strati)
selezionando da ciascuna di esse un campione casuale. In seguito,
utilizzando le stime dei singoli $\mu_{h}$, si stimerà il valore
medio $\mu$ della popolazione tramite la formula (\ref{strato media scomposta come somma pesata}),
sostituendo ai valori sconosciuti $\mu_{h}$ i rispettivi stimatori,
notati $\overline{X}_{n_{h}}$:\[
\overline{X}_{str,n}=\sum_{h=1}^{H}\pi_{h}\overline{X}_{n_{h}}\text{.}\]


\begin{esempio} In Svizzera il numero di persone occupate (dati del
secondo trimestre 2007, in milioni) sono 4,369 di cui 2,415 uomini
e 1,954 donne. Avremo quindi $\pi_{u}=\frac{2,415}{4,369}$ e $\pi_{d}=\frac{1,954}{4,369}$.
Supponiamo che $n_{u}=200$ e $n_{d}=100$. Sulla base dei due campioni
abbiamo calcolato $\overline{x}_{n_{u}}=60,000$ e rispettivamente,
$\overline{x}_{n_{d}}=50,000$. La stima del reddito medio dei lavoratori
svizzeri sarebbe quindi\begin{eqnarray*}
\overline{x}_{str,300} & = & \frac{2,415}{4,369}\ 60,000+\frac{1,954}{4,369}\ 50,000\\
 & = & 33,165+22,362=55,527\text{.}\end{eqnarray*}
 \end{esempio}

\noindent La numerosità del campione dell' $h$-esimo strato è indicato
con $n_{h}$. I sottocampioni potranno essere di numerosità diversa.
La numerosità del campione è semplicemente la somma delle $H$ numerosità
dei sottocampioni\[
n=n_{1}+n_{2}+...+n_{H}=\sum_{h=1}^{H}n_{h}\text{.}\]
 Il campione è l'unione degli $H$ sottocampioni.

\begin{definizione} Frazione di campionamento. La quantità\begin{equation}
f_{h}=\frac{n_{h}}{N_{h}}\label{frazione campionamento h}\end{equation}
 è chiamata frazione di campionamento dell'$h$-esimo strato. \end{definizione}

\noindent Quando si estrae la stessa frazione di unità da ogni strato,
o in altre parole quando la frazione di campionamento è uguale per
tutti gli strati \begin{equation}
f_{h}=c\ \ \ \forall h\label{campione stratificato proporzionale}\end{equation}
 allora il campione si dice \textquotedbl{}stratificato proporzionale\textquotedbl{}.
Quando invece $f_{h}$ non è costante si parlerà di campione \textquotedbl{}stratificato
non proporzionale\textquotedbl{} o \textquotedbl{}a probabilità
variabili\textquotedbl{}. Si noti che nel caso di campione stratificato
proporzionale, $c$ è uguale alla frazione di campionamento $f$ definita
dalla (\ref{frazione campionamento}) e pari a $\frac{n}{N}$. Infatti,
utilizzando le (\ref{frazione campionamento h}) e (\ref{campione stratificato proporzionale})
otteniamo \begin{eqnarray*}
n_{h} & = & cN_{h}\ \ \ \forall h\\
\sum_{h=1}^{H}n_{h} & = & c\sum_{h=1}^{H}N_{h}\\
n & = & cN\\
c & = & \frac{n}{N}.\end{eqnarray*}
 Per un campione stratificato proporzionale vale dunque la relazione\begin{equation}
n_{h}=\frac{N_{h}}{N}n\text{ o equivalentemente }\frac{n_{h}}{n}=\frac{N_{h}}{N}\text{\ }\forall h.\label{calcolo numerosita strato}\end{equation}
 Fissata la numerosità del campione sulla base di vincoli economici
dettati dalla limitatezza delle risorse a disposizione, il numero
di unità da estrarre dall'$h$-esimo strato è dato dalla formula (\ref{calcolo numerosita strato}).
Il campione selezionato avrà in questo caso le stesse caratteristiche
della popolazione in termini di rappresentatività di ogni strato al
suo interno (formula (\ref{campione stratificato proporzionale})).

\begin{remark} Un campione stratificato proporzionale non è condizione
né necessaria né sufficiente per garantire la correttezza dello stimatore
$\overline{X}_{str,n}$. \end{remark}

\begin{remark} Un campione di numerosità $n$ verrà generalmente
costruito eseguendo $H$ campionamenti casuali semplici di numerosità
$n_{h}$ ciascuno, $h=1,...,H$. Se il campione è stratificato proporzionale,
avremo che individui appartenenti a strati diversi avranno la medesima
probabilità di figurare nel campione. Infatti, la probabilità di figurare
nel campione di un qualsiasi individuo (prendiamo ad esempio il primo)
dello strato $h$ è uguale (cf. formula (\ref{probabilita inserimento nel campione con reimm}))\[
P(\text{"individuo }1\text{ dello strato }h\text{ è estratto"})=\frac{n_{h}}{N_{h}}=c=\frac{n}{N}\text{.}\]
 Se, al contrario, il campione non è stratificato proporzionale, il
rapporto $\frac{n_{h}}{N_{h}}$ varierà con $h$ e quindi le probabilità
di inclusione dei singoli individui varieranno anch'esse da strato
a strato. \end{remark}

\begin{remark} Se il campione è stratificato proporzionale, la formula
per il calcolo di $\overline{X}_{str,n}$ è semplificabile. Infatti\begin{eqnarray*}
\overline{X}_{str,n} & = & \sum_{h=1}^{H}\pi_{h}\overline{X}_{n_{h}}=\sum_{h=1}^{H}\frac{N_{h}}{N}\overline{X}_{n_{h}}=\sum_{h=1}^{H}\frac{N_{h}}{N}\frac{1}{n_{h}}\sum_{j=1}^{n_{h}}X_{h,j}\\
 & \underset{n_{h}=\frac{N_{h}}{N}n}{=} & \sum_{h=1}^{H}\frac{N_{h}}{N}\frac{N}{N_{h}}\frac{1}{n}\sum_{j=1}^{n_{h}}X_{h,j}=\frac{1}{n}\underset{\text{somma sull'intero campione}}{\underbrace{\sum_{h=1}^{H}\sum_{j=1}^{n_{h}}X_{h,j}}.}\end{eqnarray*}
 \end{remark}

\bigskip{}


\begin{center}
Tabella riassuntiva 
\par\end{center}

\begin{center}
\bigskip{}

\par\end{center}

\begin{center}
\begin{tabular}{cccccccc}
\hline 
{\scriptsize Strato}  & $h$  & $1,$  & $...,$  & $h,$  & $...,$  & $H$  & {\scriptsize Popolazione} \tabularnewline
\hline 
\multicolumn{1}{l}{{\scriptsize \# Unità componenti}} & $\left(N_{h}\right)$  & $N_{1},$  & $...,$  & $N_{h},$  & $...,$  & $N_{H}$  & $N$ \tabularnewline
\multicolumn{1}{l}{{\scriptsize Peso}} & $\left(\pi_{h}=\frac{N_{h}}{N}\right)$  & $\pi_{1},$  & $...,$  & $\pi_{h},$  & $...,$  & $\pi_{H}$  & $1$ \tabularnewline
\multicolumn{1}{l}{{\scriptsize Varianza}} & $\left(\sigma_{h}^{2}\right)$  & $\sigma_{1}^{2},$  & $...,$  & $\sigma_{h}^{2},$  & $...,$  & $\sigma_{H}^{2}$  & $\sigma^{2}$ \tabularnewline
\multicolumn{1}{l}{{\scriptsize Unità campionarie}} & $\left(n_{h}\right)$  & $n_{1},$  & $...,$  & $n_{h},$  & $...,$  & $n_{H}$  & $n$ \tabularnewline
\multicolumn{1}{l}{{\scriptsize Frazione di campionamento}} & $\left(f_{h}\right)$  & $f_{1},$  & $...,$  & $f_{h},$  & $...,$  & $f_{H}$  & $f$ \tabularnewline
\hline
\end{tabular}
\par\end{center}


\subsection{La correttezza di $\overline{X}_{str,n}$}

Se gli stimatori $\overline{X}_{n_{h}}$ di $\mu_{h}$ sono tutti
degli stimatori corretti, $\overline{X}_{str,n}$ sarà automaticamente
uno stimatore corretto di $\mu$:\[
E\left(\overline{X}_{str,n}\right)=E\left(\sum_{h=1}^{H}\pi_{h}\overline{X}_{n_{h}}\right)=\sum_{h=1}^{H}\pi_{h}E\left(\overline{X}_{n_{h}}\right)=\sum_{h=1}^{H}\pi_{h}\mu_{h}=\mu\text{.}\]
 La stima di $\mu$ richiede dunque la stima di $H$ valori attesi,
uno per strato. Per ciascun strato siamo liberi di scegliere la tecnica
di selezione nonché il tipo di stimatore più appropriato alle sue
caratteristiche.


\subsection{La varianza di $\overline{X}_{str,n}$}

Poiché i campionamenti eseguiti sui vari strati sono fra loro indipendenti,
la varianza di $\overline{X}_{str,n}$ è semplicemente uguale a\[
V\left(\overline{X}_{str,n}\right)=V\left(\sum_{h=1}^{H}\pi_{h}\overline{X}_{n_{h}}\right)=\sum_{h=1}^{H}\pi_{h}^{2}V\left(\overline{X}_{n_{h}}\right)\]
 Quest'ultima formula è valida indipendentemente dalle tecniche di
campionamento applicate ai vari strati (purché sia mantenuta l'indipendenza
fra un campionamento e l'altro). Ammettiamo ora che ad ogni strato
venga applicata la tecnica di campionamento senza reimmissione. Abbiamo
visto nei paragrafi precedenti che in tal caso la varianza%
\footnote{Rispetto alla formula (\ref{varianza media senza reimmissione}) occorre
evidentemente sostituire $N$ con $N_{h}$ e $n$ con $n_{h}.$%
} di $\overline{X}_{n_{h}}$ (cf. formula (\ref{varianza media senza reimmissione}))
è uguale a \[
V(\overline{X}_{n_{h}})=\frac{N_{h}-n_{h}}{N_{h}-1}\frac{\sigma_{h}^{2}}{n_{h}}=\frac{1-f_{h}}{1-1/N_{h}}\frac{\sigma_{h}^{2}}{n_{h}}\]
 dove ora $\sigma_{h}^{2}$ rappresenta la varianza dello strato $h$,
ovvero\[
\sigma_{h}^{2}=\frac{1}{N_{h}}\sum_{j=1}^{N_{h}}\left(a_{h,j}-\mu_{h}\right)^{2}\text{.}\]
 Nel caso di un campionamento senza reinserimento avremo quindi\begin{equation}
V\left(\overline{X}_{str,n}\right)=\sum_{h=1}^{H}\pi_{h}^{2}\frac{1-f_{h}}{1-1/N_{h}}\frac{\sigma_{h}^{2}}{n_{h}}.\label{varianza stratif camp senza reins}\end{equation}


\begin{remark} La varianza $\sigma^{2}$ della popolazione non compare
più nella formula (\ref{varianza stratif camp senza reins}) della
varianza dello stimatore $\overline{X}_{str,n}$. \end{remark}

\begin{remark} $V\left(\overline{X}_{str,n}\right)$ risulterà essere
tanto più piccola quanto più omogenei saranno i diversi strati al
loro interno. Ricordiamo che se uno strato $h$ è perfettamente omogeneo
allora la sua varianza è nulla. Nasce da qui il vantaggio di stratificare
la popolazione quando gli strati possiedono una certa uniformità rispetto
alla caratteristica studiata. \end{remark}

\begin{remark} La formula (\ref{varianza stratif camp senza reins})
esprime la varianza di $\overline{X}_{str,n}$ in funzione delle numerosità
$n_{h}$ dei sottocampioni. Sapendo che per un campione stratificato
proporzionale vale (cf. la (\ref{calcolo numerosita strato}))\[
n_{h}=\frac{N_{h}}{N}n\]
 è possibile riscrivere la varianza di $\overline{X}_{str,n}$ come\begin{equation}
V(\overline{X}_{str,n})=\frac{1-f}{n}\sum_{h=1}^{H}\pi_{h}\frac{N_{h}}{N_{h}-1}\sigma_{h}^{2}\text{.}\label{varianza stratificato}\end{equation}
 \end{remark}


\subsection{Effetto della stratificazione sulla precisione di stima}

Abbiamo visto in precedenza che quando il campione è ottenuto tramite
campionamento casuale semplice senza reinserimento la varianza di
$\overline{X}_{n}$ è uguale a (cf. (\ref{varianza media senza reimmissione}))\begin{equation}
V(\overline{X}_{n})=\frac{N-n}{N-1}\frac{\sigma^{2}}{n}=\frac{1-f}{n}\frac{N}{N-1}\sigma^{2}.\label{varianza senza reimmissione riscritta}\end{equation}
 Possiamo confrontare questo resultato con la formula (\ref{varianza stratificato})
della varianza di $\overline{X}_{str,n}$ di un campione stratificato
proporzionale. Tuttavia, prima di procedere al confronto vero e proprio,
occorre chiarire che relazione sussiste tra la varianza dell'intera
popolazione e la varianza di ogni singolo strato.

\begin{theorem} Notiamo con $SS$ $(SS_{h})$ la somma degli scarti
dal valore atteso al quadrato, ovvero\[
SS=\sum_{i=1}^{N}\left(a_{i}-\mu\right)^{2}\text{ e }SS_{h}=\sum_{j=1}^{N_{h}}\left(a_{h,i}-\mu_{h}\right)^{2}\text{.}\]
 Vale la seguente relazione\begin{equation}
\sigma^{2}=\sum_{h=1}^{H}\pi_{h}\sigma_{h}^{2}+\sum_{h=1}^{H}\pi_{h}\left(\mu_{h}-\mu\right)^{2}\label{scomposizione varianza in strati}\end{equation}
 \end{theorem}

\textbf{Interpretazione}: La varianza della popolazione può essere
decomposta come la somma pesata delle varianze di ogni singolo strato
(misura della eterogeneità interna agli strati) più la varianza dei
valori medi degli strati (misura di eterogeneità fra strati).

\textbf{Dimostrazione}:\begin{eqnarray*}
SS & = & \sum_{i=1}^{N}\left(a_{i}-\mu\right)^{2}=\sum_{i=1}^{N}a_{i}^{2}-N\mu^{2}=\sum_{h=1}^{H}\sum_{i=1}^{N_{h}}a_{h,i}^{2}-N\mu^{2}\\
 & = & \sum_{h=1}^{H}\sum_{i=1}^{N_{h}}\left(a_{h,i}^{2}-\mu_{h}^{2}+\mu_{h}^{2}\right)-N\mu^{2}\\
 & = & \sum_{h=1}^{H}\left(\left(\sum_{i=1}^{N_{h}}\left(a_{h,i}^{2}-\mu_{h}^{2}\right)\right)+N_{h}\mu_{h}^{2}\right)-N\mu^{2}\\
 & = & \sum_{h=1}^{H}\left(\underset{SS_{h}}{\underbrace{\left(\sum_{i=1}^{N_{h}}a_{h,i}^{2}-N_{h}\mu_{h}^{2}\right)}}+N_{h}\mu_{h}^{2}\right)-\underset{\sum_{h=1}^{H}N_{h}}{\underbrace{N}}\mu^{2}\\
 & = & \sum_{h=1}^{H}SS_{h}+\sum_{h=1}^{H}N_{h}\mu_{h}^{2}-\sum_{h=1}^{H}N_{h}\mu^{2}\\
 & = & \sum_{h=1}^{H}SS_{h}+\sum_{h=1}^{H}N_{h}\left(\mu_{h}^{2}-\mu^{2}\right)\end{eqnarray*}
 Il secondo termine,$\sum_{h=1}^{H}N_{h}\left(\mu_{h}^{2}-\mu^{2}\right)$
è uguale a $\sum_{h=1}^{H}N_{h}\left(\mu_{h}-\mu\right)^{2}$. Infatti\begin{eqnarray*}
\sum_{h=1}^{H}N_{h}\left(\mu_{h}-\mu\right)^{2} & = & \sum_{h=1}^{H}N_{h}\left(\mu_{h}^{2}-2\mu_{h}\mu+\mu^{2}\right)=\\
 & = & \sum_{h=1}^{H}N_{h}\mu_{h}^{2}-2\mu\sum_{h=1}^{H}N_{h}\mu_{h}+\mu^{2}\sum_{h=1}^{H}N_{h}\\
 & = & \sum_{h=1}^{H}N_{h}\mu_{h}^{2}-2N\mu^{2}+N\mu^{2}=\sum_{h=1}^{H}N_{h}\left(\mu_{h}^{2}-\mu^{2}\right)\end{eqnarray*}
 Per il termine $SS$ vale dunque\[
SS=\sum_{h=1}^{H}SS_{h}+\sum_{h=1}^{H}N_{h}\left(\mu_{h}-\mu\right)^{2}\text{.}\]
 Poiché $\sigma^{2}=\frac{SS}{N}$ abbiamo che\begin{eqnarray*}
\sigma^{2} & = & \frac{1}{N}\sum_{h=1}^{H}SS_{h}+\frac{1}{N}\sum_{h=1}^{H}N_{h}\left(\mu_{h}-\mu\right)^{2}\\
 & = & \frac{1}{N}\sum_{h=1}^{H}\frac{N_{h}}{N_{h}}SS_{h}+1\sum_{h=1}^{H}\frac{N_{h}}{N}\left(\mu_{h}-\mu\right)^{2}\\
 & = & \sum_{h=1}^{H}\frac{N_{h}}{N}\frac{SS_{h}}{N_{h}}+1\sum_{h=1}^{H}\frac{N_{h}}{N}\left(\mu_{h}-\mu\right)^{2}\end{eqnarray*}
 e quindi \[
\sigma^{2}=\sum_{h=1}^{H}\pi_{h}\sigma_{h}^{2}+\sum_{h=1}^{H}\pi_{h}\left(\mu_{h}-\mu\right)^{2}\text{.}\]


\noindent Tornando ora al confronto fra la varianza $V(\overline{X}_{n})$
e $V(\overline{X}_{str,n})$ notiamo che\begin{eqnarray*}
V(\overline{X}_{n})-V(\overline{X}_{str,n}) & = & \frac{1-f}{n}\frac{N}{N-1}\sigma^{2}-\frac{1-f}{n}\sum_{h=1}^{H}\pi_{h}\frac{N_{h}}{N_{h}-1}\sigma_{h}^{2}\\
 & = & \frac{1-f}{n}\left(\frac{N}{N-1}\sigma^{2}-\sum_{h=1}^{H}\pi_{h}\frac{N_{h}}{N_{h}-1}\sigma_{h}^{2}\right)\end{eqnarray*}
 Per $N$ e $N_{h}$ sufficientemente grandi $\frac{N}{N-1}\simeq1$
e $\frac{N_{h}}{N_{h}-1}\simeq1$ dimodoché \begin{eqnarray*}
V(\overline{X}_{n})-V(\overline{X}_{str,n}) & \simeq & \frac{1-f}{n}\left(\sigma^{2}-\sum_{h=1}^{H}\pi_{h}\sigma_{h}^{2}\right)\\
 & \underset{(\ref{scomposizionevarianzainstrati})}{=} & \frac{1-f}{n}\sum_{h=1}^{H}\pi_{h}\left(\mu_{h}-\mu\right)^{2}\geq0\text{.}\end{eqnarray*}
 Da quest'ultima disuguaglianza deduciamo che la varianza della media
calcolata utilizzando un campione stratificato proporzionale è in
genere inferiore a quella di un campione casuale semplice di uguale
numerosità. Il guadagno risultante dal processo di stratificazione
della popolazione rappresentato dalla quantità \[
\frac{1-f}{n}\sum_{h=1}^{H}\pi_{h}\left(\mu_{h}-\mu\right)^{2}\]
 è proporzionale alla varianza dei valori medi di strato. Esso sarà
nullo se tutti i valori medi sono uguali fra loro.


\section{La stima di $\sigma^{2}$}

Nei paragrafi precedenti è stata analizzata la proprietà di correttezza
della media campionaria sotto diverse tipologie di campionamento:
con e senza reinserimento, sistematico e stratificato. Oltre alla
correttezza ci siamo interessati anche alla sua varianza, ovvero alla
precisione con la quale il valore atteso della popolazione è approssimato.
Nelle diverse formule (\ref{varianza media con reimmissione}) (\ref{varianza media senza reimmissione})
(\ref{varianza stratif camp senza reins}) (\ref{varianza stratificato})
inerenti alla varianza della media campionaria, figura sempre $\sigma^{2}$
$($o $\sigma_{h}^{2})$, la varianza della popolazione (dell'$h$-esimo
strato). Ad esempio, per un campione casuale semplice estratto senza
reimmissione la varianza è pari a\[
V(\overline{X}_{n})=\frac{N-n}{N-1}\frac{\sigma^{2}}{n}\text{.}\]
 In generale $N$ e $n$ sono noti mentre $\sigma^{2}$ $($ o $\sigma_{h}^{2})$
può o non può esserlo. 
\begin{enumerate}
\item Quando $\sigma^{2}$ è noto non sussiste alcun problema: $V(\overline{X}_{n})$
è calcolabile. 
\item Quando $\sigma^{2}$ $(\sigma_{h}^{2})$ non è noto.


In questo caso la varianza $V(\overline{X}_{n})$ del nostro stimatore
non è calcolabile. Affinché le suddette formule siano utilizzabili,
occorrerà stimare $\sigma^{2}$. Ai fini di questo corso - a meno
che non venga specificato diversamente - utilizzeremo sempre $S^{2}$
($S_{h}^{2}$) quale stimatore di $\sigma^{2}$ ($\sigma_{h}^{2}$)\[
S^{2}=\frac{1}{n-1}\sum_{i=1}^{n}\left(X_{i}-\overline{X}\right)^{2}\]
 o rispettivamente \[
S_{h}^{2}=\frac{1}{n_{h}-1}\sum_{i=1}^{n_{h}}\left(X_{h,i}-\overline{X}_{h}\right)^{2}\text{,}\]
 dove 
\begin{itemize}
\item $n_{h}$ rappresenta la numerosità del sottocampione estratto dall'$h$-esimo
strato, 
\item $X_{h,i}$ la variabile aleatoria relativa all'$i$-esima estrazione
dallo strato $h$ 
\item $\overline{X}_{h}$ la media calcolata sull'$h$-esimo sottocampione. 
\end{itemize}
\end{enumerate}
\bigskip{}


\noindent È importante fare una chiara distinzione tra la vera varianza
di $\overline{X}_{n}$, notata appunto $V(\overline{X}_{n})$, e la
varianza stimata. Per questo motivo quando $\sigma^{2}$ ($\sigma_{h}^{2}$)
non è nota ed è stimata tramite lo stimatore $S^{2}$ $(S_{h}^{2})$
aggiungeremo l'accento circonflesso alla $V$ della varianza di $\overline{X}_{n}$.
Ad esempio, scriveremo\[
\widehat{V}(\overline{X}_{n})=\frac{N-n}{N-1}\frac{S^{2}}{n}\]
 per indicare che si tratta della stima della varianza di $\overline{X}_{n}$
e non della sua vera varianza $V(\overline{X}_{n})$.


\section{L'intervallo di confidenza per $\mu$}

Quando si presenta il risultato di una stima si è soliti fornire tale
risultato sotto forma di un valore\ (stima puntuale) più o meno una
certa quantità. Ad esempio, se organizzate il ballo dell'università
potreste stimare il numero di partecipanti a $1^{\prime}000\pm100$
persone, intendendo in tal modo che il numero di persone sarà compreso
con \emph{molta probabilità} fra le $900$ e le $1^{\prime}100$ persone.
Un secondo esempio potrebbe essere quello di una manifestazione sportiva
dove il numero esatto di partecipanti non è noto. Gli organizzatori
dovranno stimare un intervallo plausibile di partecipanti. Sulla base
di tale informazione verranno poi dimensionare le infrastrutture necessarie
allo svolgimento della manifestazione. Capita dunque spesso di vedere
delle stime in forma di intervallo. Vedremo nei successivi paragrafi
come costruire un intervallo di confidenza per $\mu$, ovvero un intervallo
dentro il quale, con molta probabilità, è contenuto il valore $\mu$.
Prima di affrontare tale discussione è necessario presentare due importanti
argomenti della teoria asintotica: la legge dei grandi numeri ed il
teorema del limite centrale.


\subsection{La legge (debole)\ dei grandi numeri}

La legge dei grandi numeri è utile al fine di comprendere il comportamento
\emph{asintotico} di medie di variabili aleatorie. Supponiamo infatti
di avere a disposizione una successione infinita $X_{1},X_{2},X_{3},...$
di variabili aleatorie 
\begin{itemize}
\item \emph{indipendenti} 
\item di valore atteso $\mu$ 
\item di varianza $\sigma^{2}$. 
\end{itemize}
\noindent Per mezzo di questa successione infinita costruiamo una
seconda successione, la successione delle medie dei primi $n$ elementi\[
\begin{array}{ccc}
\overline{X}_{1} & = & X_{1}\\
\overline{X}_{2} & = & \left(X_{1}+X_{2}\right)/2\\
\overline{X}_{3} & = & \left(X_{1}+X_{2}+X_{3}\right)/3\\
 & \vdots\\
\overline{X}_{n} & = & \frac{1}{n}\sum_{i=1}^{n}X_{i}\\
 & \vdots\end{array}\]
 La successione delle medie $\overline{X}_{1},\overline{X}_{2},\overline{X}_{3},...$
è ancora una successione di variabili aleatorie. È immediato calcolare,
per fisso $n,$ il valore atteso e la varianza di $\overline{X}_{n}$:\begin{eqnarray*}
E(\overline{X}_{n}) & = & \mu\ ,\\
V(\overline{X}_{n}) & = & \frac{\sigma^{2}}{n}\ .\end{eqnarray*}
 Come per la successione $X_{1},X_{2},X_{3},...$, le $V.A.$ $\overline{X}_{1},\overline{X}_{2},\overline{X}_{3},...$
possiedono tutte il medesimo valore atteso. Tuttavia questo non è
vero per la loro varianza, che tende a diminuire al crescere di $n$.
Inoltre abbiamo che \[
\lim_{n\rightarrow\infty}V(\overline{X}_{n})=0\ \text{.}\]
 Ma questo significa che con $n$ grande le realizzazioni di $\overline{X}_{n}$
saranno molto concentrate attorno a $\mu$.

\begin{esempio} \label{esempio sequenza normale}Per meglio comprendere
quanto accade, aggiungiamo alle tre ipotesi precedenti l'ipotesi di
normalità, vale a dire \end{esempio} 
\begin{itemize}
\item $X_{1},X_{2},X_{3},...$ sono distribuite secondo la legge normale. 
\end{itemize}
\noindent Poiché la somma pesata di $V.A.$ normali indipendenti è
una $V.A.$ normale, possiamo eseguire il grafico della funzione di
densità degli $\overline{X}_{n}$ per $n=1,2$ e $16$. Scegliamo,
senza perdita di generalità, $\mu=1$ e $\sigma^{2}=4$.

\noindent Al crescere di $n$, la funzione di densità (e quindi la
probabilità) tende a concentrarsi attorno al valore atteso $\mu$
(in questo esempio $\mu=1$). Il prossimo teorema formalizza quanto
detto finora.

\begin{theorem} Legge (debole) dei grandi numeri. Sia $X_{1},X_{2},X_{3},...$
una successione di $V.A.$ indipendenti, di valore atteso $\mu$ e
di varianza $\sigma^{2}<\infty$. Allora per qualsiasi $\varepsilon>0$
piccolo a piacere si avrà che\begin{equation}
\lim_{n\rightarrow\infty}P(|\overline{X}_{n}-\mu|>\varepsilon)=0\text{.}\label{WLLN}\end{equation}
 \end{theorem}

\noindent Per fisso $\varepsilon>0$, la probabilità $P(|\overline{X}_{n}-\mu|\leq\varepsilon)$
corrisponde alla probabilità che il valore realizzato di $\overline{X}_{n}$
cada in un intervallo di centro $\mu$ e raggio $\varepsilon$. La
(\ref{WLLN}) ci permette di affermare che questa probabilità tende
a $1$ al crescere di $n$ all'infinito.


\subsection{Uguaglianza e convergenza in distribuzione}

Nel corso di Statistica I avete studiato che ad ogni variabile aleatoria
a volori reali $X$ è associata una funzione di ripartizione $F_{X}:\mathbb{R}\rightarrow\lbrack0,1]$
definita per qualsiasi numero $c\in\mathbb{R}$ da\[
F_{X}(c):=P(X\leq c)\text{.}\]
 La funzione di ripartizione $F_{X}$ caratterizza la variabile aleatoria
$X$ in termini della sua \emph{probabilità}. Ora, date due variabili
aleatorie $X$ e $Y$ è lecito chiedersi se esse abbiano la medesima
distribuzione. Diremo che le due variabili aleatorie $X$ e $Y$ sono
uguali in distribuzione, e in tal caso scriveremo $X\sim Y$, se\begin{equation}
F_{X}(c)=F_{Y}(c)\text{ \ \ }\forall c\in\mathbb{R}\text{.}\label{uguaglianza in dist1}\end{equation}
 Se le due variabili aleatorie $X$ e $Y$ sono uguali in distribuzione
avremo dunque che \begin{equation}
P(X\leq c)=P(Y\leq c)\text{ \ \ }\forall c\in\mathbb{R}\text{.}\label{uguaglianza in distr2}\end{equation}
 A scanso di equivoci è bene precisare quanto segue. Affermare che
$X\sim Y$ non significa che la realizzazione di $X$ sarà uguale
a quella di $Y$. Ad esempio, supponiamo di lanciare due volte un
dado. Siano $X$ e $Y$ le $V.A.$ che descrivono il risultato del
primo e, rispettivamente, del secondo lancio. Ora, entrambe le $V.A.$
hanno una distribuzione discreta uniforme $U(1,6)$. $X$ e $Y$ sono
uguali in distribuzione: $X\sim Y$. Ciò non toglie che nel primo
lancio potrò osservare un cinque mentre nel secondo un tre.

\begin{definizione} Convergenza in distribuzione. Diremo che la successione
$X_{1},X_{2},\allowbreak X_{3},...$ di $V.A.$ converge in distribuzione
verso $Y$ se per ogni $c\in\mathbb{R}$ con $F_{Y}$ continua in
$c$\[
\lim_{n\rightarrow\infty}F_{X_{n}}(c)=F_{Y}(c)\text{ o equivalentemente }\lim_{n\rightarrow\infty}P(X_{n}\leq c)=P(Y\leq c).\]
 \end{definizione}


\subsection{Il Teorema del Limite Centrale}

Il Teorema del Limite Centrale (TLC) è di estrema importanza in probabilità
e statistica in quanto è il fondamento sul quale sono costruiti moltissimi
test d'ipotesi (rimandiamo al capitolo sull'inferenza statistica per
la definizione formale di un test d'ipotesi statistica). Nelle pagine
precedenti abbiamo visto che, sotto certe condizioni, una media di
$V.A.$ converge verso il suo valore atteso. Il valore limite non
è più una variabile aleatoria ma un numero ben preciso. L'idea del
teorema del limite centrale è quella di evitare, tramite un'opportuna
trasformazione, che la successione di $V.A.$ $\overline{X}_{1},\overline{X}_{2},\overline{X}_{3},...$
converga verso un numero. In altre parole, si desidera mantenere l'aleatorietà
del limite della successione e, se possibile, ottenere come valore
limite una $V.A.$ \emph{la cui distribuzione sia nota}. Come fare
dunque? L'idea è quella di standardizzare le $V.A.$ $\overline{X}_{1},\overline{X}_{2},\overline{X}_{3},...$
così da ottenere una nuova successione di $V.A.$ che chiameremo $Y_{1},Y_{2},Y_{3},...$
. In pratica dovremo eseguire i due passi necessari alla standardizzazione
ovvero 
\begin{enumerate}
\item sottrarre a $\overline{X}_{n}$ il suo valore atteso $\mu$ 
\item dividere per la sua deviazione standard$\sqrt{\frac{\sigma^{2}}{n}}$ 
\end{enumerate}
\noindent in maniera da ottere la successione $Y_{1},Y_{2},Y_{3},...$
di $V.A.\sim\left(0,1\right)$\begin{equation}
Y_{n}=\frac{\overline{X}_{n}-\mu}{\sqrt{\frac{\sigma^{2}}{n}}}\ .\label{x_n standardizzato}\end{equation}


\begin{esempio} \label{esempio somme di normali}Riprendiamo l'Esempio
(\ref{esempio sequenza normale}) in cui $\overline{X}_{n}\sim N(\mu,\frac{\sigma^{2}}{n})$.
Ancora una volta, grazie alla proprietà della normale, dopo la standardizzazione
le variabili aleatorie $Y_{n}$ saranno ancora tutte normali $N(0,1)$
per qualsiasi valore di $n=1,2,...\ $. \end{esempio}

\noindent La proprietà di normalità delle $V.A.$\ $Y_{n}$ nell'Esempio
\ref{esempio somme di normali} non è vera in generale. Se la successione
di $V.A.$ $X_{1},X_{2},...$ non è costituita da variabili normali,
la media $\overline{X}_{n}$ non sarà più distribuita secondo la legge
normale e, di riflesso, pure $Y_{n}$. La conseguenza della non normalità
delle $V.A.$ $X_{1},...,X_{n}$ è la non normalità di $Y_{n}$, sebbene
che $Y_{n}\sim(0,1)$.

\bigskip{}


\noindent Prima di presentare la versione classica del TLC facciamo
notare una particolarità relativa alla standardizzazione di $\overline{X}_{n}$
(formula (\ref{x_n standardizzato})). Tramite una serie di semplici
trasformazioni algebriche è possibile riscrivere $Y_{n}$ come una
somma pesata di $V.A.$ $\sim(0,1)$.

\begin{esercizio} \label{esercizio centralizzazione}Dimostrate dapprima
che \[
\overline{X}_{n}-\mu=\frac{1}{n}\sum\limits _{i=1}^{n}\left(X_{i}-\mu\right)\ \]
 e successivamente che\begin{equation}
Y_{n}=\frac{\overline{X}_{n}-\mu}{\sqrt{\frac{\sigma^{2}}{n}}}=\frac{1}{\sqrt{n}}\sum\limits _{i=1}^{n}\varepsilon_{i}\ ,\label{TLC somma degli epsilon}\end{equation}
 dove $\varepsilon_{i}=\frac{X_{i}-\mu}{\sigma}$. \end{esercizio}

\noindent In pratica $Y_{n}$, che corrisponde alla media $\overline{X}_{n}$
standardizzata, puo' essere interpretato come la somma debitamente
pesata delle $n$ $V.A.$ $\varepsilon_{1},...,\varepsilon_{n}$ dove
ogni $\varepsilon_{i}$ altro non è che $\frac{X_{i}-\mu}{\sigma}\sim(0,1)$.
La somma $\sum\limits _{i=1}^{n}\varepsilon_{i}$ delle $n$ variabili
aleatorie $i.i.d.$ $\sim(0,1)$ ha valore atteso zero e varianza
$n$. La standardizzazione richiede che il peso applicato a $\sum\limits _{i=1}^{n}\varepsilon_{i}$
sia $\frac{1}{\sqrt{n}}$.

\begin{theorem} \label{teo limite centrale}Teorema del Limite Centrale
(TLC). Sia $\varepsilon_{1},\varepsilon_{2},...$ una successione
di $V.A.$ indipendenti, di valore atteso nullo e varianza unitaria.
Vale allora \begin{equation}
Y_{n}=\frac{1}{\sqrt{n}}\sum\limits _{i=1}^{n}\varepsilon_{i}\underset{n\rightarrow\infty}{\sim}N(0,1)\text{.}\label{teorema limite centrale}\end{equation}
 \end{theorem}

\begin{remark} \bigskip{}
 Dal Teorema del Limite Centrale e la relazione (\ref{TLC somma degli epsilon})
si deriva che, sotto le condizioni sopraelencate (quali sono?) sulla
sequenza di $V.A.$ $X_{1},X_{2},...$ ,\ per valori di $n$ sufficientemente
grandi la media standardizzata è distribuita come una variabile aleatoria
normale standard. È importante notare e \emph{ricordarsi} che il denominatore
nella parte sinistra della (\ref{x_n standardizzato}) non è altro
che la deviazione standard di $\overline{X}_{n}$. \end{remark}

\noindent Una variabile aleatoria normale standard è generalmente
indicata con la lettera $Z$:\[
Z\sim N(0,1)\text{.}\]
 Il vantaggio di lavorare con una variabile aleatoria normale standard
risiede nel fatto che per essa è possibile calcolare probabilità del
tipo\[
P(Z\leq c)\]
 utilizzando le tavole che già conoscete. Ora se $\overline{X}_{n}$
soddisfa il teorema del limite centrale avremo che per $n$ sufficientemente
grande%
\footnote{L'uguaglianza non sarà esatta ma al crescere di $n$ all'infinito
eventuali differenze saranno in pratica trascurabili.%
} \[
\frac{\overline{X}_{n}-\mu}{\sqrt{V(\overline{X}_{n})}}\underset{\text{circa}}{\sim}Z.\]
 Poiché $Z$ e $\frac{\overline{X}_{n}-\mu}{\sqrt{V(\overline{X}_{n})}}$
sono uguali in distribuzione avremo (confronta (\ref{uguaglianza in dist1})
e (\ref{uguaglianza in distr2})) che\[
P\left(\frac{\overline{X}_{n}-\mu}{\sqrt{V(\overline{X}_{n})}}<c\right)=P\left(\frac{\overline{X}_{n}-\mu}{\sqrt{\frac{\sigma^{2}}{n}}}<c\right)\underset{TLC}{\simeq}P\left(Z<c\right)\ \ \ \forall c\in\mathbb{R}\text{.}\]
 Sarà questo il punto di partenza per la costruzione dell'intervallo
di confidenza di $\mu$.


\subsection{\label{intervallo confidenza}L'intervallo di confidenza}

Iniziamo la costruzione dell'intervallo di confidenza ragionando sulla
variabile aleatoria $Z$. Siamo interessati a calcolare la probabilità
\[
P(|Z|<1.96)=P(-1.96<Z<1.96).\]
 Detto a parole stiamo semplicemente calcolando la probabilità che
la realizzazione di $Z$ sarà compresa nell'intervallo $[-1.96,1.96]$.
Poiché $Z$ è una variabile aleatoria normale standard è immediato
verificare che \begin{equation}
P(|Z|<1.96)=0.95\ \text{.}\label{equazione livello confidenza}\end{equation}
 Ora, poiché $Z$ e $\frac{\overline{X}_{n}-\mu}{\sqrt{V(\overline{X}_{n})}}$
sono approssimativamente uguali in distribuzione%
\footnote{Ricordiamo che l'uguaglianza è vera solo al limite.%
} vale che \[
P(|Z|<1.96)=P(|\frac{\overline{X}_{n}-\mu}{\sqrt{V(\overline{X}_{n})}}|<1.96)\]
 da cui ricaviamo\begin{equation}
P(\mu-1.96\sqrt{V(\overline{X}_{n})}<\overline{X}_{n}<\mu+1.96\sqrt{V(\overline{X}_{n})})=0.95.\label{intervallo interpretazione 1}\end{equation}
 All'uguaglianza (\ref{intervallo interpretazione 1}) si dà la seguente
interpretazione: $95$ volte su $100$ lo stimatore $\overline{X}_{n}$
assumerà dei valori compresi nell'intervallo di centro $\mu$ e raggio
$1.96\sqrt{V(\overline{X}_{n})}$, ovvero \begin{equation}
P(\overline{X}_{n}\in\left[\mu-1.96\sqrt{V(\overline{X}_{n})}\ ,\mu+1.96\sqrt{V(\overline{X}_{n})}\right])=0.95.\label{intervallo interpretazione 1b}\end{equation}
 Tuttavia, essendo $\mu$ sconosciuto, questa informazione è poco
utile. Infatti dove sarà posizionato sulla retta dei numeri reali
l'intervallo \[
\left[\mu-1.96\sqrt{V(\overline{X}_{n})}\ ,\mu+1.96\sqrt{V(\overline{X}_{n})}\right]\ ?\]
 Per mezzo di semplici trasformazioni algebriche possiamo però riscrivere
la (\ref{intervallo interpretazione 1}) nel seguente modo\begin{equation}
P(\overline{X}_{n}-1.96\sqrt{V(\overline{X}_{n})}<\mu<\overline{X}_{n}+1.96\sqrt{V(\overline{X}_{n})})=0.95.\label{intervallo interpretazione 2}\end{equation}
 Quale interpretazione possiamo ora assegnare alla nuova rappresentazione
(\ref{intervallo interpretazione 2}) della precedente uguaglianza
(\ref{intervallo interpretazione 1})? Per dare un significato a questa
espressione i due estremi dell'espressione \[
\overline{X}_{n}-1.96\sqrt{V(\overline{X}_{n})}<\mu<\overline{X}_{n}+1.96\sqrt{V(\overline{X}_{n})}\]
 che definiscono l'intervallo \begin{equation}
\left[\overline{X}_{n}-1.96\sqrt{V(\overline{X}_{n})}\ ,\overline{X}_{n}+1.96\sqrt{V(\overline{X}_{n})}\right]\text{.}\label{intervallo aleatorio}\end{equation}
 L'estremo sinistro di questo intervallo è dato da $\overline{X}_{n}-1.96\sqrt{V(\overline{X}_{n})}$.
Il termine $1.96\sqrt{V(\overline{X}_{n})}$ non è aleatorio ma è
un numero. $\overline{X}_{n}$ per contro è una variabile aleatoria.
Lo stesso ragionamento si applica all'estremo destro dell'intervallo.
Per tale motivo l'intervallo definito dalla (\ref{intervallo aleatorio})
è chiamato \emph{intervallo aleatorio} o più comunemente \emph{intervallo
di confidenza al 95\%}. La (\ref{intervallo interpretazione 2}) può
essere riscritta in maniera simile alla (\ref{intervallo interpretazione 1b})
ovvero\begin{equation}
P(\mu\in\left[\overline{X}_{n}-1.96\sqrt{V(\overline{X}_{n})}\ ,\overline{X}_{n}+1.96\sqrt{V(\overline{X}_{n})}\right])=0.95.\label{intervallo interpretazione 2b}\end{equation}
 Siamo ora pronti a dare un'interpretazione alla (\ref{intervallo interpretazione 2}):
con una probabilità del $95\%$ l'intervallo aleatorio (\ref{intervallo aleatorio})
conterrà il valore $\mu$. Oppure: $95$ volte su $100$ l'intervallo
$\left[\overline{X}_{n}-1.96\sqrt{V(\overline{X}_{n})}\ ,\overline{X}_{n}+1.96\sqrt{V(\overline{X}_{n})}\right]$
conterrà il valore $\mu$. Notate la sottile differenza fra la (\ref{intervallo interpretazione 1b})
e la (\ref{intervallo interpretazione 2b}). Nella (\ref{intervallo interpretazione 1b})
l'intervallo è deterministico ma sconosciuto\ ed il punto ($\overline{X}_{n}$)
è aleatorio ed osservabile. Nella (\ref{intervallo interpretazione 2b})
per contro l'intervallo è aleatorio ed osservabile mentre il punto
($\mu$) è deterministico ma sconosciuto. È importante sottolineare
l'equivalenza delle due espressioni: è possibile passare dall'una
all'altra tramite semplici operazioni algebriche. È tuttavia la seconda
espressione in termini dell'intervallo aleatorio \[
\left[\overline{X}_{n}-1.96\sqrt{V(\overline{X}_{n})}\ ,\overline{X}_{n}+1.96\sqrt{V(\overline{X}_{n})}\right]\]
 quella che ci fornisce uno strumento pratico per la stima del valore
atteso $\mu$. Infatti sulla base dei valori realizzati di $X_{1},...,X_{n}$,
notati $x_{1},...,x_{n}$, calcoleremo dapprima la realizzazione di
$\overline{X}_{n}$, notata $\overline{x}_{n}$, ed in seguito la
realizzazione dell'intervallo aleatorio ovvero l'intervallo\begin{equation}
\left[\overline{x}_{n}-1.96\frac{\sigma}{\sqrt{n}}\ ,\ \overline{x}_{n}+1.96\frac{\sigma}{\sqrt{n}}\right].\label{realizzazione intervallo aleatorio}\end{equation}
 Se $\mu$ fosse conosciuto, potremmo andare a verificare se l'intervallo
così calcolato lo contiene oppure no. Tuttavia questa verifica è impossibile.
Quello che sappiamo è che nel $95\%$ dei casi questa procedura determina
un intervallo che contiene $\mu$.

\bigskip{}


\noindent In entrambi i casi l'ampiezza dell'intervallo è data da
$1.96\sqrt{V(\overline{X}_{n})}$ $=$ $1.96~\sigma/\sqrt{n}$. Come
già sappiamo la varianza di $\overline{X}_{n}$ dipende dalla numerosità
$n$ del campione, dalla varianza della popolazione (o degli stratti)
e dalla tecnica di campionamento utilizzata. La costante $1.96$ dipende
invece dal livello di probabilità che era stato scelto all'inizio
di questo paragrafo e che ammonta al $95\%.$ Ricordiamo infatti che
la costante $1.96$ è stata calcolata come la soluzione in $c$ della
seguente equazione (confronta la (\ref{equazione livello confidenza}))\[
P(|Z|<c)=0.95.\]


\bigskip{}
 La probabilità $\alpha=0.95$ è chiamata il \emph{livello di confidenza}.
Essa rappresenta la confidenza che riponiamo nel fatto che la realizzazione
dell'intervallo aleatorio (\ref{realizzazione intervallo aleatorio})
contenga $\mu$. È il ricercatore che solitamente sceglie il livello
di confidenza. $\alpha=90\%$, $95\%$ e $99\%$ sono i valori comunemente
utilizzati. Per dato $\alpha$ occorre poi risolvere l'equazione \[
P(|Z|<c)=\alpha\]
 trovando il valore di $c$ che la soddisfa. Le soluzioni per i tre
livelli $\alpha$ di significatività dati in precedenza sono nell'ordine
$1.64$, $1.96$ e $2.58$. Essi andranno utilizzati al posto dell'$1.96$
nella costruzione dell'intervallo di confidenza (\ref{realizzazione intervallo aleatorio}).
Da ultimo facciamo semplicemente notare quanto segue. Il valore che
la costante $c$ assume in funzione del livello $\alpha$ di confidenza
corrisponde all'$\frac{1+\alpha}{2}$-quantile della distribuzione
normale. Ad esempio, per $\alpha=90\%$, lo $0.95$-quantile è uguale
a $1.64$.


\chapter{Teoria della stima}

Nel capitolo introduttivo è stato detto che lo scopo dell'induzione
statistica è quello di trarre delle conclusioni di validità generale
rispetto ad una o più caratteristiche di una popolazione obiettivo
partendo da un insieme limitato di osservazioni (campione). È stato
inoltre osservato come la validità di tali conclusioni non sia assoluta,
ma soggetta a continua verifica. Con l'arrivo di nuove informazioni
sarà necessario confermare alla luce della nuova evidenza empirica
quanto inferito precedentemente. L'inferenza statistica si occupa
quindi di due importanti problemi: la stima e la verifica d'ipotesi.
In questo capitolo ci occuperemo del problema di stima ed in particolare
della \emph{stima parametrica puntuale}.

\bigskip{}


\noindent Come descritto nel capitolo \ref{A ind stat}, assumeremo
che la caratteristica in esame della popolazione obiettivo possa essere
rappresentata da una variabile aleatoria $X$ a valori reali la cui
distribuzione è conosciuta a meno di un parametro $\theta$. In altre
parole si ipotizza che la distribuzione della variabile aleatoria
$X$ appartenga ad una famiglia di distribuzioni (cf. paragrafo \ref{modello parametrico})
\[
\mathcal{P}=\left\{ f_{\theta}(x),\ \theta\in\Theta\right\} \]
 dove $f_{\theta}(x)$ rappresenta la funzione di densità (caso continuo)
o di probabilità (caso discreto) di $X$. Per fisso $\theta$, la
forma della densità%
\footnote{Si parlerà semplicemente di densità intendendo qualora $X$ fosse
una $V.A.$ discreta la funzione di probabilità di $X$.%
} $f_{\theta}$ è dunque nota. Diremo che 
\begin{enumerate}
\item il modello parametrico è correttamente specificato se esiste un $\theta\in\Theta$,
notato $\theta_{0}$, tale per cui $f_{\theta_{0}}(x)$ corrisponde
alla \emph{vera funzione} di densità di $X$; 
\item $\theta_{0}$ è identificato, se per qualsiasi altro $\theta\in\Theta$
vale che $f_{\theta_{0}}\neq f_{\theta}$. 
\end{enumerate}
\noindent Il valore $\theta_{0}$ indica semplicemente quel particolare
valore di $\theta$ per cui $f_{\theta_{0}}$ coincide con la vera
densità di $X$. Se il parametro $\theta_{0}$ fosse conosciuto, la
funzione di densità (e quindi la distribuzione di $X$) sarebbe completamente
specificata ed in tal caso non sarebbe necessario ricorrere all'inferenza.
Tuttavia, non essendo questo il caso, dovremo, sulla base di un $n$-campione
di $X$, stimare il valore $\theta_{0}$. Abbiamo a questo punto due
possibilità:\ eseguire una stima puntuale di $\theta_{0}$ oppure
costruire un intervallo di confidenza per $\theta_{0}$. Ad esempio,
nel caso della stima del valore medio $\mu$ della popolazione abbiamo
stimato il valore atteso della $V.A$. $X$ sulla base del valore
assunto dalla statistica (stimatore) $\overline{X}_{n}$. La realizzazione
di $\overline{X}_{n}$, che notiamo con $\overline{x}_{n}$, è dunque
una stima puntuale di $\mu_{0}$. In generale indicheremo con $T(X_{1},X_{2},...,X_{n})$
la statistica utilizzata quale stimatore puntuale di $\theta_{0}$.
La seconda possibilità per stimare $\theta_{0}$ è quella di costruire
un intervallo di confidenza. In tal caso avremo bisogno di due statistiche,
che indicheremo con $I_{1}(X_{1},...,X_{n})$ e $I_{2}(X_{1},...,X_{n})$,
tali per cui $I_{1}<I_{2}$ per qualsiasi realizzazione di $X_{1},...,X_{n}$.
$I_{1}$ e $I_{2}$ sono gli estremi dell'intervallo aleatorio $I=\left[I_{1}(X_{1},...,X_{n})\ ,I_{2}(X_{1},...,X_{n})\right]$.
Nel paragrafo \ref{intervallo confidenza}, le due statistiche $I_{1}$
e $I_{2}$ ad un livello di confidenza del $95\%$ erano date da\[
I_{1}=\overline{X}_{n}-1.96\sqrt{V(\overline{X}_{n})}\text{ e }I_{2}=\overline{X}_{n}+1.96\sqrt{V(\overline{X}_{n})}.\]
 Questo secondo approccio per stimare il parametro sconosciuto è chiamato
stima per intervalli. In questo capitolo ci soffermeremo sulla stima
puntuale. Per tutto il presente capitolo, salvo indicato diversamente,
assumeremo che 
\begin{itemize}
\item $X$ è una variabile aleatoria con funzione di densità in $\mathcal{P}$,
cioè esiste un $\theta_{0}\in\Theta$ tale per cui\ $f_{\theta_{0}}(x)$
è la densità di $X$; 
\item $\theta_{0}$ è identificato; 
\item $\theta_{0}$ è sconosciuto; 
\item $X_{1},...,X_{n}$ è un $n$-campione di $X$. 
\end{itemize}
\noindent Le variabili aleatorie $X_{1},...,X_{n}$ saranno quindi
indipendenti ed identicamente distribuite con funzione di densità
$f_{\theta_{0}}$. Il nostro obiettivo consiste nel trovare delle
statistiche (funzioni di $X_{1},...,X_{n}$ e dunque $V.A.$) da usare
quali stimatori del parametro sconosciuto $\theta_{0}$.


\section{Il metodo dei momenti}

Iniziamo questo paragrafo con alcune definizioni.

\begin{definizione} \label{momento r-esimo}Momento $r$-esimo. Sia
$X$ una $V.A.$ con funzione di densità $f_{\theta}$. Il momento
$r$-esimo di $X$, notato $M_{r}$, è definito come\[
M_{r}=E(X^{r})\]
 ammesso che il valore atteso esista. \end{definizione}

\noindent Quando $r=1$, $M_{1}$ corrisponde al valore atteso di
$X$ che indicheremo semplicemente come d'abitudine con $\mu$. $M_{2}$
è il secondo momento di $X$ che ritroviamo ad esempio nella formula
alternativa della varianza di $X$\[
V(X)=E(X^{2})-\mu^{2}\text{.}\]
 Utilizzando questa nuova notazione, $V(X)$ può dunque essere scritta
come $M_{2}-\mu^{2}$.\bigskip{}


\begin{remark} Per una variabile aleatoria $X$ distribuita simmetricamente%
\footnote{$X$ possiede una distribuzione simmetrica rispetto allo $0$ se $f(x)=f(-x)$.%
} attorno allo $0$ e tale per cui $E\left(\mid X^{r}\mid\right)<\infty$,
gli $r$-esimi momenti dispari sono tutti uguali a $0$. \end{remark}

\bigskip{}
 L'$r$-esimo momento di una variabile aleatoria $X$ non è altro
che il valore atteso della variabile aleatoria $Y$, dove $Y:=g(X)$
con \[
g:\mathbb{R}\rightarrow\mathbb{R}\text{, }x\mapsto y=x^{r}\text{.}\]
 Dal corso di Statistica I sappiamo che il valore atteso di $Y$ può
essere calcolato come\begin{equation}
E(Y)=E\left(X^{r}\right)=\int_{-\infty}^{\infty}x^{r}f_{\theta}(x)dx\text{.}\label{momento r}\end{equation}
 Come intuibile dalla (\ref{momento r}) (verificate nell'Esempio
\ref{esempio momenti distrib poisson}), il valore di $M_{r}=\int_{-\infty}^{\infty}x^{r}f_{\theta}(x)dx$
dipenderà dal particolare valore del parametro sconosciuto $\theta$.
Quando necessario espliciteremo la dipendenza di $M_{r}$ dal parametro
sconosciuto $\theta$ scrivendo semplicemente $M_{r}(\theta)$.

\noindent \begin{esempio} Supponiamo che la variabile aleatoria $X$
sia distribuita secondo la legge normale $N(0,\sigma^{2})$ dove la
varianza $\sigma^{2}$ della distribuzione è sco\-no\-sciu\-ta.
In questo caso il parametro sconosciuto $\theta$ corrisponde alla
varianza $\sigma^{2}$. Consideriamo il quarto momento \begin{equation}
M_{4}=E\left(X^{4}\right)=\int_{-\infty}^{\infty}x^{4}\frac{1}{\sqrt{2\pi\sigma^{2}}}\exp\left(-\frac{1}{2}\frac{x^{2}}{\sigma^{2}}\right)dx\ .\label{integrale quarto momento}\end{equation}
 Anziché calcolare direttamente l'integrale (\ref{integrale quarto momento})
definiamo la $V.A.$ $Z$ \[
Z=\frac{X}{\sigma}\sim N(0,1).\]
 Utilizzando l'integrazione per parti (si veda il suggerimento), è
semplice calcolare il valore atteso di \begin{eqnarray*}
E\left(Z^{4}\right) & = & \int_{-\infty}^{\infty}z^{4}\frac{1}{\sqrt{2\pi}}\exp\left(-\frac{1}{2}z^{2}\right)dz\ \\
 & = & \int_{-\infty}^{\infty}\underset{v}{\underbrace{z^{3}}}\ \underset{u^{\prime}}{\ \underbrace{z\frac{1}{\sqrt{2\pi}}\exp\left(-\frac{1}{2}z^{2}\right)}}dz.\\
 & = & ...=3\end{eqnarray*}
 Da cui otteniamo \[
3=E\left(Z^{4}\right)=E\left(\left(\frac{X}{\sigma}\right)^{4}\right)=\frac{1}{\sigma^{4}}E\left(X^{4}\right)\]
 cioè\[
M_{4}=E\left(X^{4}\right)=3\sigma^{4}=3\left(\sigma^{2}\right)^{2}.\]
 \end{esempio}

\begin{definizione} \label{momento r-esimo centrato}Momento $r$-esimo
centrato. Il momento $r$-esimo \emph{centrato} di $X$, notato $M_{r}^{c}$
è definito come\[
M_{r}^{c}=E\left(\left(X-\mu\right)^{r}\right)\text{.}\]
 \end{definizione}

\bigskip{}
 Il primo momento centrato di $X$ è dunque uguale a $0$. Il secondo
momento centrato è la varianza di $X$, da cui segue come appena visto
l'uguaglianza\[
M_{2}^{c}=M_{2}-\mu^{2}\text{.}\]
 Se $X$ è simmetrica rispetto al suo valore atteso e tale per cui
$E\left(\mid X^{r}\mid\right)<\infty$ allora tutti i momenti centrati
di ordine dispari saranno uguali a $0$.

\noindent \begin{remark} (Curiosità.) Esiste la seguente relazione
tra i momenti $M_{r}$ ed i momenti centrati $M_{r}^{c}$\[
M_{r}^{c}=\sum_{i=0}^{r}\left(-1\right)^{i}\ C_{r}^{i}\ \mu^{i}\ M_{r-i}\]
 dove $C_{r}^{i}=\frac{r!}{i!(r-i)!}$ è il coefficiente binomiale.
\end{remark}

\begin{esempio} \label{esempio momenti distrib poisson}Sia $X_{1},...,X_{n}$
un $n$-campione estratto da una distribuzione di Poisson. La famiglia
parametrica $\mathcal{P}$ di $X$ è data da \[
\mathcal{P}=\left\{ f_{\theta}(x)=\frac{\theta^{x}e^{-\theta}}{x!},\ x\in\left\{ 0,1,...\right\} ,\ \theta\in\mathbb{R}^{+}\right\} \text{.}\]
 Il momento $M_{1}$ è semplicemente il valore atteso di $X$ che
solitamente notiamo con $\mu$:\begin{equation}
\mu=\sum_{x=0}^{\infty}x\frac{\theta^{x}e^{-\theta}}{x!}=\theta\text{.}\label{esempio poisson 1}\end{equation}
 Il secondo momento $M_{2}$ è invece \begin{equation}
M_{2}=\sum_{x=0}^{\infty}x^{2}\frac{\theta^{x}e^{-\theta}}{x!}=\theta+\theta^{2}\text{.}\label{esempio poisson 2}\end{equation}
 Infine, per il terzo momento $M_{3}$ vale\begin{equation}
M_{3}=\sum_{x=0}^{\infty}x^{3}\frac{\theta^{x}e^{-\theta}}{x!}=\theta+3\theta^{2}+\theta^{3}\text{.}\end{equation}
 Come potete constatare sia $M_{1}$ che $M_{2}$ sono particolari
funzioni del parametro $\theta$. \end{esempio}

\noindent Le Definizioni \ref{momento r-esimo} e \ref{momento r-esimo centrato}
considerano i momenti teorici della popolazione (o di una variabile
aleatoria $X$). È tuttavia possibile estendere la definizione di
$r$-esimo momento ad un $n$-campione $X_{1},...,X_{n}$.

\begin{definizione} Momenti campionari. Sia $X_{1},...,X_{n}$ un
$n$-campione estratto da una popolazione $X$. Il momento campionario
$r$-esimo, notato $\widehat{M}_{r,n}$, è definito come\[
\widehat{M}_{r,n}=\frac{1}{n}\sum_{i=1}^{n}X_{i}^{r}\text{.}\]
 \end{definizione}

\noindent Il primo momento campionario corrisponde a $\overline{X}_{n}$,
la media del campione. Analogamente alla Definizione \ref{momento r-esimo centrato}
il momento campionario $r$-esimo centrato è definito come\[
\widehat{M}_{r,n}^{c}=\frac{1}{n}\sum_{i=1}^{n}\left(X_{i}-\overline{X}_{n}\right)^{r}\text{.}\]


\noindent Il secondo momento campionario centrato $\widehat{M}_{2,n}^{c}=\frac{1}{n}\sum_{i=1}^{n}\left(X_{i}-\overline{X}_{n}\right)^{2}$
è l'equivalente \emph{empirico} di $\sigma^{2}$, la varianza di $X$.
È interessante osservare che lo stimatore $S^{2}$ della varianza
è derivabile da $\widehat{M}_{2,n}^{c}$ tramite la semplice formula
\[
S^{2}=\frac{n}{n-1}\widehat{M}_{2,n}^{c}\text{.}\]
 Il fattore di proporzionalità $\frac{n}{n-1}$ tende a $1$ al crescere
della numerosità $n$ del campione.

\begin{remark} Sia $\widehat{M}_{r,n}$ che $\widehat{M}_{r,n}^{c}$
sono delle statistiche (delle funzioni di $X_{1},...,X_{n}$ che possono
essere calcolate in quanto non dipendono da nessun parametro sconosciuto)
e quindi sono esse stesse delle variabili aleatorie. In generale non
è possibile ricavare analiticamente la distribuzione di queste statistiche
tuttavia per alcuni valori di $r$ è possibile calcolarne il valore
atteso e/o la varianza. \end{remark}


\subsection{Convergenza dei momenti campionari}

La proprietà fondamentale che caratterizza i momenti campionari è
la loro convergenza verso il rispettivo momento teorico. Più precisamente
vale il seguente teorema.

\bigskip{}


\begin{theorem} \label{teorema convergenza momenti campionari}Sia
$X_{1},...,X_{n}$ un $n$-campione estratto da una popolazione $X$
avente i primi $r$-momenti finiti, ovvero:\ $E\left(X^{j}\right)=M_{j}$,
$j=1,\ldots,r$. Allora per qualsiasi $\varepsilon>0$ si avrà che\begin{equation}
\lim_{n\rightarrow\infty}P(|\widehat{M}_{r,n}-M_{r}|>\varepsilon)=0\text{.}\label{convergenza probabilita campione}\end{equation}
 \end{theorem}

\noindent Per fisso $\varepsilon>0$ con $\varepsilon$ piccolo a
piacere la probabilità $P(|\widehat{M}_{r,n}-M_{r}|\leq\varepsilon)$
corrisponde alla probabilità che il valore%
\footnote{Il valore che noi calcoleremo una volta osservate $X_{1},...,X_{n}$.%
} realizzato di $\widehat{M}_{r,n}$ cada in un intervallo di centro
$M_{r}$ e raggio $\varepsilon$. Il Teorema \ref{teorema convergenza momenti campionari}
afferma semplicemente che per quanto piccolo possa essere l'intervallo
attorno al vero valore del momento teorico $M_{r}$, al crescere di
$n$ all'infinito il valore calcolato del momento campionario (utilizzando
l' $n$-campione)\ sarà contenuto nell'intervallo stesso con probabilità
prossima ad $1$.


\subsection{Stimatore dei momenti}

Abbiamo ora tutti gli elementi necessari per definire lo stimatore
dei momenti e comprendere l'idea che lo caratterizza. Ricapitolando
abbiamo visto che 
\begin{itemize}
\item La distribuzione della variabile aleatoria $X$ è sconosciuta. Tuttavia
sappiamo che essa appartenere alla famiglia di distribuzioni\[
\mathcal{P}=\left\{ f_{\theta}(x),\ \theta\in\Theta\right\} \text{.}\]
 In particolare esiste un unico $\theta\in\Theta$, notato $\theta_{0}$,
tale per cui $f_{\theta_{0}}(x)$ è la funzione di densità di $X$. 
\item Per fisso $\theta\in\Theta$ possiamo calcolare l'$r$-esimo momento
(momento centrato) di $X$ che sarà notato $M_{r}(\theta)$ o rispettivamente
$M_{r}^{c}(\theta)$. 
\item Osservando un $n$-campione $X_{1},...,X_{n}$ estratto dalla popolazione
$X$ di densità $f_{\theta_{0}}$ possiamo calcolare l'$r$-esimo
momento (centrato) cam\-pio\-na\-rio $\widehat{M}_{r,n}$ ($\widehat{M}_{r,n}^{c}$).
Il limite per $n\rightarrow\infty$ di $\widehat{M}_{r,n}$ è uguale
al corrispettivo momento della popolazione $M_{r}(\theta_{0})$. Avremo
dunque\ \begin{equation}
\widehat{M}_{r,n}\simeq M_{r}(\theta_{0})\text{.}\label{approx momento}\end{equation}
 
\end{itemize}
\begin{esempio} \label{esempio M3 poisson}Supponiamo che la variabile
aleatoria $X$ possegga una distribuzione di Poisson. Abbiamo visto
che per $r=3$ vale la seguente relazione\[
M_{3}(\theta)=\theta+3\theta^{2}+\theta^{3}\text{.}\]
 Questo significa che per $n$ sufficientemente grande avremo \[
\widehat{M}_{3,n}\simeq M_{3}(\theta_{0})=\theta_{0}+3\theta_{0}^{2}+\theta_{0}^{3}\]
 \end{esempio}

\noindent L'approssimazione (\ref{approx momento}) è il punto di
partenza dal quale costruire lo stimatore. Il lato sinistro della
(\ref{approx momento}) è calcolabile una volta che il campione $X_{1},...,X_{n}$
è osservato. Il lato destro invece contiene il parametro incognito
$\theta_{0}$. Possiamo però tentare di risolvere {}``l'equazione\textquotedblright{}\ (\ref{approx momento})
rispetto a $\theta_{0}$ ottenendo così un'approssimazione (stima)
di $\theta_{0}$ che indicheremo $\widehat{\theta}$. Nel caso dell'Esempio
\ref{esempio M3 poisson} supponiamo che il valore realizzato di $\widehat{M}_{3,n}$
sia uguale $1$. Vale dunque \begin{equation}
\widehat{M}_{3,n}=1\simeq M_{3}(\theta_{0})=\theta_{0}+3\theta_{0}^{2}+\theta_{0}^{3}.\label{nuova equazione secondo momento 0}\end{equation}
 Risolvendo rispetto a $\theta_{0}$ otteniamo le tre soluzioni $\sqrt{2}-1,-\sqrt{2}-1,-1$
di cui solo la prima è ammissibile in quanto nel caso della distribuzione
di Poisson $\theta\in\left(0,\infty\right)$. Poiché la soluzione
è solo un'approssimazione del vero valore scriveremo \[
\widehat{\theta}=\sqrt{2}-1\]
 e non $\theta_{0}=\sqrt{2}-1$.

\noindent Cambiando l'ordine $r$ del momento cambia sia la relazione
che lega il valore teorico del momento al valore del parametro sia
il valore stimato del momento empirico corrispondente. Ad esempio,
se nell'Esempio \ref{esempio M3 poisson} anziché utilizzare il terzo
momento utilizzassimo il secondo momento, otterremmo la seguente situazione\begin{equation}
\widehat{M}_{2,n}\simeq M_{2}(\theta_{0})=\theta_{0}+\theta_{0}^{2}.\label{nuova equazione secondo momento}\end{equation}
 Con lo stesso $n$-campione utilizzato in precedenza per calcolare
$\widehat{M}_{3,n}$ potremmo calcolare $\widehat{M}_{2,n}$ ed utilizzare
tale valore per risolvere la (\ref{nuova equazione secondo momento})
ottenendo così una nuova stima $\widehat{\theta}$ di $\theta_{0}$
che molto verosimilmente sarà diversa dalla precedente. Prendendo
ad esempio $\widehat{M}_{2,n}=0.39$ avremmo quale unica soluzione
ammissibile $\widehat{\theta}=0.3$ che è diversa dalla soluzione
precedente. In questo caso $\widehat{\theta}$ sarebbe lo stimatore
dei momenti di $\theta_{0}$ basato sul secondo momento.

Risolvere le equazioni (\ref{nuova equazione secondo momento 0})
e (\ref{nuova equazione secondo momento}) corrisponde, in pratica,
a trovare l'inversa della funzione dei momenti\[
M_{r}(\cdot):\Theta\rightarrow\mathbb{R}\ ,\ \theta\mapsto M_{r}(\theta)\ .\]
 Infatti, applicando la funzione inversa $M_{r}^{-1}$ ad ambo i lati
della (\ref{approx momento}) otteniamo\begin{equation}
M_{r}^{-1}(\widehat{M}_{r,n})\simeq M_{r}^{-1}\left(M_{r}(\theta_{0})\right)=\theta_{0}\text{.}\end{equation}
 La quantità $M_{r}^{-1}(\widehat{M}_{r,n})$ è calcolabile a condizione
che la funzione inversa $M_{r}^{-1}$ esista (l'equazione abbia un'unica
soluzione). La quantità $M_{r}^{-1}(\widehat{M}_{r,n})$ rappresenta
un'approssimazione (stima) del vero parametro $\theta_{0}.$ Come
già accennato precedentemente questo è il motivo per cui utilizzeremo
la notazione $\widehat{\theta}$ anziché $\theta_{0}$ nell'indicare
il valore stimato. Riassumendo, quando la funzione inversa $M_{r}^{-1}$
è disponibile in forma analitica lo stimatore col metodo dei momenti
di $\theta_{0}$ è uguale a \begin{equation}
\widehat{\theta}=M_{r}^{-1}(\widehat{M}_{r,n})\text{,}\label{approx momento inverso}\end{equation}
 altrimenti $\widehat{\theta}$ verrà calcolato quale soluzione rispetto
a $\theta$ dell'equazione\[
\widehat{M}_{r,n}=M_{r}(\theta)\]
 come visto ad esempio nel caso della distribuzione di Poisson e $r=2,3$.
Graficamente abbiamo la seguente interpretazione:

\begin{center}
Grafico 
\par\end{center}

\begin{esempio} \label{Stimatore momenti N_mu_sigma}Supponiamo che
$X_{1},...,X_{n}$ sia un campione casuale da una distribuzione normale
$N\left(\mu_{0},\sigma_{0}^{2}\right)$ il cui valore atteso $\mu_{0}$
e varianza $\sigma_{0}^{2}$ sono entrambi sconosciuti. La famiglia
parametrica di distribuzioni $\mathcal{P}$ è uguale \[
\mathcal{P}=\left\{ f_{\theta}(x)=\frac{1}{\sqrt{2\pi\sigma^{2}}}\exp\left(-\frac{1}{2\sigma^{2}}\left(x-\mu\right)^{2}\right),\ x\in\mathbb{R\ },\ \theta=(\mu,\sigma^{2})\in\mathbb{R}\times\mathbb{R}^{+}\right\} \]
 In questo esempio il parametro sconosciuto $\theta$ è costituito
da due elementi: $\theta=\left(\theta_{1},\theta_{2}\right)=\left(\mu,\sigma^{2}\right)$.
Parleremo perciò di due parametri sconosciuti. Sarà necessario utilizzare
due momenti distinti al fine di ottenere un sistema di due equazioni
e due incognite. Prendiamo arbitrariamente i primi due momenti $M_{1}$
e $M_{2}$ e costruiamo il seguente sistema di equazioni%
\footnote{Ricordiamo che \begin{eqnarray*}
\sigma^{2} & = & E(X^{2})-\left(E(X)\right)^{2}\\
 & = & M_{2}-\mu^{2}\end{eqnarray*}
 da cui si ricava facilmente\[
M_{2}=\sigma^{2}+\mu^{2}.\]
 %
} \begin{equation}
\left\{ \begin{array}{l}
\widehat{M}_{1,n}\simeq M_{1}\left(\mu,\sigma^{2}\right)=\mu\\
\widehat{M}_{2,n}\simeq M_{2}\left(\mu,\sigma^{2}\right)=\sigma^{2}+\mu^{2}\end{array}\right.\label{esempio momenti normale 1}\end{equation}
 Il primo momento campionario $\widehat{M}_{1,n}$ corrisponde a $\overline{X}_{n}$
mentre il secondo momento campionario $\widehat{M}_{2,n}$ è uguale
$\frac{1}{n}\sum_{i=1}^{n}X_{i}^{2}$. Trascurando l'errore d'approssimazione
riscriviamo il sistema precedente utilizzando l'uguaglianza stretta
così da ottenere il sistema a due equazioni e due incognite desiderato\[
\left\{ \begin{array}{l}
\overline{X}_{n}=\mu\\
\frac{1}{n}\sum_{i=1}^{n}X_{i}^{2}=\sigma^{2}+\mu^{2}\end{array}\right..\]
 Risolvendo rispetto a $\mu$ e $\sigma^{2}$ otteniamo lo stimatore
dei momenti di $\theta_{0}=(\mu_{0},\sigma_{0}^{2})$\begin{eqnarray*}
\widehat{\mu} & = & \overline{X}_{n}\\
\widehat{\sigma}^{2} & = & \frac{1}{n}\sum_{i=1}^{n}X_{i}^{2}-\left(\overline{X}_{n}\right)^{2}=\frac{1}{n}\sum_{i=1}^{n}\left(X_{i}-\overline{X}_{n}\right)^{2}\text{.}\end{eqnarray*}
 Lo stimatore dei momenti della varianza $\sigma^{2}$ di $X$ è diverso
da $S^{2}$ che sappiamo essere uno stimatore corretto. Infatti per
$\widehat{\sigma}^{2}$ vale che\begin{eqnarray*}
E\left(\widehat{\sigma}^{2}\right) & = & E\left(\frac{1}{n}\sum_{i=1}^{n}\left(X_{i}-\overline{X}_{n}\right)^{2}\right)=E\left(\frac{n-1}{n}\frac{1}{n-1}\sum_{i=1}^{n}\left(X_{i}-\overline{X}_{n}\right)^{2}\right)\\
 & = & \frac{n-1}{n}E\left(S^{2}\right)=\frac{n-1}{n}\sigma^{2}=\left(1-\frac{1}{n}\right)\sigma^{2}.\end{eqnarray*}
 La distorsione (Bias in inglese) di $\widehat{\sigma}^{2}$ quale
stimatore di $\sigma^{2}$ è uguale a\[
B(\widehat{\sigma}^{2})=E\left(\widehat{\sigma}^{2}\right)-\sigma^{2}=-\frac{1}{n}\sigma^{2}\text{.}\]
 Tuttavia, per $n\rightarrow\infty$ tale distorsione tende a $0$.
Diremo allora che $\widehat{\sigma}^{2}$ è uno stimatore asintoticamente
corretto di $\sigma^{2}$. \end{esempio}

\pagebreak


\section{Il metodo di massima verosimiglianza}

L'idea alla base del metodo di stima di massima verosimiglianza è
molto semplice ed intuitiva. Il seguente esempio (preso da A. Mood,
F. Graybill e D. Boes, Introduzione alla statistica,\ McGraw-Hill,
ISBN 88-386-0661-7) è illuminante.

\bigskip{}


\noindent Supponiamo che un'urna contenga un certo numero di palle
nere e un certo numero di palle bianche, e supponiamo che si sappia
che il rapporto fra i due numeri è di $3/1$, ma che non si sappia
se le palle più numerose siano le nere o le bianche. In altre parole,
la probabilità di estrarre una palla nera è\ $1/4$ oppure $3/4$.
Se si estraggono dall'urna con reimmissione $n$ palle, la distribuzione
di $X$, la variabile aleatoria che denota il numero di palle nere
presenti nel campione, è data dalla distribuzione binomiale\[
f_{p}(x)=C_{n,x}\ p^{x}q^{n-x}\ \ \ \ \ \ \text{per }x=0,1,2,...,n,\]
 dove $q=1-p$ e $p$ è la probabilità di estrarre una palla nera.
In questo caso $p=1/4$ oppure $p=3/4$. Estrarremo con reimmissione
un campione di tre palle, cioè $n=3$ e tenteremo di stimare il parametro
incognito $p$ della distribuzione. Il problema di stima è particolarmente
semplice in questo caso perché dobbiamo solo scegliere fra $p=.25$
oppure $p=0.75$. Anticipiamo i risultati dell'estrazione del campione.
Si danno di seguito gli esiti possibili e le loro probabilità:\[
\begin{tabular}{c|c|c|c|c}
\hline  Esito: \ensuremath{x} &  \ensuremath{0} &  \ensuremath{1} &  \ensuremath{2} &  \ensuremath{3}\\
\hline \ensuremath{f_{\frac{3}{4}}(x)} &  \ensuremath{\frac{1}{64}} &  \ensuremath{\frac{9}{64}} &  \ensuremath{\frac{27}{64}} &  \ensuremath{\frac{27}{64}}\\
\hline \ensuremath{f_{\frac{1}{4}}(x)} &  \ensuremath{\frac{27}{64}} &  \ensuremath{\frac{27}{64}} &  \ensuremath{\frac{9}{64}} &  \ensuremath{\frac{1}{64}}\\\hline \end{tabular}\]
 In questo esempio, se trovassimo $x=0$ su un campione di $3$ estrazioni,
sarebbe da preferire la stima $p=0.25$ rispetto a $p=0.75$, perché
la probabilità $27/64$ è maggiore di $1/64$, cioè perché un campione
con $x=0$ è estratto più probabilmente (nel senso di avere una maggiore
probabilità) da una popolazione con $p=1/4$ piuttosto che da una
con $p=3/4$. E in generale dovremmo stimare $p=0.25$ quando $x=0$
o $x=1$ e $p=0.75$ quando $x=2$ o $x=3$. Lo stimatore può quindi
essere definito come\[
\widehat{p}=\widehat{p}(x)=\left\{ \begin{array}{cc}
0.25 & \text{per }x=0,1\\
0.75 & \text{per }x=2,3\end{array}\right..\]
 Lo stimatore {}``decide\textquotedblright{}\ così il valore di
$p$, notato $\widehat{p}$, per ogni possibile $x$, in modo tale
che \[
f_{\widehat{p}}(x)>f_{p^{\prime}}(x),\]
 dove $p^{\prime}$ è il valore alternativo di $p$.

\noindent Più in generale, se fossero possibili più valori alternativi
di $p$, potremmo ragionevolmente procedere nella stessa maniera.
Così se noi trovassimo $x=6$ in un campione di ampiezza $25$ estratto
da una popolazione binomiale, dovremmo sostituire tutti i possibili
valori di $p$ nell'espressione\begin{equation}
f_{p}(6)=C_{25,6}\ p^{6}(1-p)^{19}\ \ \ \ \ \text{per }0\leq p\leq1\text{.}\label{stima max likel iniziale}\end{equation}


\noindent Si può trovare la posizione del massimo ponendo la derivata
della funzione (\ref{stima max likel iniziale}) rispetto a $p$ uguale
a $0$ e risolvendo rispetto a $p$ l'equazione risultante. È immediato
verificare che \[
\frac{\partial}{\partial p}f_{p}(6)=C_{25,6}\ p^{5}(1-p)^{18}\left[6(1-p)-19p\right].\]
 Ponendo $\frac{\partial}{\partial p}f_{p}(6)=0$ e risolvendo rispetto
a $p$ troviamo le radici $p=0,1,6/25$. Le prime due radici danno
un minimo della funzione e quindi vanno scartate. Quindi la nostra
stima sarà $\widehat{p}=6/25$. Questa stima ha la proprietà che \[
f_{\widehat{p}}(6)>f_{p^{\prime}}(6)\]
 per qualsiasi altro valore di $p$ nell'intervallo $\left[0,1\right]$.

\bigskip{}


\noindent La definizione di stimatore di massima verosimiglianza necessita
dapprima la definizione di funzione di verosimiglianza.\bigskip{}


\begin{definizione} \label{definizione funzione di verosimiglianza}Funzione
di verosimiglianza. Si dice funzione di verosimiglianza di $n$ variabili
casuali $X_{1},...,X_{n}$ la densità congiunta delle $n$ variabili
casuali, $f_{X_{1},...,X_{n}}(x_{1},...,x_{n};\theta),$ \emph{considerate
come funzione di }$\theta$. In particolare, se $X_{1},...,X_{n}$
è un $n$-campione estratto dalla popolazione $X$ di densità $f(x;\theta)$,
la funzione di verosimiglianza è semplicemente il prodotto delle densità
$f(x_{1};\theta)\ f(x_{2};\theta)...f(x_{n};\theta).$\bigskip{}
 \end{definizione}

\begin{remark} Per ricordarci che la funzione di verosimiglianza
è una funzione di $\theta$, utilizziamo per tale funzione la notazione
$L(\theta;x_{1},...,x_{n})$ oppure $L(\cdot;x_{1},...,x_{n})$.\bigskip{}
 \end{remark}

\noindent La funzione di verosimiglianza $L(\theta;x_{1},...,x_{n})$
fornisce la {}``verosimiglianza\textquotedblright{}\ che le variabili
aleatorie $X_{1},...,X_{n}$ assumano il particolare valore osservato
$x_{1},...,x_{n}$. La \emph{verosimiglianza} è dunque il valore della
funzione di densità congiunta valutata in $x_{1},...,x_{n}$; per
variabili aleatorie discrete corrisponde a una probabilità. Osservati
$x_{1},...,x_{n}$ la funzione di verosimiglianza dipende unicamente
da $\theta$, il parametro sconosciuto. Se la funzione $L(\theta;x_{1},...,x_{n})$
possiede un massimo, tale massimo verrà indicato con $\widehat{\theta}$
e scriveremo \begin{equation}
\widehat{\theta}=\underset{\theta\in\Theta}{\arg\max}L(\theta;x_{1},...,x_{n})\end{equation}
 per sottolineare che $\widehat{\theta}$ è la soluzione di un problema
di massimizzazione. Il valore di $\widehat{\theta}$ dipenderà ovviamente
dai valori osservati $x_{1},...,x_{n}$ (dalle realizzazioni delle
$V.A.$ $X_{1},...,X_{n}$). $\widehat{\theta}$ è dunque una funzione
di $x_{1},...,x_{n}$: potremo allora scrivere $\widehat{\theta}=T_{mv}(x_{1},...,x_{n})$.
La statistica $T_{mv}(X_{1},...,X_{n})$ sarà chiamata stimatore di
massima verosimiglianza di $\theta$.\bigskip{}


\begin{definizione} Stimatore di massima verosimiglianza. Sia \begin{equation}
L(\theta)=L(\theta;x_{1},...,x_{n})\end{equation}
 la funzione di verosimiglianza delle variabili casuali $X_{1},X_{2},...,X_{n}$.
Se $\widehat{\theta}$ {[}dove $\widehat{\theta}=T_{mv}(x_{1},...,x_{n})\ $è
una funzione delle osservazioni $x_{1},...,x_{n}${]} è il valore
di $\theta$ in $\Theta$ che massimizza $L(\theta)$, allora $T_{mv}(X_{1},...,X_{n})$
è lo \emph{stimatore di massima verosimiglianza} di $\theta$. $\widehat{\theta}=T_{mv}(x_{1},...,x_{n})$
è la \emph{stima} di massima verosimiglianza di $\theta$ sulla base
della realizzazione $x_{1},...,x_{n}$ dell'$n$-campione $X_{1},X_{2},...,X_{n}$.
\end{definizione}

\noindent Come già detto nei capitoli precedenti in questo corso tratteremo
esclusivamente il caso in cui le variabili casuali $X_{1},...,X_{n}$
costituiscono un $n$-campione, ovvero quando esse formano un campione
casuale semplice estratto con reimmissione da una popolazione $X$
avente funzione di densità $f_{\theta}$. Le variabili casuali $X_{1},...,X_{n}$
saranno quindi indipendenti fra loro ed identicamente distribuite.
Come già osservato nella definizione (\ref{definizione funzione di verosimiglianza})
di funzione di verosimiglianza, grazie all'indipendenza delle $V.A.$
$X_{1},...,X_{n}$ la funzione di verosimiglianza si riduce al seguente
prodotto di densità\[
L(\theta)=f(x_{1};\theta)\ f(x_{2};\theta)...f(x_{n};\theta).\]
 Se la funzione di verosimiglianza $L(\theta)$ soddisfa determinate
\emph{condizioni di regolarità}, lo stimatore di massima verosimiglianza
sarà soluzione dell'equazione\[
\frac{\partial}{\partial\theta}L(\theta)=0\text{.}\]


\noindent Ricordiamo che il logaritmo naturale $\ln()$ è una funzione
monotona crescente \ (cf. il suo grafico). Questo significa che gli
estremi della funzione di verosimiglianza $L(\theta)$ e della cosiddetta
$\log$-verosimiglianza sono gli stessi. Pertanto è indifferente ai
fini della massimizzazione della funzione di verosimiglianza massimizzare
la stessa $L(\theta)$ oppure il suo logaritmo $\ln L(\theta)$.

\bigskip{}


\noindent Se il numero di parametri sconosciuti anziché uno è $k$,
la funzione di vero\-si\-miglianza dipenderà da $\theta_{1},\theta_{2},...\theta_{k}$
e scriveremo\[
L(\theta_{1},\theta_{2},...\theta_{k})=\prod_{i=1}^{n}f_{\theta_{1},\theta_{2},...,\theta_{k}}(x_{i})\text{.}\]
 La funzione di verosimiglianza dovrà essere massimizzata rispetto
ai $k$ parametri. Come nel caso di un singolo parametro sconosciuto,
il massimo della funzione di verosimiglianza sarà soluzione del sistema
di equazioni\[
\left\{ \begin{array}{c}
\frac{\partial}{\partial\theta_{1}}L(\theta_{1},\theta_{2},...,\theta_{k})=0\\
\frac{\partial}{\partial\theta_{2}}L(\theta_{1},\theta_{2},...,\theta_{k})=0\\
\vdots\\
\frac{\partial}{\partial\theta_{k}}L(\theta_{1},\theta_{2},...,\theta_{k})=0.\end{array}\right.\]
 Qualora invece decidessimo di massimizzare il logaritmo di $L(\theta_{1},\theta_{2},...,\theta_{k})$
avremo \[
\left\{ \begin{array}{c}
\frac{\partial}{\partial\theta_{1}}\ln L(\theta_{1},\theta_{2},...,\theta_{k})=0\\
\frac{\partial}{\partial\theta_{2}}\ln L(\theta_{1},\theta_{2},...,\theta_{k})=0\\
\vdots\\
\frac{\partial}{\partial\theta_{k}}\ln L(\theta_{1},\theta_{2},...,\theta_{k})=0.\end{array}\right.\]
 In entrambi i casi indicheremo con $\widehat{\theta}_{i}=T_{mv,i}(X_{1},...,X_{n})$,
$i=1,...,k$ i valori che massimizzano la funzione di verosimiglianza
$L(\theta_{1},\theta_{2},...,\theta_{k})$.

\begin{esempio} \label{massimo vero bernoulli}Supponiamo di estrarre
con reimmissione un campione casuale semplice di numerosità $n$ da
un'urna contenente una certa frazione $p$ di palline rosse e $q=(1-p)$
di palline bianche. Sia $X$ definita da\[
X=\left\{ \begin{array}{cl}
1 & \text{se la pallina estratta è rossa,}\\
0 & \text{altrimenti.}\end{array}\right.\]
 $X$ è dunque distribuita secondo la distribuzione di Bernoulli.
La famiglia parametrica $\mathcal{P}$ è data da\[
\mathcal{P}=\left\{ f_{p}(x),\ p\in\left[0,1\right]\right\} \text{,}\]
 con \[
f_{p}(x)=\left\{ \begin{array}{cl}
p & \text{se }x=1,\\
q & \text{se }x=0,\\
0 & \text{altrimenti.}\end{array}\right.\]
 Le realizzazioni campionarie $x_{1},...,x_{n}$ di $X_{1},...,X_{n}$
formeranno una successione di $0$ e di $1.$ Poiché $x_{1}$ sarà
uguale a $0$ o $1$, possiamo anche scrivere che \begin{equation}
f_{p}(x_{1})=p^{x_{1}}q^{1-x_{1}}.\label{densita bernoulli}\end{equation}
 Infatti, se $x_{1}=1$, $f_{p}(1)=p^{1}q^{1-1}=p$ mentre se $x_{1}=0$,
$f_{p}(0)=p^{0}q^{1-0}=q$. Poiché le $n$ variabili aleatorie $X_{1},...,X_{n}$
sono indipendenti, la funzione di verosimiglianza è il prodotto delle
$n$ densità per cui grazie alla (\ref{densita bernoulli}) otteniamo
\begin{eqnarray*}
L(p) & = & \prod_{i=1}^{n}f_{p}(x_{i})=\prod_{i=1}^{n}p^{x_{i}}q^{1-x_{i}}\\
 & = & p^{\sum x_{i}}q^{n-\sum x_{i}}\text{.}\end{eqnarray*}
 Ponendo $y=\sum_{i=1}^{n}x_{i}$ otteniamo%
\footnote{$y$ corrisponde quindi al numero di palline rosse estratte.%
} che la $\log$-verosimiglianza è uguale a\[
\ln L(p)=y\ln p+(n-y)\ln q\text{.}\]
 Volendo massimizzare la funzione di $\log$-verosimiglianza rispetto
al parametro sconosciuto $p$ poniamo la sua derivata prima uguale
a zero:\[
\frac{\partial\ln L(p)}{\partial p}=\frac{y}{p}-\frac{n-y}{1-p}\overset{!}{=}0.\]
 Risolvendo quest'ultima equazione rispetto a $p$ otteniamo lo stimatore
di massima verosimiglianza \[
\widehat{p}=\frac{y}{n}=\frac{1}{n}\sum_{i=1}^{n}x_{i}=\overline{x}\text{.}\]
 Verifichiamo che il punto estremo così calcolato sia effettivamente
un punto di massimo:\begin{eqnarray*}
\frac{\partial^{2}\ln L(p)}{\partial p^{2}} & = & -\frac{y}{p^{2}}-\frac{n-y}{\left(1-p\right)^{2}}\\
 & = & ...\\
 & = & \frac{-p^{2}+2\overline{x}p-\overline{x}}{np^{2}\left(1-p\right)^{2}}\end{eqnarray*}
 È immediato verificare che la derivata seconda nel punto $p=\widehat{p}=\overline{x}$
è uguale a $\overline{x}^{2}-\overline{x}<0$. In $\widehat{p}$ la
funzione di verosimiglianza ha dunque un massimo. \end{esempio}

\begin{remark} In questo caso lo stimatore di massima verosimiglianza
di $p$ coincide con la media campionaria che intuitivamente dovrebbe
essere la stima di questo parametro. \end{remark}

\begin{esempio} Due parametri sconosciuti. Supponiamo di estrarre
un campione casuale semplice di numerosità $n=4$ da una popolazione
normale $N(\mu_{0},\sigma_{0}^{2})$ con entrambi $\mu_{0}$ e $\sigma_{0}^{2}$
sconosciuti. I valori osservati di $X_{1},...,X_{4}$ sono $x_{1}=3$,
$x_{2}=-3$, $x_{3}=5$, $x_{4}=-2$. La famiglia parametrica è uguale
a \[
\mathcal{P}=\left\{ f_{\theta}(x)=\frac{1}{\sqrt{2\pi\sigma^{2}}}\exp\left(-\frac{1}{2\sigma^{2}}\left(x-\mu\right)^{2}\right),\ \theta=(\mu,\sigma^{2})\in\mathbb{R}\times\mathbb{R}^{+}\right\} .\]
 In questo esempio la funzione di massima verosimiglianza $L(\mu,\sigma^{2})$
è data ancora una volta dal prodotto delle $4$ densità\begin{eqnarray*}
L(\mu,\sigma^{2}) & = & \prod_{i=1}^{4}f_{\mu,\sigma^{2}}(x_{i})\\
 & = & \left(\frac{1}{2\pi\sigma^{2}}\right)^{4/2}\exp\left(-\frac{1}{2\sigma^{2}}\left[\left(3-\mu\right)^{2}+\left(-3-\mu\right)^{2}+\left(5-\mu\right)^{2}+\left(-2-\mu\right)^{2}\right]\right)\end{eqnarray*}
 Come già visto nell'Esempio \ref{massimo vero bernoulli} passando
alla $\log$-verosimiglianza si ottiene un'espressione più accessibile\begin{eqnarray*}
\ln L(\mu,\sigma^{2}) & = & -2\ln(2\pi)-2\ln(\sigma^{2})+\\
 &  & -\frac{1}{2\sigma^{2}}\left[\left(3-\mu\right)^{2}+\left(-3-\mu\right)^{2}+\left(5-\mu\right)^{2}+\left(-2-\mu\right)^{2}\right].\end{eqnarray*}
 Quest'ultima espressione andrà massimizzata in funzione di $\mu$
e $\sigma^{2}$. \end{esempio}


\section{Proprietà degli stimatori puntuali}

Nei paragrafi precedenti abbiamo derivato il metodo dei momenti ed
il metodo di massima verosimiglianza quali metodi possibili per ricavare
degli stimatori puntuali. Ovviamente non sono questi gli unici metodi
di stima. Lo stimatore dei minimi quadrati la cui presentazione è
rimandata al corso di Introduzione all'Econometria potrebbe essere
un ulteriore esempio. Vista l'abbondanza di stimatori la domanda che
vogliamo affrontare in questo paragrafo è la seguente: $``$Dati due
stimatori esiste un modo per decidere quale dei due è il migliore?\textquotedblright{}.
Per decidere questo definiremo alcune proprietà che uno stimatore
può possedere oppure no. Esse ci aiuteranno a decidere se uno stimatore
è migliore di un altro.

\bigskip{}


\noindent Nel paragrafo \ref{modello parametrico} abbiamo definito
la proprietà di correttezza (cf. Definizione \ref{definizione di stimatore corretto})
di uno stimatore. Se uno stimatore non è corretto è possibile quantificare
il suo grado di distorsione.

\begin{definizione} \bigskip{}
 Distorsione (Bias). Sia $T(X_{1},...,X_{n})$ uno stimatore di $\theta$.
La distorsione di $T(X_{1},...,X_{n})$, notata $B(T)$, è difinita
come \[
B(T):=E\left(T(X_{1},...,X_{n})\right)-\theta\text{.}\]
 \end{definizione}

\noindent Il Bias di uno stimatore corretto è ovviamente $0$. Per
campioni finiti il bias di uno stimatore $T(X_{1},...,X_{n})$ può
essere funzione del numero $n$ di osservazioni. Lo stimatore dei
momenti $\widehat{\sigma}^{2}$ della varianza di una distribuzione
$N(\mu,\sigma^{2})$, $\mu$ e $\sigma^{2}$ entrambi sconosciuti,
derivato nell'Esempio \ref{Stimatore momenti N_mu_sigma}\ lo dimostra.
Nel me\-de\-si\-mo esempio abbiamo studiato il comportamento asintotico
(per $n\rightarrow\infty$) della distorsione. Lo studio del comportamento
asintotico di uno stimatore e delle sue proprietà è molto importante
in quanto per $n$ finito la funzione di distribuzione di $T_{n}$
non è generalmente conosciuta%
\footnote{Finora avete incontrato stimatori relativamente semplici quali la
media cam\-pio\-na\-ria $\overline{X}_{n}$ o $S^{2}$, per i quali
è possibile calcolare i momenti pur non conoscendo la famiglia parametrica
di densità utilizzata. Tuttavia essi sono dei casi particolari. In
generale anche il semplice calcolo di $E(T(X_{1},...,X_{n}))$ può
risultare assai complesso o addirittura impossibile.%
}. Per tale motivo si è costretti a confrontare gli stimatori sulla
base delle loro \emph{proprietà asintotiche} il cui calcolo è possibile
grazie a teoremi quali la legge dei grandi numeri e il teorema del
limite centrale (a tal proposito su veda il paragrafo \ref{elementi di teoria asintotica}
dedicato alla teoria asintotica).

\bigskip{}


\noindent La correttezza di uno stimatore è una proprietà importante
ma non fondamentale per la determinazione del miglior stimatore. Come
è stato visto nelle serie di esercizi esiste in genere più di uno
stimatore corretto dello stesso parametro. Per tale motivo la correttezza
non è un criterio sufficiente per individuare quale sia lo stimatore
migliore fra due o più stimatori dello stesso parametro. Per trovare
una soluzione al nostro problema consideriamo la seguente situazione.
Sia $X_{1},X_{2}$ e $X_{3}$ un campione aleatorio estratto da una
popolazione normale $N(\mu,1)$. Sono proposti i seguenti stimatori
\[
\begin{array}{ll}
\widehat{\mu}_{1}=\frac{X_{1}+X_{2}}{2} & \Rightarrow E(\widehat{\mu}_{1})=\mu,\\
\widehat{\mu}_{2}=\frac{X_{1}+X_{2}+X_{3}}{3} & \Rightarrow E(\widehat{\mu}_{2})=\mu,\\
\widehat{\mu}_{3}=\frac{X_{1}+2X_{2}+X_{3}}{4} & \Rightarrow E(\widehat{\mu}_{3})=\mu,\\
\widehat{\mu}_{4}=X_{1} & \Rightarrow E(\widehat{\mu}_{4})=\mu,\\
\widehat{\mu}_{5}=\frac{1}{9}\left(X_{1}+X_{2}+X_{3}\right) & \Rightarrow E(\widehat{\mu}_{5})=\frac{1}{3}\mu.\end{array}\]
 I primi quattro stimatori sono tutti stimatori corretti di $\mu$.
L'ultimo per contro è distorto, con un termine di distorsione pari
a $B(\widehat{\mu}_{5})=\frac{1}{3}\mu-\mu=-\frac{2}{3}\mu$. Qual
è dunque il migliore? Notiamo che i cinque stimatori hanno varianze
diverse. Infatti\[
V\left(\widehat{\mu}_{1}\right)=\frac{1}{2},~V\left(\widehat{\mu}_{2}\right)=\frac{1}{3},~V\left(\widehat{\mu}_{3}\right)=\frac{3}{8},~V\left(\widehat{\mu}_{4}\right)=1,~V\left(\widehat{\mu}_{5}\right)=\frac{1}{27}.\]
 Fra i primi quattro stimatori corretti quello con la varianza minore
è $\widehat{\mu}_{2}$. Per contro $\widehat{\mu}_{5}$ è distorto,
ma con una varianza in assoluto inferiore, anche rispetto a $\widehat{\mu}_{2}$.
Se decidessimo di restringere la ricerca dello stimatore migliore
all'interno della classe di stimatori corretti, ovviamente $\widehat{\mu}_{2}$
sarebbe quello da preferire in quanto è il più preciso in termini
di varianza. Tuttavia se estendessimo la ricerca anche a stimatori
non necessariamente corretti, dovremmo trovare un criterio che ci
permetta di misurare il $``$trade-off\textquotedblright{}\ tra la
perdita in precisione causata dalla distorsione ed il guadagno in
precisione dovuto ad una varianza inferiore. Tale criterio ci è dato
dal cosiddetto \emph{Errore Quadratico Medio (Mean Squared Error)}$.$

\begin{definizione} \label{EQM come var e bias}Errore Quadratico
Medio (EQM). Sia $T(X_{1},...,X_{n})$ uno stimatore di $\theta$.
L'Errore Quadratico Medio dello stimatore $T(X_{1},...,X_{n})$ di
$\theta$ è definito da\[
EQM_{T}=E\left(\left(T-\theta\right)^{2}\right)\text{.}\]
 \end{definizione}

\noindent Il termine $``$errore quadratico medio\textquotedblright{}\ può
essere giustificato se si pensa alla differenza $T-\theta$ come all'errore
che si compie nella stima di $\theta$. $E\left(\left(T-\theta\right)^{2}\right)$
è dunque una misura di dispersione dei valori dello stimatore $T$
attorno al \emph{vero} valore $\theta$. Se noi confrontassimo gli
stimatori guardando i loro rispettivi errori quadratici medi, ne preferiremmo
naturalmente uno con errore quadratico medio piccolo.

\begin{theorem} Sia $T(X_{1},...,X_{n})$ uno stimatore di $\theta$.
Vale la seguente identità:\begin{eqnarray}
EQM_{T} & = & \underset{\text{Varianza di }T}{V(T)}+\underset{\text{quadrato della distorsione}}{\left(E(T)-\theta\right)^{2}}\label{scomposizione mse}\\
 & = & V(T)+\left(B\left(\theta\right)\right)^{2}\text{.}\notag\end{eqnarray}
 \end{theorem}

\begin{remark} Per uno stimatore corretto $T$ di $\theta$ avremo
che il secondo termine è zero e quindi varrà semplicemente $EQM_{T}=V(T)$.
\end{remark}

\noindent Tornando ai due stimatori $\widehat{\mu}_{2}$ e $\widehat{\mu}_{5}$
possiamo ora calcolare il rispettivo $EQM$. Poiché $\widehat{\mu}_{1}$
è uno stimatore corretto avremo che \[
EQM_{\widehat{\mu}_{2}}=V(\widehat{\mu}_{2})=\frac{1}{3}.\]
 Per quanto riguarda invece $\widehat{\mu}_{5}$ \[
EQM_{\widehat{\mu}_{5}}=V(\widehat{\mu}_{5})+\left(-\frac{2}{3}\mu\right)^{2}=\frac{1}{27}+\frac{4}{9}\mu^{2}.\]


Avremo quindi che lo stimatore $\widehat{\mu}_{5}$ è superiore allo
stimatore $\widehat{\mu}_{2}$ in media quadratica per valori di $\mu$
compresi nell'intervallo $\left(-\sqrt{2/3},\sqrt{2/3}\right).$


\section{\label{elementi di teoria asintotica}Elementi di teoria asintotica}

In questo paragrafo consideriamo due importanti caratteristiche di
uno stimatore $T(X_{1},...,X_{n})$ di $\theta$. La prima è la consistenza,
definita attraverso la convergenza in probabilità di $T(X_{1},...,X_{n})$
a $\theta$ mentre la seconda è la normalità asintotica della quantità
$\sqrt{n}\left(T(X_{1},...,X_{n})-\theta\right)$. Entrambi i concetti
sono già stati incontrati in precedenza: il primo ad esempio quando
è stata trattata la convergenza dei momenti campionari $M_{r,n}$
ai rispettivi momenti $\mu_{r}$, il secondo quando abbiamo considerato
la distribuzione limite della media standardizzata $\frac{(\overline{X}_{n}-\mu)}{\sqrt{\sigma^{2}/n}}$.


\subsection{Consistenza}

La consistenza dello stimatore $T(X_{1},...,X_{n})$ di $\theta$
è definita nel seguente modo

\begin{definizione} Consistenza. Sia $T(X_{1},...,X_{n})$ uno stimatore
del parametro sconosciuto $\theta$. Diremo che $T$ è uno stimatore
consistente di $\theta$ se per qualsiasi $\epsilon>0$ $T$ soddisfa
la seguente condizione\begin{equation}
\lim_{n\rightarrow\infty}P\left(T(X_{1},...,X_{n})\in\left(\theta-\epsilon,\theta+\epsilon\right)\right)=1.\label{convergenza probabilita}\end{equation}
 \end{definizione}

\begin{remark} Uno stimatore che soddisfa la (\ref{convergenza probabilita})
si dice convergente in probabilità a $\theta$ e si scrive $T(X_{1},...,X_{n})\underset{n\rightarrow\infty}{\overset{P}{\rightarrow}}\theta$.
\end{remark}

\noindent La consistenza di uno stimatore è dunque una proprietà asintotica.
Al cre\-sce\-re dell'informazione disponibile la pre\-ci\-sio\-ne
della stima, misurata tramite la probabilità di trovarsi in prossimità
del vero valore, deve essere totale e cioè la probabilità deve tendere
a $1$. Uno stimatore consistente ci garantisce che all'aumentare
dell'informazione (numero di osservazioni) il valore stimato si avvicinerà
con probabilità cre\-scen\-te al vero valore. Potremmo chiederci
quale sia la relazione tra la consistenza di uno stimatore e la sua
varianza. Prima di affrontare questa discussione presentiamo un'ulteriore
definizione.

\begin{definizione} Convergenza in media quadratica. Lo stimatore
$T(X_{1},...,X_{n})$ del parametro sconosciuto $\theta$ è convergente
(o consistente) in media quadratica se \[
\lim_{n\rightarrow\infty}EQM_{T}=E((T-\theta)^{2})=0\text{.}\]
 \end{definizione}

\begin{remark} Poiché, come visto nel teorema \ref{EQM come var e bias}
vale che\[
EQM_{T}=V(T)+\left(B\left(\theta\right)\right)^{2}\ ,\]
 lo stimatore $T$ sarà convergente in media quadratica se e solo
se sia la varianza che la sua distorsione tendono a $0$ al crescere
di $n$ all'infinito. In questo modo abbiamo un criterio molto semplice
per verificare la convergenza in media quadratica di $T$. \end{remark}

\noindent Possiamo ora caratterizzare la relazione che lega la consistenza
di uno stimatore alla sua varianza.

\begin{theorem} Se uno stimatore $T$ di $\theta$ è consistente
in media quadratica, esso sarà pure uno stimatore consistente di $\theta$
(non è necessariamente vero l'inverso). \end{theorem}

\noindent Il precedente teorema è particolarmente utile in quanto
permette di trovare un criterio semplice per verificare la consistenza
di uno stimatore $T$ di $\theta$. Infatti, se sia la distorsione
che la varianza di $T$ tendono a $0$ al crescere di $n$, allora
lo stimatore è consistente. Ovviamente per uno stimatore corretto
è sufficiente che la sua varianza tenda a $0$ al crescere di $n$
essendo la sua distorsione uguale a $0$.


\subsection{Normalità asintotica}

Il teorema \ref{teo limite centrale} del limite centrale afferma
che la media $\overline{X}_{n}$ delle variabili aleatorie $X_{1},...,X_{n}$
se opportunamente standardizzata converge per $n\rightarrow\infty$
in distribuzione ad una variabile aleatoria $Z\sim N(0,1)$\begin{equation}
\frac{\overline{X}_{n}-\mu}{\frac{\sigma}{\sqrt{n}}}\underset{n\rightarrow\infty}{\sim}Z\text{.}\label{standardizzazione della media}\end{equation}
 Il lato sinistro della (\ref{standardizzazione della media}) che
chiameremo $Y_{n}$ può essere riscritto come\[
Y_{n}=\frac{\sqrt{n}\left(\overline{X}_{n}-\mu\right)}{\sigma}\text{.}\]
 Una proprietà della convergenza in distribuzione è quella che se
$Y_{n}$ converge a $Z$ e noi moltiplichiamo $Y_{n}$ per un numero,
diciamo $c$, allora $cY_{n}$ convergerà in distribuzione a $cZ$.
Questa proprietà ci permette di studiare il comportamento asintotico
della quantità $\sqrt{n}\left(\overline{X}_{n}-\mu\right)$. Infatti
\[
\sqrt{n}\left(\overline{X}_{n}-\mu\right)=\sigma\frac{\sqrt{n}\left(\overline{X}_{n}-\mu\right)}{\sigma}=\sigma Y_{n}\underset{n\rightarrow\infty}{\sim}\sigma Z\text{.}\]
 Ma poiché $Z$ è $N(0,1)$, $\sigma Z$ avrà una distribuzione $N(0,\sigma^{2})$.
Abbiamo dunque dimostrato che \begin{equation}
\sqrt{n}\left(\overline{X}_{n}-\mu\right)\underset{n\rightarrow\infty}{\sim}N(0,\sigma^{2})\text{.}\label{distribuzione media non standardizzata}\end{equation}
 Le due formule (\ref{standardizzazione della media}) e (\ref{distribuzione media non standardizzata})
sono del tutto equivalenti. Tuttavia la formula (\ref{distribuzione media non standardizzata})
è quella generalmente utilizzata per presentare la distribuzione a\-sin\-to\-ti\-ca
dello stimatore di massima verosimiglianza (dopo le opportune modifiche
di notazione).

\begin{theorem} \label{distr asintotic ml}Distribuzione asintotica
dello stimatore di massima verosimiglianza. Sia $X_{1},...,X_{n}$
un campione $i.i.d.$ estratto da una popolazione $X$ di densità
$f_{\theta}(x)$. Sia $\widehat{\theta}_{n}:=T_{mv}(X_{1},...,X_{n})$
lo stimatore di massima verosimiglianza di $\theta$ con \[
\sum\limits _{i=1}^{n}\frac{\partial\ln f_{\theta}(x_{i})}{\partial\theta}\mid_{\theta=\widehat{\theta}_{n}}=0.\]
 Allora vale che 
\begin{enumerate}
\item Lo stimatore di massima verosimiglianza è consistente per il parametro
$\theta$:\ $\widehat{\theta}_{n}\overset{P}{\underset{n\rightarrow\infty}{\rightarrow}}\theta$. 
\item $\sqrt{n}\left(\widehat{\theta}_{n}-\theta\right)$ è asintoticamente
normale \[
\sqrt{n}\left(\widehat{\theta}_{n}-\theta\right)\underset{n\rightarrow\infty}{\sim}N(0,\frac{1}{I(\theta)})\]
 dove $I(\theta):=E\left[\left(\frac{\partial\ln f_{\theta}(X)}{\partial\theta}\right)^{2}\right]$
è chiamata l'informazione di Fisher. 
\item Alternativamente $I(\theta)$ può essere calcolata nel seguente modo\[
I(\theta)=-E\left(\frac{\partial^{2}\ln f_{\theta}(X)}{\partial\theta^{2}}\right).\]
 
\end{enumerate}
\end{theorem}

\begin{remark} Per il calcolo di $I(\theta)$ la funzione $\ln f_{\theta}(x)$
è derivata rispetto a $\theta$ (la $x$ è considerata costante!).
La stessa cosa vale per la derivata seconda $\partial^{2}\ln f_{\theta}(x)/\partial\theta^{2}$.
\end{remark}

\noindent Quest'ultimo teorema è particolarmente importante in quanto
stabilisce che lo stimatore di massima verosimiglianza è uno stimatore
consistente di $\theta$ e asintoticamente normale. Infatti, come
nel caso della media campionaria $\overline{X}_{n}$, la distribuzione
asintotica di $\sqrt{n}\left(\widehat{\theta}_{n}-\theta\right)$
è anch'essa normale con una varianza che dipende da un'espressione
conosciuta col nome di \emph{informazione di Fisher} (ed uguale al
valore atteso del quadrato di $\frac{\partial\ln f_{\theta}(X)}{\partial\theta}$).
Per finire l'informazione di Fisher, notata $I(\theta)$, è altresì
calcolabile per mezzo del valore atteso della seconda derivata di
$\ln f_{\theta}$.

\begin{esempio} Supponiamo di estrarre un campione casuale semplice
di numerosità $n$ da una popolazione normale $N(\mu,\sigma^{2})$
con solo $\mu$ sconosciuto. La famiglia parametrica è uguale a ($\sigma^{2}$
poiché conosciuto è ora da considerarsi alla stregua di un numero)
\[
\mathcal{P}=\left\{ f_{\mu}(x)=\frac{1}{\sqrt{2\pi\sigma^{2}}}\exp\left(-\frac{1}{2\sigma^{2}}\left(x-\mu\right)^{2}\right),\ \mu\in\mathbb{R}\right\} .\]
 La funzione di massima verosimiglianza $L(\mu)$ è data dal prodotto
delle $n$ densità\begin{eqnarray*}
L(\mu) & = & \prod_{i=1}^{n}f_{\mu}(x_{i})\\
 & = & \left(\frac{1}{2\pi\sigma^{2}}\right)^{n/2}\exp\left(-\frac{1}{2\sigma^{2}}\sum\limits _{i=1}^{n}\left(x_{i}-\mu\right)^{2}\right).\end{eqnarray*}
 Lo stimatore di massima verosimiglianza di $\mu$ sappiamo essere
uguale alla media campionaria $\overline{X}_{n}$. Inoltre, poiché
la somma di variabili aleatorie normali indipendenti è ancora normale
(è questa una particolarità della distribuzione normale), la distribuzione
di $\overline{X}_{n}$ è $N(\mu,\frac{\sigma^{2}}{n})$. La distribuzione
di $\sqrt{n}\left(\overline{X}_{n}-\mu\right)$ è dunque $N(0,\sigma^{2})$.
Se il Teorema \ref{distr asintotic ml} è corretto, dovranno valere
le seguenti uguaglianze:\begin{equation}
\sigma^{2}=E\left[\left(\frac{\partial\ln f_{\mu}(X)}{\partial\mu}\right)^{2}\right]^{-1}=-\left[E\left(\frac{\partial^{2}\ln f_{\mu}(X)}{\partial\mu^{2}}\right)\right]^{-1}.\label{verifica uguaglianza fisher}\end{equation}
 \end{esempio}

\begin{esercizio} Quale esercizio verificate voi stessi la correttezza
della (\ref{verifica uguaglianza fisher}) nel caso in cui la $X$
è distribuita secondo la legge di normale $N(\mu,\sigma^{2})$. Procedete
come segue: 
\begin{enumerate}
\item Calcolate la derivata $\frac{\partial\ln f_{\mu}}{\partial\mu}$,
il suo quadrato ed infine il valore atteso del suo quadrato, notato
$E\left[\left(\frac{\partial\ln f_{\mu}(X)}{\partial\mu}\right)^{2}\right]$. 
\item Calcolate la derivata seconda $\partial^{2}\ln f_{\theta}(x)/\partial\theta^{2}$
ed in seguito il suo valore atteso. 
\end{enumerate}
\end{esercizio}


\subsection{Disuguaglianza di Cramèr-Rao}

La disuguaglianza di Cramèr-Rao stabilisce un \emph{limite inferiore}
per quanto riguarda la varianza di un \emph{qualsiasi} stimatore corretto
del parametro $\theta$. In altre parole, per quanto preciso possa
essere lo stimatore in questione la sua varianza non sarà mai al di
sotto di tale limite.

\begin{theorem} \label{Disuguaglianza di crame rao}Disuguaglianza
di Cramèr-Rao. Sia $X_{1},...,X_{n}$ un campione $i.i.d.$ estratto
da una popolazione $X$ di densità $f_{\theta}(x)$ e $T(X_{1},...,X_{n})$
uno stimatore corretto di $\theta$. Vale la seguente disuguaglianza\begin{equation}
V(T(X_{1},...,X_{n}))\geq\frac{1}{n\ I(\theta)}\label{limite di cramer rao}\end{equation}
 dove $I(\theta)$ è l'informazione di Fisher definita nel Teorema
\ref{distr asintotic ml}. \end{theorem}

\begin{remark} \label{osservazione cramer rao}Grazie alle proprietà
della varianza la disuguaglianza (\ref{limite di cramer rao}) può
essere riscritta come\[
V\left(\sqrt{n}\left(T(X_{1},...,X_{n})-\theta\right)\right)\geq\frac{1}{I(\theta)}\text{.}\]
 \end{remark}

\noindent L'utilità di quest'ultimo teorema risiede nel fatto che
esso rivela il limite massimo di efficienza nella stima del parametro
sconosciuto $\theta$. Come detto precedentemente, per $n$ finito,
può non essere possibile calcolare la varianza dello stimatore $T$
e ovviamente non sarà neppure possibile verificare se il limite inferiore
dato nella (\ref{limite di cramer rao}) è raggiunto%
\footnote{In generale, per $n$ fisso, il limite di Cramèr-Rao è un limite inferiore
non raggiungibile.%
} o meno. In tal caso si è\ soliti guardare alla varianza della distribuzione
asintotica di \[
\sqrt{n}\left(T(X_{1},...,X_{n})-\theta\right)\]
 che nella maggior parte dei casi che incontrerete in econometria
sarà $N(0,\upsilon^{2})$. Il termine $\upsilon^{2}$ corrisponde
alla varianza della distribuzione asintotica di \[
\sqrt{n}\left(T(X_{1},...,X_{n})-\theta\right)\text{.}\]
 Quando $T(X_{1},...,X_{n})$ è lo stimatore di massima verosimiglianza
di $\theta$, il teorema \ref{distr asintotic ml} ci dice che $\upsilon^{2}$
è uguale a $\frac{1}{I(\theta)}$ che per l'osservazione \ref{osservazione cramer rao}
corrisponde al limite inferiore. Lo stimatore di massima verosimiglianza
raggiunge quindi \emph{asintoticamente} il limite inferiore di Cramèr-Rao.

\bigskip{}


\noindent È possibile generalizzare la disuguaglianza di Cramèr-Rao
anche al caso di uno stimatore $T$ non corretto di $\theta$. In
tal caso il teorema \ref{Disuguaglianza di crame rao} va modificato
come segue.

\begin{theorem} Disuguaglianza di Cramèr-Rao, caso generale. Sia
$X_{1},...,X_{n}$ un campione $i.i.d.$ estratto da una popolazione
$X$ di densità $f_{\theta}(x)$ e $T(X_{1},...,X_{n})$ uno stimatore
di $\theta$ la cui distorsione è uguale a $B(\theta)$. Vale la seguente
disuguaglianza\begin{equation}
V(T(X_{1},...,X_{n}))\geq\frac{(1+\frac{\partial B(\theta)}{\partial\theta})^{2}}{n\ I(\theta)}\end{equation}
 dove $I(\theta)$ è l'informazione di Fisher definita nel Teorema
\ref{distr asintotic ml}. \end{theorem}


\chapter{Verifica d'ipotesi}

Dopo aver trattato alcuni argomenti propri della teoria della stima
affronte\-re\-mo in questo capitolo il secondo grande tema della
statistica inferenziale: la verifica d'ipotesi.

\bigskip{}


\noindent L'induzione statistica e la verifica di ipotesi sono alla
base di tutta la ricerca scientifica. In economia così come nelle
scienze naturali o in medicina accade spesso che l'oggetto del problema
sia quello di capire se, a seguito di un particolare evento o di un
intervento pianificato, vi sia un cambiamento nelle caratteristiche
della popolazione in termini del suo comportamento e/o attributi.
In medicina, ad esempio, si potrebbe voler determinare se un nuovo
farmaco o una nuova terapia sia più efficace nella cura di una certa
malattia rispetto a un farmaco o trattamento tradizionale. Anche in
micro- e macroeconomia ci sono numerosi esempi dove la verifica d'ipotesi
può essere utilizzata per appurare empiricamente la correttezza di
una teoria economica o l'efficacia di una determinata politica economica.
In primo luogo sarà ne\-ces\-sa\-rio definire la famiglia parametrica
$\mathcal{F}$ di densità che si intende utilizzare. In seguito si
dovrà definire l'ipotesi che si desidera verificare in termini della
distribuzione di probabilità della popolazione in esame.

\bigskip{}


\begin{definizione} Ipotesi statistica. Un'ipotesi statistica è un'affermazione
o supposizione sulla distribuzione di una o più variabili casuali.
\end{definizione}

\noindent L'ipotesi statistica soggetta ad esame è chiamata ipotesi
nulla ed è generalmente notata con $``H_{0}:$\textquotedblright{}\ seguito
dalla descrizione dell'ipotesi.

\bigskip{}


\begin{esempio} \label{esempio produttore penne p1}Un produttore
di penne a sfera ha acquistato una macchina per la produzione delle
sfere da inserire nella punta della penna. Una volta messa a punto,
la macchina dovrebbe produrre penne dal diametro di $0.6$ millimetri.
Per il produttore è particolarmente importante che le sfere prodotte
non siano né troppo grandi né troppo piccole. Dall'esperienza maturata
in passato si sa che una macchina messa a punto correttamente produce
sfere di diametro $0.6$ millimetri con una variabilità di $\sigma=0.005$
millimetri: $X\sim N(0.6,(0.005)^{2})$. La famiglia parametrica di
densità è dunque data da \[
\mathcal{P}=\left\{ f(x\mid\mu)=\frac{1}{\sqrt{2\pi}0.005}\exp\left(-\frac{1}{2\cdot0.005^{2}}\left(x-\mu\right)^{2}\right),\ \mu\in\mathbb{R}^{+}\right\} .\]
 Sotto l'ipotesi che la macchina abbia la giusta messa a punto, $\mu$
è conosciuto ed uguale a $0.6$. Per contro%
\footnote{Implicitamente si assume che difetti nella taratura della macchina
non influenzano la varianza della distribuzione.%
}, se la macchina fosse mal funzionante il diametro medio della produzione
potrebbe essere superiore o inferiore a $0.6$. Poiché la prima ipotesi
determina univocamente la distribuzione di $X$ la utilizzeremo quale
ipotesi nulla: \[
H_{0}:\text{la macchina è tarata correttamente.}\]
 L'alternativa all'ipotesi nulla, chiamata \emph{ipotesi alternativa},
verrà indicata con $``H_{A}:$\textquotedblright{}. In questo primo
esempio essa può essere espressa matematicamente come\[
H_{A}:\mu\neq0.6\text{.}\]
 \end{esempio}

\begin{esempio} \label{esempio caseificio p1}Un caseificio ha il
forte sospetto che un suo fornitore diluisca il latte con acqua. Da
numerosi test eseguiti in passato dal Laboratorio cantonale si sa
che la temperatura di gelo di un campione di latte è una variabile
aleatoria normale di valore atteso $-0.545$ ${{}^{\circ}}C$ e deviazione
standard $0.008$ ${{}^{\circ}}C$.

\noindent La famiglia parametrica di densità è ancora normale \[
\mathcal{P}=\left\{ f(x\mid\mu)=\frac{1}{\sqrt{2\pi}0.008}\exp\left(-\frac{1}{2\cdot0.008^{2}}\left(x-\mu\right)^{2}\right),\ \mu\in\mathbb{R}\right\} .\]
 Supponiamo che il latte non sia annacquato: in tal caso il valore
di $\mu$ sarebbe quello calcolato dal Laboratorio cantonale e la
distribuzione di $X$ e di un campione $\left(X_{1},X_{2},...,X_{n}\right)$
sarebbe conosciuta. Per contro, qualora il latte venisse diluito con
acqua, la sua temperatura di gelo sarebbe superiore a quella del latte
$``$puro\textquotedblright{}. Avremmo quindi%
\footnote{Si assume ragionevolmente che l'annacquamento del latte non modifichi
$\sigma^{2}$.%
} $\mu>-0.545$. Tuttavia, non conoscendo la percentuale di acqua aggiunta
al latte, l'esatto valore di $\mu$ non sarebbe comunque calcolabile.
Inoltre la legge afferma che $``$chiunque è presunto innocente fino
a quando la sua colpevolezza non sia dimostrata dinanzi alla Corte\textquotedblright{}.
Quindi la nostra ipotesi nulla sarà la seguente\[
H_{0}:\text{Il latte non è annacquato (}\Leftrightarrow\text{il fornitore è onesto)}\]
 che in base al nostro ragionamento può essere espressa in termini
del parametro $\mu$ semplicemente come\[
H_{0}:\mu=-0.545\text{.}\]
 Non rifiutare $H_{0}$ significa scagionare il fornitore dal sospetto
di truffa nei confronti del caseificio. Per contro, l'alternativa
di $H_{0}$ è che il fornitore effettivamente diluisca con acqua il
latte venduto. In tal caso il valore atteso della temperatura di gelo
sarà superiore a $-0.545$. L'\emph{ipotesi alternativa} $H_{A}$
sarà dunque espressa come\[
H_{A}:\mu>-0.545\text{.}\]
 Il grosso vantaggio di aver scelto quale ipotesi nulla $\mu=-0.545$
è dato dal fatto che $H_{0}$ identifica in maniera esatta la distribuzione
di $X$ e di $\left(X_{1},X_{2},...,X_{5}\right)$. \end{esempio}

\bigskip{}


\noindent Abbiamo definito l'ipotesi nulla e l'ipotesi alternativa
sulla base delle informazioni in nostro possesso ed alle varie assunzioni
riguardo alla famiglia parametrica $\mathcal{P}$. In entrambi i casi
l'ipotesi nulla è tale per cui la distribuzione della variabile aleatoria
$X$ è completamente specificata. In generale diremo che un'ipotesi
statistica (nulla o alternativa che sia) è \emph{semplice }se specifica
completamente la distribuzione di $X$, come è appunto il caso per
le due ipotesi nulle dei due ultimi esempi. In caso contrario diremo
invece che l'ipotesi è \emph{composta}. Ad esempio l'ipotesi alternativa
\[
H_{A}:\mu>-0.545\]
 dell'Esempio \ref{esempio caseificio p1} è un'ipotesi composta in
quanto non identifica esattamente la distribuzione di $X$. $H_{A}$
è l'unione di un'infinità di ipotesi semplici.


\section{Test per un'ipotesi statistica}

Eseguire un test di un'ipotesi statistica significa costruire una
regola di decisione basata sulle osservazioni disponibili che ci permette
di concludere se l'ipotesi sotto esame debba essere rifiutata o meno.
Vista la natura aleatoria di quanto osservato, tale conclusione varierà
a seconda del campione osservato. Diamo innanzi tutto una definizione
formale di quanto detto.

\bigskip{}


\begin{definizione} Test per un'ipotesi statistica. Un test di una
ipotesi statistica $H$ è una regola o procedimento per decidere se
rifiutare o meno $H$. \end{definizione}

\bigskip{}


\noindent Il problema è come determinare tale regola. In pratica l'informazione
disponibile sarà contenuta in un $n$-campione $\left(X_{1},X_{2},...,X_{n}\right)$
di osservazioni di $X$. La decisione dipenderà dai valori che osserveremo:
se quanto osservato sarà $``$in sintonia\textquotedblright{}\ con
l'ipotesi non la rifiuteremo. Le osservazioni ci daranno dunque evidenza
pro o contro l'ipotesi. Tale evidenza sarà generalmente definita in
termini di probabilità. Illustriamo quanto appena detto continuando
gli esempi precedenti.

\bigskip{}


\begin{esempio} Continuazione dell'Esempio \ref{esempio caseificio p1}.
Il caseificio decide di calcolare la temperatura di gelo di un campione
di 5 cartoni di latte, notato $(x_{1},...,x_{5})$, provenienti dal
fornitore in questione. Potremmo a questo punto domandarci qual è
la probabilità, sotto l'ipotesi nulla, di osservare $(x_{1},...,x_{5})$.
Tuttavia questa domanda ha poco senso: la distribuzione di $\left(X_{1},...,X_{5}\right)$
è una distribuzione continua per cui tale probabilità è $0$. Per
contro, anziché lavorare direttamente con i valori del campione, utilizziamo
una statistica $S$. In particolare, calcoliamo la media delle cinque
osservazioni, $\overline{x}=-0.536$. Grazie alle proprietà della
distribuzione normale sappiamo che la media campionaria $\overline{X}\sim N(\mu,\frac{0.008^{2}}{5})$.
Sotto l'ipotesi $H_{0}$ la distribuzione di $\overline{X}$ è $N(-0.545,\frac{0.008^{2}}{5})$.A
questo punto è possibile calcolare la probabilità di osservare un
valore di $\overline{X}$ uguale o superiore a quello calcolato dal
caseificio:\begin{eqnarray*}
P_{H_{0}}(\overline{X}>-0.536) & = & P_{H_{0}}(\overline{X}+0.545>0.009)\\
 & = & P_{H_{0}}(\frac{\sqrt{5}\left(\overline{X}+0.545\right)}{0.008}>2.515)\\
 & = & 0.59\%.\end{eqnarray*}
 La probabilità è dunque $0.59\%$. Quindi se il latte fosse $``$puro\textquotedblright{}\ osserveremmo
in media una temperatura simile o superiore meno di una volta su cento.
Questo è un evento raro visto che la sua probabilità è bassa. Una
pro\-ba\-bi\-li\-tà dello $0.59\%$ genera evidenza contro l'ipotesi
di onestà del fornitore. Si potrebbe dunque decidere di rifiutare
l'ipotesi nulla a favore dell'ipotesi alternativa. \end{esempio}

\bigskip{}


\begin{definizione} $p$-value. La \emph{probabilità} sotto $H_{0}$
di osservare un valore della statistica almeno estremo quanto il valore
osservato è detta $p$-value. \end{definizione}

\bigskip{}


\noindent Il $p$-value è dunque un indice di evidenza empirica a
favore dell'ipotesi nulla $H_{0}$. Il test statistico parlerà tanto
più a favore dell'ipotesi nulla tanto più elevato sarà il $p$-value.
La decisione finale di rifiutare o meno $H_{0}$ dipenderà dalla $``$quantità\textquotedblright{}\ di
evidenza sotto la quale non siamo più disposti a mantenere $H_{0}$
come ipotesi valida. Tale soglia, notata $\alpha$, è detta \emph{livello
di significatività}. Essa può variare a dipendenza delle circostanze.
In economia si utilizza generalmente un livello di significatività
del $5\%$. Assumendo dunque un livello di significatività $\alpha=5\%$,
rifiuteremo l'ipotesi nulla se il $p$-value $<\alpha$. In tal caso
diremo che il test è significativo ad un livello di significatività
dell' $\alpha$ per cento.

\bigskip{}


\begin{remark} È importante sottolineare che a causa della natura
aleatoria del fenomeno le nostre conclusioni saranno soggette ad errore.
Infatti, la scarsa evidenza a favore di $H_{0}$ non significa che
$H_{0}$ sia falsa. Come avremo modo di approfondire in seguito, il
livello di significatività $\alpha$ misura la probabilità dell'errore
di rifiutare $H_{0}$ quando questa è effettivamente vera. \end{remark}

\bigskip{}


\begin{esempio} Continuazione dell'Esempio \ref{esempio produttore penne p1}.
Per verificare il corretto funzionamento della macchina il produttore
produce un campione $i.i.d.$ di $n=25$ sfere. Come in precedenza
utilizziamo quale statistica $S$ la media campionaria $\overline{X}$.
Supponiamo che il valore medio realizzato sia di $\overline{x}=0.5985$.
Sotto l'ipotesi $H_{0}$ la distribuzione di $\overline{X}$ è $N(0.6,0.001^{2})$.A
differenza dell'Esempio \ref{esempio caseificio p1}, in questo caso
l'ipotesi alternativa non ha una direzione ben precisa. Il vero valore
di $\mu$ potrebbe essere superiore o inferiore a $0.6$. Per questo
motivo nel calcolo del $p$-value si terrà conto della probabilità
di osservare un valore di $S$ ($\overline{X}$ in questo caso) inferiore
a $0.5985$ (più estremo sulla sinistra della distribuzione) e superiore
a $0.6015$ (più estremo sulla destra della distribuzione). Tale valore
è stato calcolato nel seguente modo\[
0.6+(0.6-0.5985)=0.6015.\]
 Il $p$-value è dunque uguale a\begin{eqnarray*}
P_{H_{0}}(\overline{X}<0.5985,\overline{X}>0.6015) & = & P_{H_{0}}(|\overline{X}-0.6|>0.0015)\\
 & = & P_{H_{0}}(\frac{|\overline{X}-0.6|}{0.001}>1.5)=13.4\%.\end{eqnarray*}
 Decisamente questo non rappresenta un evento raro. Fissato un livello
di significatività pari al $5\%$ il $p$-value risulta essere più
grande. Per tale motivo non possiamo rifiutare l'ipotesi nulla. La
macchina è da considerarsi perfettamente funzionante. \end{esempio}

Ricapitolando quanto visto fino ad ora abbiamo i seguenti elementi
costitutivi di un test d'ipotesi 
\begin{enumerate}
\item L'ipotesi, definita come un'asserzione su un determinato fenomeno.
Nei nostri due esempi le ipotesi sotto esame concernono il funzionamento
di una macchina per la produzione di sfere e la composizione del latte. 
\item L'ipotesi nulla, $H_{0}$. È un'affermazione grazie alla quale è possibile
ricavare la distribuzione di una o più variabili aleatorie. Spesso
l'ipotesi nulla è qualcosa del tipo $``$... nessun problema ...\textquotedblright{}\ oppure
$``$... nessun effetto ...\textquotedblright{}\ oppure $``$...
nessuna differenza ...\textquotedblright{}. 
\item L'ipotesi alternativa, $H_{A}$, è da intendersi come una $``$direzione
contro l'ipotesi nulla$``$. Nel primo esempio con $H_{A}:\mu\neq0.6$
parleremo di test bilaterale, in quanto l'alternativa non specifica
una direzione per il vero valore di $\mu$ rispetto a quello proposto
dall'ipotesi nulla. Nel secondo esempio il test è unilaterale destro
in quanto l'alternativa si trova alla destra ($\mu>\mu_{0}=-0.545$)
del valore suggerito da $H_{0}$.\ Riassumendo:

\begin{itemize}
\item \emph{Test unilaterale}:\ l'alternativa è specificata in una sola
direzione. 
\item \emph{Test bilaterale}: l'alternativa è specificata in due direzioni. 
\end{itemize}
\item Statistica del test. In entrambi gli esempi la statistica $S$ utilizzata
nella costruzione del test è la media campionaria. La statistica $S$
deve essere tale per cui, sotto l'ipotesi nulla $H_{0}$, la sua distribuzione
è conosciuta. 
\item $\alpha\in\left(0,1\right)$ (ad esempio $\alpha=5\%$)$\ $che corrisponde
al livello di significatività desiderato. È la soglia o quantità di
evidenza (in termini di probabilità) minima richiesta, sotto la quale
si rigetta l'ipotesi nulla in quanto giudicata poco credibile. 
\item Il $p$-value, calcolato tenendo conto dell'ipotesi alternativa (unilaterale
o bilaterale). Esso corrisponde alla probabilità di osservare qualcosa
di simile o di più estremo (come indicato dall'ipotesi alternativa). 
\item La decisione se rifiutare o meno il test. Se il $p$-value è inferiore
al livello di significatività predefinito $H_{0}$ sarà rifiutata,
altrimenti l'ipotesi nulla verrà mantenuta. 
\end{enumerate}

\section{Regione critica di un Test d'ipotesi}

Il test per un'ipotesi statistica presentato nel precedente paragrafo
è basato sul concetto di $p$-value, ovvero la probabilità di osservare
un valore della statistica $S$ uguale o più estremo di quello calcolato
tramite le osservazioni $(x_{1},...,x_{n})$. Il $p$-value è un concetto
relativamente nuovo, introdotto con l'avvento del personal computer
grazie al quale il suo calcolo risulta essere immediato. Tuttavia,
quella del $p$-value non è l'unica formulazione possibile di un test
d'ipotesi. Infatti, studieremo ora un modo di formulare un test d'ipotesi
che è alternativo a quello basato sul $p$-value, ma \emph{equivalente}
dal punto di vista delle conclusioni. La formulazione del test è diversa,
non il suo risultato. Utilizzeremo l'Esempio \ref{esempio caseificio p1}
quale punto di partenza.


\subsection{Test unilaterale destro}

Abbiamo la seguente situazione: 
\begin{enumerate}
\item Vogliamo testare l'ipotesi riguardante la composizione del latte acquistato
da un certo fornitore sospettato di aggiungere acqua al suo latte. 
\item L'ipotesi nulla $H_{0}$ è che il fornitore sia una persona onesta.
Sotto questa ipotesi la distribuzione della temperatura di gelo del
latte del fornitore, notata $X$, è identica a quella definita dal
Laboratorio cantonale ($``$non c'è nessuna differenza\textquotedblright{}),
ovvero $X\sim N(-0.545,0.008^{2})$. L'ipotesi nulla può essere quindi
formalizzata come \[
H_{0}:\mu=-0.545\text{.}\]

\item L'ipotesi alternativa è che il fornitore abbia aggiunto acqua. In
tal caso il latte ghiaccerà in media ad una temperatura superiore\[
H_{A}:\mu>-0.545\text{.}\]

\item Abbiamo deciso di utilizzare la media campionaria $\overline{X}$
quale statistica per costruire il test. Sotto l'ipotesi nulla la nostra
statistica è distribuita $N(-0.545,\frac{0.008^{2}}{5})$. 
\item $\alpha=5\%$ è il livello di significatività desiderato. 
\end{enumerate}
\noindent Fino a questo punto la costruzione del test è identica alla
formulazione tramite il $p$-value. Ora, anziché calcolare il $p$-value,
calcoliamo l' $1-\alpha$ quantile $k$ della distribuzione della
media campionaria $\overline{X}$ (vedi disegno). $k$ sarà in seguito
utilizzato per definire quando rigettare $H_{0}$. Poiché abbiamo
scelto $\alpha=5\%$, il valore $k$ soddisfa la seguente uguaglianza\begin{equation}
P_{H_{0}}(\overline{X}>k)=0.05\text{.}\label{k alpha media}\end{equation}


Il quantile può essere ricavato utilizzando le tavole della distribuzione
normale. Infatti\begin{eqnarray*}
P_{H_{0}}(\overline{X}+0.545>k+0.545) & = & 0.05\\
P_{H_{0}}\left(\frac{\overline{X}+0.545}{0.008/\sqrt{5}}>\frac{k+0.545}{0.008/\sqrt{5}}\right) & = & 0.05\\
P\left(Z>\frac{k+0.545}{0.008/\sqrt{5}}\right) & = & 0.05\\
P\left(Z\leq\frac{k+0.545}{0.008/\sqrt{5}}\right) & = & 0.95\end{eqnarray*}
 Sotto l'ipotesi nulla la quantità $Z=\frac{\overline{X}+0.545}{0.008/\sqrt{5}}$
è distribuita $N(0,1)$. Dalle tavole sappiamo che $P\left(Z\leq1.645\right)=0.95$
da cui si ricava che%
\footnote{Ricordiamo che data una variabile aleatoria $N(\mu,\sigma^{2})$ l'$\alpha$-quantile
è dato dalla seguente formula\[
q_{\alpha}=\mu+z_{\alpha}\sigma\]
 dove $z_{\alpha}$ rappresenta l'$\alpha$-quantile della distribuzione
normale standard.%
} \[
k=-0.545+1.645\cdot0.008/\sqrt{5}=-0.539.\]
 Per costruzione, la probabilità di osservare un valore di $\overline{X}$
superiore o uguale a $-0.539$ è dunque uguale $5\%$. Inoltre, come
già osservato nel caso del $p$-value, l'osservazione di valori estremi
in direzione dell'ipotesi alternativa è da considerarsi come evidenza
sfavorevole all'ipotesi nulla. Per questo motivo utilizzeremo la seguente
regola di decisione: 
\begin{enumerate}
\item [7 bis.] Se il valore calcolato della statistica $\overline{X}$
($S$ in generale) cadrà $``$lontano\textquotedblright{}\ e in direzione
dell'ipotesi alternativa, ovvero se \begin{equation}
\overline{x}>k=-0.539\label{disequazione test destro}\end{equation}
 rifiuteremo l'ipotesi nulla, altrimenti non la rifiuteremo. 
\end{enumerate}
\begin{remark} Il $``$quanto lontano\textquotedblright{}\ deve
cadere il valore della nostra statistica affinché $H_{0}$ venga rigettata
dipende dal livello di significatività $\alpha$. Tanto più piccolo
il valore di $\alpha$ (che rappresenta il livello minimo di evidenza
richiesta a favore di $H_{0}$) e tanto più estrema sarà la soglia
$k$. \end{remark}

\noindent La decisione se rifiutare o meno il test dipende dalla disequazione
(\ref{disequazione test destro}). Essa definisce implicitamente una
così detta \emph{regione critica}.

\begin{definizione} Regione critica (test unilaterale destro). L'insieme
$R$ delle possibili realizzazioni $(x_{1},...,x_{5})$ di $(X_{1},...,X_{5})$
per cui $\overline{x}>k=-0.539$ (e quindi tali per cui il test è
rifiutato) è chiamato la regione critica del test o semplicemente
regione critica\[
R=\left\{ (x_{1},...,x_{5})\mid\overline{x}>k=-0.539\right\} .\]
 \end{definizione}

\bigskip{}


\noindent Notiamo che la regione critica è definita in termini delle
possibili realizzazioni $\left(x_{1},...,x_{5}\right)$ del campione
$(X_{1},...,X_{n})$ e non rispetto all'intervallo $(-0.539,\infty)$.
Talvolta è possibile ottenere una rappresentazione grafica di $R$.
Per esempio, il grafico di $\overline{x}>-0.539$ per $n=2$ dà la
seguente regione critica


\subsection{Test bilaterale}

Ricapitolando quanto discusso nell'Esempio \ref{esempio produttore penne p1}\ concernente
il produttore di penne a sfera ci troviamo nella seguente situazione. 
\begin{enumerate}
\item Vogliamo testare l'ipotesi riguardante la corretta messa a punto della
macchina che produce le sfere per la punta delle penne. 
\item L'ipotesi nulla $H_{0}$ è che la macchina sia correttamente tarata,
ovvero che il diametro $X\sim N(0.6,(0.005)^{2})$. Matematicamente
l'ipotesi nulla può essere espressa semplicemente da \[
H_{0}:\mu=0.6\text{.}\]

\item L'ipotesi alternativa è che la macchina non sia a punto e che di conseguenza
il diametro medio delle sfere prodotte sia diverso da $0.6$\[
H_{A}:\mu\neq0.6\text{.}\]

\item Abbiamo deciso di utilizzare la media campionaria $\overline{X}$
quale statistica per costruire il test. Sotto l'ipotesi nulla la media
campionaria delle $25$ osservazioni è distribuita $N(0.6,(0.001)^{2})$. 
\item $\alpha=5\%$ è il livello di significatività desiderato. 
\end{enumerate}
\noindent Per quanto riguarda i punti 1-5 non vi è alcuna differenza
con la specificazione del test basata sul $p$-value. A questo punto
però anziché calcolare il $p$-value, costruiamo la regione critica.
Essa verrà in seguito utilizzata per definire quando rifiutare il
test.

\bigskip{}


\noindent Tendenzialmente rigetteremo l'ipotesi nulla se osserveremo
dei valori della statistica estremi in direzione dell'ipotesi alternativa.
Essendo questo un test bilaterale, dobbiamo considerare valori estremi
della statistica in ambo le direzioni. Ciò è possibile assegnando
metà del livello di significatività al lato sinistro della distribuzione
e l'altra metà al lato destro. Dovremo quindi calcolare due quantili
della distribuzione di $\overline{X}$: il primo (lato sinistro) è\ il
$2.5\%$-quantile ed il secondo (lato destro) è il $97.5\%-$quantile\begin{equation}
\left\{ \begin{array}{l}
P_{H_{0}}(\overline{X}<k_{1})=2.5\%\\
P_{H_{0}}(\overline{X}>k_{2})=2.5\%\end{array}\right.\end{equation}


\[
\left\{ \begin{array}{l}
P_{H_{0}}\left(\overline{X}-0.6<k_{1}-0.6\right)=2.5\%\\
P_{H_{0}}\left(\overline{X}-0.6>k_{2}-0.6\right)=2.5\%\end{array}\right.\]
 \[
\left\{ \begin{array}{l}
P_{H_{0}}(\frac{\overline{X}-0.6}{0.001}<\frac{k_{1}-0.6}{0.001})=2.5\%\\
P_{H_{0}}(\frac{\overline{X}-0.6}{0.001}>\frac{k_{2}-0.6}{0.001})=2.5\%\end{array}\right.\]
 Ancora una volta sotto l'ipotesi nulla la quantità $\frac{\overline{X}-0.6}{0.001}=Z$
è distribuita $N(0,1)$. Definendo $z_{0.025}=\frac{k_{1}-0.6}{0.001}$
e $z_{0.975}=\frac{k_{2}-0.6}{0.001}$ il sistema si può riscrivere
come \[
\left\{ \begin{array}{l}
P(Z<z_{0.025})=2.5\%\\
P(Z>z_{0.975})=2.5\%\end{array}\right.\Leftrightarrow P(|\frac{\overline{X}-0.6}{0.001}|>z_{0.975})=0.05\]
 Utilizzando le tavole della distribuzione normale standard e la sua
simmetria attorno allo $0$ deduciamo che $z_{0.975}=-z_{0.025}=1.96$.
Infine, si ottiene $k_{1}=0.598$ e $k_{2}=0.6019.$ Siamo ora pronti
a definire la regola per il rifiuto dell'ipotesi nulla. 
\begin{enumerate}
\item [7 bis.] Se il valore calcolato della statistica $\overline{X}$
cadrà $``$lontano\textquotedblright{}\ e in direzione dell'ipotesi
alternativa, ovvero se \begin{equation}
\overline{x}<k_{1}=0.598\text{ oppure }\overline{x}>k_{2}=0.6019\label{disequazione test bilaterale}\end{equation}
 rifiuteremo l'ipotesi nulla. In caso contrario%
\footnote{Ciò corrisponde al caso in cui \[
\frac{|\overline{X}-0.6|}{0.001}\leq z_{0.975}.\]
 %
} $H_{0}$ sarà mantenuta. La regola di decisione può essere espressa
anche nella sua forma standar\-diz\-za\-ta: se \[
|\frac{\overline{x}-0.6}{0.001}|>z_{0.975}=1.96\]
 rifiuteremo l'ipotesi nulla. 
\end{enumerate}
\noindent Anche nel caso di un'ipotesi bilaterale possiamo definire
una regione critica $R$ includendo in essa tutte quelle realizzazioni
$\left(x_{1},...,x_{25}\right)$ tali per cui una delle due disuguaglianze
della (\ref{disequazione test bilaterale}) è soddisfatta.

\begin{definizione} Regione critica (test bilaterale). L'insieme
$R$ delle possibili realizzazioni $(x_{1},...,x_{25})$ di $(X_{1},...,X_{25})$
per cui $\overline{x}<k_{1}=0.598$ oppure $\overline{x}>k_{2}=0.6019$
(e quindi tali per cui il test è rifiutato) è chiamato regione critica
del test\[
R=\left\{ (x_{1},...,x_{25})\mid\overline{x}<k_{1}=0.598\text{ oppure }\overline{x}>k_{2}=0.6019\right\} .\]
 \end{definizione}

\begin{remark} La costruzione di un test d'ipotesi statistica consiste
quindi nel scegliere, oltre che l'ipotesi nulla e quella alternativa,
una regione critica. $R$ è un sottoinsieme delle possibili realizzazioni
campionarie. Se i valori $(x_{1},...,x_{n})$ che osserveremo cadranno
nella regione critica, ovvero se 
\begin{itemize}
\item test unilaterale destro: $\overline{x}>k$, 
\item test unilaterale sinistro: $\overline{x}<k$, 
\item test bilaterale: $\overline{x}<k_{1}$ oppure $\overline{x}>k_{2}$,
rifiuteremo l'ipotesi nulla. 
\item test bilaterale (forma standardizzata): $|\frac{\overline{x}-\mu_{0}}{\sigma}|>z_{1-\alpha/2}$,
rifiutiamo $H_{0}$. 
\end{itemize}
Per costruzione la regione critica dovrà soddisfare il vincolo concernente
il livello di significatività prescelto, ovvero \begin{equation}
P_{H_{0}}(R)=\alpha\text{.}\end{equation}
 \end{remark}


\section{Scelta della statistica $S$}

La scelta della statistica $S$ utilizzata nella costruzione di un
test di ipotesi è importante tanto quanto lo è la scelta dello stimatore
$T$ nell'ambito della stima puntuale. Nei due esempi precedenti abbiamo
utilizzato la media $\overline{X}$ quale statistica $S$ per la costruzione
del test%
\footnote{Dunque nei due casi visti $S$ coincide con lo stimatore $\overline{X}$
del valore atteso della popolazione.%
}. Cosa succederebbe se, anziché la media, utilizzassimo un'altra statistica?
Vogliamo considerare questa possibilità per l'Esempio \ref{esempio caseificio p1}
e la statistica $S=X_{\min}=\min(X_{1},...,X_{5})$. Supponiamo che
i cinque valori osservati siano uguali a%
\footnote{La media dei cinque valori è uguale a $-0.536$ che corrisponde al
valore utilizzato precedentemente per $\overline{x}$.%
}\[
(x_{1},...,x_{5})=(-0.532,-0.54,-0.525,-0.541,-0.542).\]
 Il valore di $X_{\min}$ per questa realizzazione del campione è
dunque $x_{\min}=-0.542$. La distribuzione di $S$ dipende dalla
distribuzione congiunta di $(X_{1},...,X_{5})$. Per eseguire il test
(indipendentemente se formulato col $p$-value o con la regione critica)
dovremo ricavare la funzione di ripartizione di $S$.


\subsection{\label{distribuzione del minimo}Distribuzione del $\min(X_{1},...,X_{5})$}

Prima di proseguire nella costruzione del test di $H_{0}$ dell'Esempio
\ref{esempio caseificio p1} calcoliamo%
\footnote{Al fine di distinguere fra la funzione di ripartizione (densità) di
$S$ e la funzione di ripartizione (densità) delle $X_{i}$ aggiungeremo
la lettera $S$ o $X_{i}$ al piede di $F$ ($f$).%
} $F_{S}(s)$, la distribuzione di $S$, cioè del minimo fra $(X_{1},...,X_{5})$.
Essa è per definizione uguale a \[
F_{S}(s)=P(\min(X_{1},...,X_{5})\leq s).\]
 Anziché tentare di calcolare direttamente la probabilità $P(\min(X_{1},...,X_{5})\leq s)$,
la riscriviamo come\begin{equation}
F_{S}(s)=1-P(\min(X_{1},...,X_{5})>s)\text{.}\label{distribuzione minimo step1}\end{equation}
 Il motivo per cui si percorre questa strada è semplice: prendiamo
ad esempio $s=2.$ $\min(X_{1},...,X_{5})>2$ se e solo se tutte e
$5$ le variabili aleatorie saranno maggiori di $2$. Quindi l'evento
che $\min(X_{1},...,X_{5})>2$ corrisponde (è identico) all'evento
che tutte e $5$ le variabili aleatorie sono maggiori di $2$. Per
tale motivo e per un valore qualsiasi $s$ \[
P(\min(X_{1},...,X_{5})>s)=P(X_{1}>s,...,X_{5}>s)\text{.}\]
 Utilizzando l'indipendenza degli $X_{i}$ \[
P(X_{1}>s,...,X_{5}>s)=\prod_{i=1}^{5}P(X_{i}>s).\]
 Infine, poiché $P(X_{i}>s)=1-P(X_{i}\leq s)$, otteniamo la seguente
identità \[
P(\min(X_{1},...,X_{5})>s)=P(X_{1}>s,...,X_{5}>s)=\prod_{i=1}^{5}\left(1-P(X_{i}\leq s)\right)\]
 che quando inserita nella (\ref{distribuzione minimo step1}) ci
permette di ottenere la formula finale \begin{equation}
F_{S}(s)=1-\prod_{i=1}^{5}\left[1-P(X_{i}\leq s)\right].\label{Fss parziale}\end{equation}
 Questa formula vale per il minimo di qualsiasi campione $(X_{1},...,X_{5})$
di va\-ria\-bili aleatorie indipendenti. Per ottenere la formula
(\ref{Fss parziale}) abbiamo utilizzato esclusivamente l'indipendenza
degli $X_{i}$. Poiché $(X_{1},...,X_{5})$ sono oltre che indipendenti
anche identicamente distribuiti la (\ref{Fss parziale}) è semplificabile
in \begin{eqnarray}
F_{S}(s) & = & 1-\left[1-P(X\leq s)\right]^{5}\notag\\
 & = & 1-\left[1-F_{X}(s)\right]^{5}\label{formula finale minimo}\end{eqnarray}
 La formula (\ref{formula finale minimo}) è la formula finale che
mette in relazione la funzione di ripartizione di $S$ (il minimo
fra $(X_{1},...,X_{5})$) con la funzione di ripartizione di $X$,
la popolazione dalla quale sono campionate le $X_{i}.$ Da questa
formula è immediato derivare la funzione di densità di $S$. Derivando
entrambi i lati rispetto ad $s$ otteniamo\begin{equation}
\frac{\partial}{\partial s}F_{S}(s)=f_{S}(s)=5\left[1-F_{X}(s)\right]^{4}\ f_{X}(s).\end{equation}
 Abbiamo ora tutto quanto occorre per continuare l'Esempio \ref{esempio caseificio p1}.


\subsection{\label{formulazione test xmin}Formulazione del test}

Riprendiamo qui di seguito la situazione punto per punto: 
\begin{enumerate}
\item Vogliamo testare l'ipotesi riguardante la composizione del latte acquistato
da un certo fornitore sospettato di aggiungere acqua al suo latte. 
\item L'ipotesi nulla $H_{0}$ è che il fornitore sia onesto \[
H_{0}:\mu=-0.545\text{.}\]

\item L'ipotesi alternativa è che il fornitore abbia aggiunto acqua\[
H_{A}:\mu>-0.545\text{.}\]



Fino a questo punto nulla è mutato. La novità consiste nell'utilizzare
la statistica $X_{\min}$ al posto di $\overline{X}$. Grazie al paragrafo
\ref{distribuzione del minimo} conosciamo la distribuzione di $X_{\min}$.
Il nuovo punto $4$. diventa

\item Abbiamo deciso di utilizzare $S=X_{\min}$ quale statistica per costruire
il test. Sotto l'\emph{ipotesi nulla} ogni singola $X_{i}\sim N(-0.545,0.008^{2}).$
La funzione di ripartizione di $S$ è data da \[
F_{S}(s)=1-\left[1-F_{X}(s)\right]^{5}\]
 mentre la funzione di densità è uguale \[
f_{S}(s)=5\left[1-F_{X}(s)\right]^{4}\ f_{X}(s).\]
 dove \[
f_{X}(s)=\frac{1}{\sqrt{2\pi}0.008}\exp\left(-\frac{1}{2\cdot0.008^{2}}\left(s+0.545\right)^{2}\right)\]
 e\[
F_{X}(s)=\int\limits _{-\infty}^{s}f_{X}(x)dx\]
 Notate che per dato valore di $s$ sia $F_{S}$ che $f_{S}$ potrebbero
essere calcolate in Excel o Openoffice utilizzando la funzione NORMDIST(). 
\item Come con la media campionaria $\overline{X}$ prendiamo un livello
di signifi\-ca\-ti\-vi\-tà $\alpha=5\%$. 
\item Calcolo del $p$-value.


In questo caso il $p$-value è da calcolarsi rispetto alla statistica
$S=X_{\min}.$ Come detto in precedenza, il valore realizzato di $x_{\min}=-0.542$.
Il $p$-value sarà dunque\begin{eqnarray*}
P_{H_{0}}(S>-0.542) & = & 1-P_{H_{0}}(S\leq-0.542)\\
 & = & 1-F_{S}(-0.542)=0.5545\%.\end{eqnarray*}
 È questa una probabilità assai bassa ed inferiore al livello di significatività
prefissato del $5\%$. L'evidenza a favore di $H_{0}$ è come nel
caso della media campionaria $\overline{X}$ insufficiente%
\footnote{Ricordiamo che in precedenza per la media campionaria $\overline{X}$
era stato calcolato un $p$-valore dello $0.59\%$.%
} e per tale motivo rifiutiamo l'ipotesi nulla.

\item [6 bis.] Calcolo della regione critica.


Essendo questo un test d'ipotesi unilaterale destro, la regione critica
è definita tramite l'$1-\alpha$ quantile della distribuzione di $S$,
notato $k$.\begin{eqnarray}
P_{H_{0}}(S>k) & = & 0.05\label{k_alpha minimo}\\
F_{S}(k) & = & 0.95\\
k & = & F_{S}^{-1}(0.95)\notag\\
k & = & -0.546\notag\end{eqnarray}


\item [7.] Per valori della statistica $S$ superiori a $k=-0.546$ (estremi
in direzione dell'ipotesi alternativa) rigetteremo l'ipotesi nulla.
In questo caso la regione critica $R$ è definita dall'insieme delle
possibili realizzazioni $(x_{1},...,x_{5})$ tali che $\min(x_{1},...,x_{5})>k=-0.546$,
\[
R=\left\{ (x_{1},...,x_{5})\mid\min(x_{1},...,x_{5})>k=-0.546\right\} .\]
 
\end{enumerate}
\noindent Il valore realizzato $x_{\min}=-0.542$ è effettivamente
maggiore di $-0.546$ e pertanto $(x_{1},...,x_{5})=(-0.532,-0.54,-0.525,-0.541,-0.542)\in R$.
L'ipotesi nulla va rigettata! Per $n=2$ è istruttivo eseguire il
grafico di $\min(x_{1},x_{2})>-0.546$ e confrontarlo con il grafico
di $\overline{x}>-0.539$. Ovviamente le due regioni critiche sono
diverse a conferma che i due test, sebbene costruiti ad uno stesso
livello di significatività del $5\%$, sono diversi.

\bigskip{}


\noindent In questo esempio i due test, l'uno basato sulla media campionaria
e l'altro basato sul minimo del campione, hanno condotto alla medesima
conclusione. Tuttavia ciò non è sempre il caso. È allora spontaneo
chiedersi quale dei due test sia il migliore. Per costruzione, entrambi
i test rigetteranno l'ipotesi nulla con una probabilità del $5\%$
quando questa è effettivamente vera. Da questo punto di vista essi
sono equivalenti. Per il fornitore dunque, potrebbe essere indifferente
l'uso dell'uno o dell'altro al fine di valutare la sua onestà. Riprenderemo
questo discorso all'interno del prossimo paragrafo.

\pagebreak


\section{Errore di prima e seconda specie}

Se osserviamo la verifica d'ipotesi come un problema decisionale possiamo
identificare due tipi di decisioni e due tipi di errori possibili.
Per quanto riguarda le decisioni possiamo 
\begin{itemize}
\item rifiutare $H_{0}$, 
\item non rifiutare $H_{0}$ (mantenere l'ipotesi in vista di ulteriori
verifiche tramite altri test). 
\end{itemize}
\noindent Per quanto riguarda invece gli errori abbiamo due tipi di
errori che indichiamo con un asterisco\[
\begin{tabular}{l|c|c|}
 \cline{2-3}  &  \ensuremath{H_{0}}vera  &  \ensuremath{H_{0}}falsa \\
\hline \multicolumn{1}{|l|}{Rifiutare \ensuremath{H_{0}}}  &  \begin{tabular}{l}
 decisione incorretta\ensuremath{^{\ast}}\\
\multicolumn{1}{c}{\ensuremath{\alpha}}\end{tabular}  &  \begin{tabular}{l}
 decisione corretta \\
\multicolumn{1}{c}{\ensuremath{\beta}}\end{tabular} \\
\hline \multicolumn{1}{|l|}{Non rifiutare \ensuremath{H_{0}}}  &  \begin{tabular}{l}
 decisione corretta \\
\multicolumn{1}{c}{\ensuremath{1-\alpha}}\end{tabular}  &  \multicolumn{1}{|l|}{\begin{tabular}{l}
 decisione incorretta\ensuremath{^{\ast}}\\
\multicolumn{1}{c}{\ensuremath{1-\beta}}\end{tabular}} \\\hline \end{tabular}\]
 Abbiamo quindi tipi di errore con probabilità associate ($\alpha$
e $1-\beta$). 
\begin{itemize}
\item $\alpha$ è chiamato livello di significatività o\emph{\ errore di
prima specie} e corrisponde alla probabilità di rifiutare $H_{0}$
quando $H_{0}$ è vera. Si tratta di una probabilità condizionata:\[
\alpha=P(\text{Rifiutare }H_{0}\ \mid\ H_{0}\text{ è vera})=P_{H_{0}}(\text{Rifiutare }H_{0}).\]

\item $\beta$ è invece la probabilità di rifiutare $H_{0}$ quando questa
è falsa ($\Leftrightarrow$ quando $H_{A}$ vera)\[
\beta=P(\text{Rifiutare }H_{0}\ \mid\ H_{0}\text{ è falsa})=P_{H_{A}}(\text{Rifiutare }H_{0}).\]

\item $1-\beta$ è chiamato errore di seconda specie e corrisponde all'errore
di non rifiutare $H_{0}$ quando questa è falsa. 
\end{itemize}
\begin{remark} Nell'Esempio \ref{esempio caseificio p1} del caseificio
abbiamo quale ipotesi nulla \[
H_{0}:\text{\textquotedblright innocente\textquotedblright}\]
 ed i seguenti due errori 
\begin{itemize}
\item Errore di $1^{a}$ specie: fornitore dichiarato colpevole quando in
realtà è innocente. 
\item Errore di $2^{a}$ specie: fornitore dichiarato innocente quando in
realtà è colpevole. 
\end{itemize}
\end{remark}

\bigskip{}


\noindent Idealmente non vorremmo mai rifiutare $H_{0}$ quando questa
è vera (cioè vorremmo un $\alpha$ uguale a $0$) e rifiutarla sempre
quando essa è falsa (un $\beta=1$). Questo però non è possibile.
Occorre studiare come si possono controllare queste due probabilità
per ridurre al minimo le possibilità d'errore.

\noindent Possiamo dunque chiederci come si decide di \textquotedblright{}Rifiutare
$H_{0}$\textquotedblright{}\ sulla base dei dati disponibili? Nei
paragrafi precedenti abbiamo definito dei test d'ipotesi basati su
una statistica $S$ ed una regione critica \begin{eqnarray*}
R & = & \left\{ (x_{1},...,x_{n})\mid S(x_{1},...,x_{n})>k\right\} \text{ (test unilaterale destro),}\\
R & = & \left\{ (x_{1},...,x_{n})\mid S(x_{1},...,x_{n})<k\right\} \text{ (test unilaterale sinistro),}\\
R & = & \left\{ (x_{1},...,x_{n})\mid|S(x_{1},...,x_{n})|>k\right\} \text{ (test bilaterale).}\end{eqnarray*}
 Il criterio per rifiutare $H_{0}$ dipende dal fatto che i valori
osservati del campione appartengano o meno alla regione critica, ovvero
se \[
S(x_{1},...,x_{n})>k\]
 rifiutiamo $H_{0}$ altrimenti non la rifiutiamo (test unilaterale
destro). Il valore di $k$ che definisce la soglia fra rifiuto e non
rifiuto di $H_{0}$ è stato fissato in modo tale che la probabilità
di osservare valori più estremi di $k$ sia uguale al livello di significatività
$\alpha$ prescelto. Per tale motivo si è soliti aggiungere al piede
di $k$ il valore $1-\alpha$ (test unilaterale destro), $\alpha$
(test unilaterale sinistro), $1-\frac{\alpha}{2}$ (test bilaterale).

\begin{esempio} Tornando all'Esempio \ref{esempio caseificio p1}
del caseificio (test unilaterale destro basato sulla media campionaria)\begin{eqnarray*}
\alpha & = & P_{H_{0}}(\text{rifiutare }H_{0})=P_{H_{0}}(\overline{X}>k_{1-\alpha})\\
 & = & P_{H_{0}}\left(\frac{\overline{X}+0.545}{0.008/\sqrt{5}}>\frac{k_{1-\alpha}+0.545}{0.008/\sqrt{5}}\right)\\
 & = & P\left(\underset{\sim N(0,1)}{Z}>\frac{k_{1-\alpha}+0.545}{0.008/\sqrt{5}}\right)\end{eqnarray*}
 Utilizzando la solida proprietà $P\left(Z>a\right)=1-P(Z\leq a)$\[
P\left(Z\leq\frac{k_{1-\alpha}+0.545}{0.008/\sqrt{5}}\right)=1-\alpha\]
 da cui \begin{eqnarray*}
\frac{k_{1-\alpha}+0.545}{0.008/\sqrt{5}} & = & z_{1-\alpha}\\
k_{1-\alpha} & = & -0.545+z_{1-\alpha}0.008/\sqrt{5}\end{eqnarray*}
 Utilizzando la tabella sottostante è possibile calcolare le varie
soglie della regione critica in funzione del livello di significatività
(errore di prima specie) desiderato:\[
\begin{array}{cccc}
\alpha & 5\% & 2.5\% & 1\%\\
1-\alpha & 95\% & 97.5\% & 99\%\\
z_{1-\alpha} & 1.645 & 1.96 & 2.33\end{array}\]
 Ricordiamo che grazie alla simmetria della distribuzione normale
avremo per un test unilaterale sinistro i seguenti valori di $z_{\alpha}:$\[
\begin{array}{cccc}
\alpha & 5\% & 2.5\% & 1\%\\
z_{\alpha} & -1.645 & -1.96 & -2.33\end{array}\]
 \end{esempio}

\begin{remark} Come già accennato, il livello \textquotedblright{}tipico\textquotedblright{}\ di
significatività è del 5\%. In medicina si indica con 
\begin{itemize}
\item n.s. : se il risultato non è significativo al 5\%, 
\item {*} : se il risultato è significativo al 5\%, 
\item {*}{*} :\ se il risultato è significativo all'1\%, 
\item {*}{*}{*} :\ se il risultato è significativo allo 0.1\%. 
\end{itemize}
\end{remark}

\newpage{}


\subsection{Relazione tra errore di prima e di seconda specie}

Ci chiediamo quale sia la relazione fra errore di prima e di seconda
specie. Per fare questo analizziamo il seguente esempio.

\begin{esempio} Supponiamo che la variabile aleatoria $X$ sia distribuita
secondo la legge normale $N(\mu,1)$ e che l'ipotesi nulla sia $H_{0}:\mu=0$
mentre l'ipotesi alternativa%
\footnote{Sono entrambe ipotesi semplici in quanto identificano esattamente
la distribuzione di $X$.%
} $H_{A}:\mu=2$. Si osserva un'unica realizzazione di $X$, notata
semplicemente $x$. L'errore di prima specie (livello di significatività)
è fissato inizialmente ad $\alpha=5\%.$ Il grafico della funzione
di densità di $X$ sotto le due ipotesi è riportato qui sotto. Poiché
l'ipotesi alternativa è situata alla destra di $H_{0}$, la soglia
$k$ della regione critica al livello di significatività desiderato
è definita da\[
P_{H_{0}}(X>k)=0.05\Rightarrow k_{95\%}=z_{95\%}=1.645.\]
 La regione critica%
\footnote{In questo esempio ad uso didattico la statistica $S$ utilizzata è
semplicemente il valore osservato. La regione critica $R$ coincide
quindi con l'intervallo $(k,\infty)$. Tuttavia è questo un caso che
capita rarissimamente nelle applicazioni.%
} è \[
R=\left\{ x\in(1.645,\infty)\right\} .\]
 Graficamente la probabilità $P_{H_{0}}(X>k)$ è rappresentata dalla
superficie tratteggiata della figura precedente. Una volta determinata
la regione critica, il test di $H_{0}$ è dunque il seguente: \end{esempio} 
\begin{itemize}
\item si osserva la realizzazione $x$ di $X$. 
\item Se $x$ cade nella regione critica rifiutiamo $H_{0}.$ (Se $H_{0}$
è vera, questo accadrà, per costruzione, con una probabilità pari
ad $\alpha=5\%$.) 
\item Se $x$ cade al di fuori della regione critica non rifiutiamo $H_{0}.$
(Se $H_{0}$ è vera, questo accadrà, per costruzione, con una probabilità
uguale ad $1-\alpha=95\%$.) 
\end{itemize}
\noindent Una volta determinata la regione critica $R$ sulla base
dell'ipotesi nulla ed il livello di significatività desiderato (errore
di prima specie) possiamo chiederci cosa sarebbe la probabilità di
rifiutare l'ipotesi nulla (o di non rifiutarla) se la vera distribuzione
di $X$ fosse data da $H_{A}$.

\begin{remark} È importante sottolineare che la regione critica non
varia: noi rifiuteremo $H_{0}$ se l'osservazione di $x$ cadrà nell'intervallo
$(1.645,\infty)$ mentre non la rifiuteremo se $x\in(-\infty,1.645]$.
Ciò che vogliamo fare ora è calcolare la probabilità dell'evento $X\in(1.645,\infty)$
dato che la distribuzione di $X$ è ora data dall'ipotesi alternativa
$H_{A}$. \end{remark}

\noindent La probabilità di rigettare $H_{0}$ è definita dalla probabilità
dell'evento $X>1.645$ e la sua probabilità è semplicemente\begin{equation}
P\left(X>1.645\right).\label{Prob generica}\end{equation}
 Questa probabilità deve essere calcolata sotto l'ipotesi alternativa
$H_{A}$, vale a dire sotto l'ipotesi che $X\sim N(2,1)$. Facciamo
questo aggiungendo $H_{A}$ alla $P$ della (\ref{Prob generica})
che quindi diventa\[
P_{H_{A}}\left(X>1.645\right)\]
 Per calcolare questa probabilità utilizziamo la solita tecnica di
standardizzazione, tenendo presente che sotto l'ipotesi alternativa
$H_{A}$ il valore atteso di $X$ è uguale $2$ (mentre la varianza
in questo caso è ancora 1).

\[
P_{H_{A}}\left(\underset{Z\sim N(0,1)}{\underbrace{X-2}}>1.645-2\right)=P\left(Z>-0.355\right)=P(Z\leq0.355)=63.87\%.\]
 Abbiamo in questo modo calcolato la probabilità di rifiutare $H_{0}$
condi\-zio\-na\-ta\-men\-te al fatto che essa sia falsa. Questa
probabilità è stata indicata con la lettera $\beta$ e corrisponde
all'azione corretta nel caso che $H_{A}$ sia vera. Graficamente essa
corrisponde alla superficie alla destra di $k$ rispetto alla funzione
di densità tratteggiata (funzione di densità di $X$ rispetto a $H_{A}$).
In teoria noi vorremmo che questa probabilità fosse uguale $1$, ma
come è evidente dal disegno questo è impossibile per $\alpha>0$.
Siamo dunque costretti ad accettare il fatto che con una probabilità
pari a $1-\beta$ ($36.13\%$ in questo caso) noi non rifiuteremo
$H_{0}$ quando questa andrebbe invece rifiutata. Come descritto precedentemente
$1-\beta$ è l'errore di seconda specie. In questo semplice e\-sem\-pio
ad un errore di prima specie del $5\%$ corrisponde un errore di seconda
specie del $36.13\%$.

\bigskip{}


\noindent Potremmo decidere a questo punto di diminuire l'errore di
prima specie (il livello di significatività)\ e portarlo al $2.5\%$.
Cosa capiterà a $\beta$ ed indirettamente all'errore di seconda specie
$1-\beta$? Calcoliamo innanzi tutto il nuovo valore critico di $k$,
ovvero

\[
P_{H_{0}}(X>k)=0.025\Rightarrow k_{97.5\%}=z_{97.5\%}=1.96.\]
 Abbiamo ridotto l'errore di prima specie ed il valore di $k$ si
è spostato sulla destra rispetto al valore precedente. Cosa implica
questo per $\beta$? Sappiamo che \[
\beta=P_{H_{A}}\left(\text{Rifiuto }H_{0}\right)=P_{H_{A}}\left(X>1.96\right).\]
 Per calcolare $\beta$ usiamo la solita tecnica di standardizzazione
tenendo presente che sotto l'ipotesi alternativa $X\sim N(2,1)$:\begin{eqnarray*}
\beta & = & P_{H_{A}}\left(X>1.96\right)=P_{H_{A}}\left(\underset{Z\sim N(0,1)}{\underbrace{X-2}}>-0.04\right)\\
 & = & P\left(Z\leq0.04\right)=51.6\%\end{eqnarray*}


\noindent Guardando il disegno notiamo che la superficie a destra
di $k$ delimitata dalla densità tratteggiata è diminuita rispetto
al valore precedente. Si è quindi ridotta la probabilità $\beta$
di rifiutare $H_{0}$ quando questa andrebbe giustamente rifiutata:
ora $\beta=51.6\%$ mentre prima era $63.87\%$. L'errore di seconda
specie $1-\beta$ è dunque aumentato, passando dal $36.13\%$ al $48.4\%$.

\bigskip{}


\noindent Da questo esempio deduciamo che esiste un relazione inversa
fra errore di prima specie ed errore di seconda specie nel senso che
qualora si decida di diminuire la probabilità d'errore di prima specie
si dovrà pagare un costo in termini della probabilità d'errore di
seconda specie e viceversa. Possiamo semplicemente scrivere quanto
detto a parole con\[
\alpha\downarrow\Rightarrow1-\beta\uparrow.\]
 Per tale motivo non è possibile scendere a zero con entrambe le probabilità.
Si è pertanto soliti fissare il livello di significatività $\alpha$
ad un livello appropriato. Come detto, in econometria si utilizza
un $\alpha=5\%$. Il nostro sistema giuridico per contro assegna maggiore
importanza all'errore di $1^{a}$ specie (dichiarare colpevole un
innocente) e per tale motivo i valori di $\alpha$ saranno di molto
inferiori (radar detection $\alpha=10^{-10}\%$).


\subsection{Potenza di un test}

J. Neyman e E. Pearson, due famosi statistici del ventesimo secolo,
propongono di fissare $\alpha$, il livello di significatività del
test e di massimizzare%
\footnote{Che corrisponde a minimizzare l'errore di seconda specie $1-\beta$.%
} la probabilità $\beta=P($Rifiutare $H_{0}\ \mid\ H_{0}$ è falsa$)$.
La probabilità $\beta$ è chiamata potenza del test.

\begin{definizione} Potenza di un test (caso unilaterale destro).
La potenza di un test, notata $\beta$, è definita come la probabilità
di rifiutare $H_{0}$ quando essa è falsa%
\footnote{Per un test unilaterale sinistro la potenza è definita da \[
\beta=P_{H_{A}}(S<k_{\alpha})\]
 e per un test bilaterale

\[
\beta=P_{H_{A}}(|S|>k_{1-\frac{\alpha}{2}}).\]
 %
}\[
\beta=P_{H_{A}}(S>k_{1-\alpha}).\]
 \end{definizione}

\begin{esempio} Nell'Esempio \ref{esempio caseificio p1} del caseificio
abbiamo costruito due possibili test d'ipotesi, il primo basato sulla
media $\overline{X}$ del campione ed il secondo basato sul minimo
$X_{\min}$ del campione. Per un livello di significatività del $5\%$
i due test avevano condotto alla medesima conclusione. Nel primo caso
(uso di $\overline{X}$) il valore critico $k_{0.95}=-0.539$, infatti
\[
P_{H_{0}}(\overline{X}>-0.539)=5\%.\]
 Nel secondo caso (uso di $X_{\min}$) il valore critico $k_{0.95}=-0.546$
\[
P_{H_{0}}(X_{\min}>-0.546)=5\%.\]
 Vogliamo ora calcolare la potenza $\beta$ per entrambi i test, che
per definizione sappiamo essere\[
\beta=P_{H_{A}}(\overline{X}>-0.539)\]
 e rispettivamente\[
\beta=P_{H_{A}}(X_{\min}>-0.546).\]
 Tuttavia l'ipotesi alternativa $H_{A}:\mu>-0.545$ non identifica
con precisione la distribuzione, essa si limita a dire che il valore
atteso della popolazione $X$ è superiore a $-0.545$. Per tale motivo
eseguiamo dapprima il calcolo per un particolare valore di $\mu>-0.545$,
diciamo $\mu=-0.54$, ed in seguito per un valore di $\mu>-0.545$
qualsiasi. \end{esempio}


\subsubsection{Potenza quando $S=\overline{X}$}

$\bullet$ Caso particolare, ipotesi alternativa $X\sim N(-0.54,0.008^{2})$
$\Rightarrow\overline{X}\sim N(-0.54,0.008^{2}/5)$\begin{eqnarray*}
\beta & = & P_{H_{A}}(\overline{X}>-0.539)=P_{H_{A}}\left(\underset{Z\sim N(0,1)}{\underbrace{\frac{\overline{X}-(-0.54)}{0.008/\sqrt{5}}}}>\frac{-0.539-(-0.54)}{0.008/\sqrt{5}}\right)\\
 & = & P\left(Z>0.2795\right)=1-P\left(Z\leq0.2795\right)=0.39\end{eqnarray*}


\noindent $\bullet$ Caso generale, ipotesi alternativa $X\sim N(\mu,0.008^{2})$
$\Rightarrow\overline{X}\sim N(\mu,0.008^{2}/5)$ con $\mu>-0.545$

\noindent Il calcolo è esattamente uguale al precedente, basta sostituire
$-0.54$ con $\mu$\[
P_{H_{A}}(\overline{X}>-0.539)=P_{H_{A}}\left(\underset{Z\sim N(0,1)}{\underbrace{\frac{\overline{X}-\mu}{0.008/\sqrt{5}}}}>\frac{-0.539-\mu}{0.008/\sqrt{5}}\right)=P\left(Z>\frac{-0.539-\mu}{0.008/\sqrt{5}}\right).\]
 Il valore assunto da $\beta$ dipende dal valore di $\mu$. È dunque
possibile rappresentare graficamente $\beta$ come funzione del valore
del parametro $\mu$.


\subsubsection{Potenza quando $S=X_{\min}$}

\noindent $\bullet$ Caso particolare, ipotesi alternativa $X\sim N(-0.54,0.008^{2})$

\noindent Nel paragrafo \ref{formulazione test xmin}, punto 4, abbiamo
derivato la distribuzione di $X_{\min}$ sotto l'ipotesi nulla. La
funzione di ripartizione di $S$ sotto l'ipotesi alternativa sarà
del tutto simile, e cioè \[
\beta=P_{H_{A}}(S>-0.546)=1-F_{S}(-0.546)=\left[1-F_{X}(-0.546)\right]^{5}\]
 ma con $F_{X}(s)$ che rappresenta ora la funzione di ripartizione
di $X$ sotto $H_{A}$, ovvero la funzione di ripartizione di una
$V.A.$ normale di valore atteso $-0.54$ e varianza $0.008^{2}$.
Il valore di $\beta$ è dunque\[
\beta=\left[1-F_{X}(-0.546)\right]^{5}=0.277\]
 Osserviamo che il valore calcolato è inferiore a quello ottenuto
utilizzando la media $\overline{X}$ del campione. Ciò significa che\ quando
l'ipotesi nulla è falsa, il test basato sulla statistica $S=X_{\min}$
la rigetterà con una probabilità di solo il $27.7\%$ mentre il test
basato sulla statistica $S=\overline{X}$ la rigetterà con una probabilità
ben superiore ed uguale al $39\%$. Il test sulla media $\overline{X}$
è dunque da preferirsi rispetto al test sul minimo $X_{\min}$ poiché
\emph{più potente} nel testare $H_{0}$ contro l'ipotesi alternativa
$H_{A}:\mu=-0.54$. È interessante chiedersi se questo vale solo per
$\mu=-0.54$ o la superiorità del test sulla media è \textquotedblright{}uniforme\textquotedblright{}\ per
qualsiasi $\mu>-0.545$.\pagebreak

\noindent $\bullet$ Caso generale, ipotesi alternativa $X\sim N(\mu,0.008^{2})$.
In questo caso come con la media calcoleremo $\beta=P_{H_{A}}(S>-0.546)$
per un qualsiasi valore di $\mu>-0.545$. Il grafico della potenza
$\beta$ del test in funzione di $\mu$ dà il seguente risultatoSovrapponendo
nel medesimo grafico le curve di potenza dei due test notiamo che
effettivamente il test sulla media è da preferire al test sul minimo
per qualsiasi ipotesi alternativa semplice $H_{A}:\mu=\widetilde{\mu}>-0.545$.Vogliamo
ora metterci nei panni del fornitore di latte e ragionare rispetto
alla scelta del test ottimale. Supponiamo dapprima che egli sia innocente,
cioè che $H_{0}$ sia corretta. Per il fornitore è indifferente che
la corte utilizzi il test basato sulla media campionaria $\overline{X}$
o sul minimo $X_{\min}$. Questo perché, in entrambi i casi, la probabilità
di essere ingiustamente condannato (errore di prima specie)\ è uguale
$5\%$. Per contro, supponiamo che egli sappia di essere colpevole
o, in altre parole, che $H_{A}$ sia vera. In tal caso egli non sarà
più indifferente rispetto alla scelta del test. Infatti, qualora la
corte utilizzasse il test sulla media, la probabilità $\beta$ di
essere (giustamente) condannato sarebbe uguale al $39\%$ mentre per
il test basato su $X_{\min}$ la probabilità sarebbe solo del $27.7\%$.
È chiaro quindi che il fornitore preferirà il test meno potente poiché
meno efficace nello scoprire la verità. Il tribunale per contro, deciderà
di utilizzare il test più potente a disposizione che in questo caso
è il test basato su $\overline{X}$.

\bigskip{}


\noindent In generale potremmo chiederci se, dati 
\begin{itemize}
\item un'ipotesi nulla $H_{0}:\mu=\mu_{0}$, 
\item un'ipotesi alternativa $H_{A}:\mu=\mu_{A}$, 
\item un livello prefissato $\alpha$ di significatività (errore di prima
specie), 
\end{itemize}
\noindent sia possibile trovare (costruire) un test che, fra tutti
i possibili test, sia il più potente in assoluto. La risposta a questo
quesito ci è data dall'importante lemma di Neyman e Pearson.


\section{Il Lemma di Neyman e Pearson}

In questo paragrafo daremo una soluzione alla domanda che ci siamo
posti al termine del paragrafo precedente, ovvero come trovare il
test di massima potenza (ricordiamo che la potenza di un test è la
probabilità di rifiutare $H_{0}$ quando questa è falsa). Prima di
dare la soluzione cerchiamo di formalizzare il problema i cui elementi
essenziali sono i seguenti. 
\begin{enumerate}
\item Una popolazione $X$ la cui distribuzione, caratterizzata tramite
la sua funzione di densità, è sconosciuta. Si suppone che la densità
di $X$ sia contenuta nella famiglia parametrica \[
\mathcal{P}=\left\{ f_{\theta}(x),\ \theta\in\Theta\right\} .\]

\item Un'ipotesi nulla $H_{0}$ riguardante la distribuzione di $X$. Tale
ipotesi è espressa in termini del parametro sconosciuto $\theta$
nel seguente modo\[
H_{0}:\theta=\theta_{0}\]
 dove $\theta_{0}$ rappresenta un particolare valore del parametro
($\theta_{0}$ è quindi un numero). 
\item Un'ipotesi alternativa semplice \[
H_{A}:\theta=\theta_{A}\]
 dove $\theta_{A}$ è il valore che il parametro $\theta$ assume
sotto l'ipotesi alternativa. 
\item Il livello $\alpha$ di significatività desiderato (errore di prima
specie). 
\end{enumerate}
\noindent Sulla base di questi elementi desideriamo costruire il test
ottimale. Ricordiamo che un qualsiasi test basato sulla statistica
$S$ sarà caratterizzato da una regione critica $R$ definita tramite%
\footnote{Se i valori osservati danno un valore della statistica $S$ superiore
alla soglia $k_{1-\alpha}$ si rifiuta l'ipotesi nulla. Si veda gli
esempi con $\overline{X}$ e $X_{\min}$.%
}\begin{equation}
R=\left\{ (x_{1},...,x_{n})\mid S(x_{1},...,x_{n})>k_{1-\alpha}\right\} \end{equation}
 dove la soglia $k_{1-\alpha}$ è stata scelta in maniera tale che
la regione critica $R$ soddisfi%
\footnote{Una volta scelta la statistica $S$, il valore della soglia $k_{\alpha}$
è automaticamente fissato tramite l'equazione (\ref{soglia k_alpha}).
In pratica quindi il problema si riduce alla scelta ottimale di $S$.%
}\begin{equation}
P_{H_{0}}(R)=P_{H_{0}}(S>k_{1-\alpha})=\alpha\text{.}\label{soglia k_alpha}\end{equation}
 Il problema risiede quindi nel trovare la statistica $S^{\ast}$
(e la soglia $k_{\alpha}^{\ast}$ corrispondente) tale per cui \begin{equation}
P_{H_{A}}(R^{\ast})=P_{H_{A}}(S^{\ast}>k_{\alpha}^{\ast})=P(\text{rifiuto }H_{0}\text{ }|\ H_{0}\text{ è falsa})=\beta\end{equation}
 sia massimo rispetto a qualsiasi altra statistica $S$.

\begin{esempio} \label{esempio grotta}State passeggiando tranquillamente
nel bosco quando notate l'entrata di una grotta ed incuriositi decidete
di entrarvi. Nel suo interno la luce è molto debole, tanto che dopo
alcuni metri la visibilità è praticamente nulla. A questo punto decidete
di tornare indietro ma all'improvviso andate ad inciampare contro
un baule che una volta aperto risulta contenere 100 kg di gioielli
e pietre preziose di ogni genere, colore e dimensione. Volendo approfittare
della situazione, decidete di riempire lo zaino con le gemme e i gioielli
più preziosi. Purtroppo per voi però, lo zaino ha una capacità massima
di $\alpha=5$ kg. Vi trovate dunque nella spiacevole situazione di
dover selezionare, tramite un'opportuna strategia di selezione $S$,
quali gioielli mettere nello zaino. L'insieme dei gioielli e delle
pietre preziose che verranno da voi scelti è notato $R$ (raccolto).
Ogni gioiello/pietra $g$ ha un peso $p_{s}(g)$ ed un prezzo di mercato
$p_{r}(g)$. Il vostro scopo è dunque quello di massimizzare il valore
della raccolto, sotto il vincolo che il suo peso sia uguale ad $\alpha$.

\noindent Supponiamo che i gioielli contenuti nel baule siano quelli
della Tabella (\ref{table:esempio1_neyman_pearson}). Per massimizzare
il valore del contenuto dello zaino dobbiamo semplicemente ordinare
i gioielli in ordine decrescente rispetto al rapporto prezzo/peso.
Così facendo ci assicuriamo di prendere gli oggetti di maggior valore
per unità di peso.\vspace{0.5cm}


\noindent La Tabella (\ref{table:esempio2_neyman_pearson}) contenente
la lista dei gioielli ordinata rispetto al rapporto prezzo/peso permette
di costruire l'insieme $R^{\ast}$ della raccolto ottimale, che corrisponde
a \[
R^{\ast}=\left\{ g_{32},g_{24},g_{1},g_{21},g_{36},g_{16},g_{27}\right\} .\]
 Notiamo che la strategia di selezione ottimale $S^{\ast}(x)=\frac{p_{r}(g)}{p_{s}(g)}$
prevede di prendere solo gli oggetti aventi un rapporto prezzo/peso
superiore ad una soglia $k_{\alpha}^{\ast}$, che nel nostro caso
è uguale a 7'481.30. Tale soglia è stata scelta in maniera che il
peso complessivo della regione critica sia uguale ad $\alpha$ ovvero
$5$ kg. Formalmente abbiamo determinato $k_{\alpha}^{\ast}$ tramite
la seguente relazione ($P_{s}$ denota il peso totale)\[
P_{s}(R^{\ast})=P_{s}(g\ |\ S^{\ast}(g)>k_{\alpha}^{\ast})=5\ \text{kg.}\]
 \end{esempio}

\begin{theorem} La strategia di selezione $S^{\ast}=\frac{p_{r}(g)}{p_{s}(g)}>k_{\alpha}^{\ast}$
massimizza il valore (prezzo totale) del raccolto $R$\ rispetto
a tutte le possibili strategie $S$ aventi una raccolto $R$ di peso
$5$ kg. \end{theorem}

\vspace{0.5cm}


%TCIMACRO{\TeXButton{TeX field}{\def\JPicScale{0.8}}}%
%BeginExpansion
\global\long\global\long\def\JPicScale{0.8}
 %EndExpansion


\unitlength 0.8 mm \begin{picture}(150,90)(0,0) \linethickness{0.3mm}
\put(0,90){\line(1,0){150}} \put(0,10){\line(0,1){80}}
\put(150,10){\line(0,1){80}} \put(0,10){\line(1,0){150}}
\linethickness{0.3mm} \put(80.01,54.75){\line(0,1){0.5}} \multiput(80,55.74)(0.01,-0.5){1}{\line(0,-1){0.5}}
\multiput(79.98,56.24)(0.02,-0.5){1}{\line(0,-1){0.5}} \multiput(79.95,56.73)(0.03,-0.5){1}{\line(0,-1){0.5}}
\multiput(79.91,57.23)(0.04,-0.5){1}{\line(0,-1){0.5}} \multiput(79.86,57.72)(0.05,-0.49){1}{\line(0,-1){0.49}}
\multiput(79.8,58.22)(0.06,-0.49){1}{\line(0,-1){0.49}} \multiput(79.73,58.71)(0.07,-0.49){1}{\line(0,-1){0.49}}
\multiput(79.65,59.2)(0.08,-0.49){1}{\line(0,-1){0.49}} \multiput(79.57,59.69)(0.09,-0.49){1}{\line(0,-1){0.49}}
\multiput(79.47,60.18)(0.1,-0.49){1}{\line(0,-1){0.49}} \multiput(79.36,60.66)(0.11,-0.49){1}{\line(0,-1){0.49}}
\multiput(79.24,61.15)(0.12,-0.48){1}{\line(0,-1){0.48}} \multiput(79.11,61.63)(0.13,-0.48){1}{\line(0,-1){0.48}}
\multiput(78.98,62.11)(0.14,-0.48){1}{\line(0,-1){0.48}} \multiput(78.83,62.58)(0.15,-0.48){1}{\line(0,-1){0.48}}
\multiput(78.68,63.05)(0.16,-0.47){1}{\line(0,-1){0.47}} \multiput(78.51,63.52)(0.16,-0.47){1}{\line(0,-1){0.47}}
\multiput(78.34,63.99)(0.17,-0.47){1}{\line(0,-1){0.47}} \multiput(78.15,64.45)(0.09,-0.23){2}{\line(0,-1){0.23}}
\multiput(77.96,64.91)(0.1,-0.23){2}{\line(0,-1){0.23}} \multiput(77.76,65.36)(0.1,-0.23){2}{\line(0,-1){0.23}}
\multiput(77.55,65.81)(0.11,-0.23){2}{\line(0,-1){0.23}} \multiput(77.33,66.26)(0.11,-0.22){2}{\line(0,-1){0.22}}
\multiput(77.1,66.7)(0.11,-0.22){2}{\line(0,-1){0.22}} \multiput(76.86,67.14)(0.12,-0.22){2}{\line(0,-1){0.22}}
\multiput(76.62,67.57)(0.12,-0.22){2}{\line(0,-1){0.22}} \multiput(76.36,68)(0.13,-0.21){2}{\line(0,-1){0.21}}
\multiput(76.1,68.42)(0.13,-0.21){2}{\line(0,-1){0.21}} \multiput(75.83,68.84)(0.14,-0.21){2}{\line(0,-1){0.21}}
\multiput(75.55,69.25)(0.14,-0.21){2}{\line(0,-1){0.21}} \multiput(75.26,69.65)(0.14,-0.2){2}{\line(0,-1){0.2}}
\multiput(74.97,70.05)(0.15,-0.2){2}{\line(0,-1){0.2}} \multiput(74.66,70.45)(0.1,-0.13){3}{\line(0,-1){0.13}}
\multiput(74.35,70.83)(0.1,-0.13){3}{\line(0,-1){0.13}} \multiput(74.03,71.22)(0.11,-0.13){3}{\line(0,-1){0.13}}
\multiput(73.71,71.59)(0.11,-0.13){3}{\line(0,-1){0.13}} \multiput(73.37,71.96)(0.11,-0.12){3}{\line(0,-1){0.12}}
\multiput(73.03,72.32)(0.11,-0.12){3}{\line(0,-1){0.12}} \multiput(72.69,72.68)(0.12,-0.12){3}{\line(0,-1){0.12}}
\multiput(72.33,73.03)(0.12,-0.12){3}{\line(1,0){0.12}} \multiput(71.97,73.37)(0.12,-0.11){3}{\line(1,0){0.12}}
\multiput(71.6,73.7)(0.12,-0.11){3}{\line(1,0){0.12}} \multiput(71.23,74.03)(0.13,-0.11){3}{\line(1,0){0.13}}
\multiput(70.84,74.34)(0.13,-0.11){3}{\line(1,0){0.13}} \multiput(70.46,74.66)(0.13,-0.1){3}{\line(1,0){0.13}}
\multiput(70.06,74.96)(0.13,-0.1){3}{\line(1,0){0.13}} \multiput(69.66,75.25)(0.2,-0.15){2}{\line(1,0){0.2}}
\multiput(69.26,75.54)(0.2,-0.14){2}{\line(1,0){0.2}} \multiput(68.84,75.82)(0.21,-0.14){2}{\line(1,0){0.21}}
\multiput(68.43,76.09)(0.21,-0.14){2}{\line(1,0){0.21}} \multiput(68.01,76.36)(0.21,-0.13){2}{\line(1,0){0.21}}
\multiput(67.58,76.61)(0.21,-0.13){2}{\line(1,0){0.21}} \multiput(67.15,76.86)(0.22,-0.12){2}{\line(1,0){0.22}}
\multiput(66.71,77.09)(0.22,-0.12){2}{\line(1,0){0.22}} \multiput(66.27,77.32)(0.22,-0.11){2}{\line(1,0){0.22}}
\multiput(65.82,77.54)(0.22,-0.11){2}{\line(1,0){0.22}} \multiput(65.37,77.75)(0.23,-0.11){2}{\line(1,0){0.23}}
\multiput(64.92,77.95)(0.23,-0.1){2}{\line(1,0){0.23}} \multiput(64.46,78.14)(0.23,-0.1){2}{\line(1,0){0.23}}
\multiput(64,78.33)(0.23,-0.09){2}{\line(1,0){0.23}} \multiput(63.53,78.5)(0.47,-0.17){1}{\line(1,0){0.47}}
\multiput(63.06,78.67)(0.47,-0.16){1}{\line(1,0){0.47}} \multiput(62.59,78.82)(0.47,-0.16){1}{\line(1,0){0.47}}
\multiput(62.11,78.97)(0.48,-0.15){1}{\line(1,0){0.48}} \multiput(61.64,79.11)(0.48,-0.14){1}{\line(1,0){0.48}}
\multiput(61.16,79.23)(0.48,-0.13){1}{\line(1,0){0.48}} \multiput(60.67,79.35)(0.48,-0.12){1}{\line(1,0){0.48}}
\multiput(60.19,79.46)(0.49,-0.11){1}{\line(1,0){0.49}} \multiput(59.7,79.56)(0.49,-0.1){1}{\line(1,0){0.49}}
\multiput(59.21,79.64)(0.49,-0.09){1}{\line(1,0){0.49}} \multiput(58.72,79.72)(0.49,-0.08){1}{\line(1,0){0.49}}
\multiput(58.23,79.79)(0.49,-0.07){1}{\line(1,0){0.49}} \multiput(57.73,79.85)(0.49,-0.06){1}{\line(1,0){0.49}}
\multiput(57.24,79.9)(0.49,-0.05){1}{\line(1,0){0.49}} \multiput(56.74,79.94)(0.5,-0.04){1}{\line(1,0){0.5}}
\multiput(56.25,79.97)(0.5,-0.03){1}{\line(1,0){0.5}} \multiput(55.75,79.99)(0.5,-0.02){1}{\line(1,0){0.5}}
\multiput(55.25,80)(0.5,-0.01){1}{\line(1,0){0.5}} \put(54.76,80){\line(1,0){0.5}}
\multiput(54.26,79.99)(0.5,0.01){1}{\line(1,0){0.5}} \multiput(53.76,79.97)(0.5,0.02){1}{\line(1,0){0.5}}
\multiput(53.27,79.94)(0.5,0.03){1}{\line(1,0){0.5}} \multiput(52.77,79.9)(0.5,0.04){1}{\line(1,0){0.5}}
\multiput(52.27,79.85)(0.49,0.05){1}{\line(1,0){0.49}} \multiput(51.78,79.79)(0.49,0.06){1}{\line(1,0){0.49}}
\multiput(51.29,79.72)(0.49,0.07){1}{\line(1,0){0.49}} \multiput(50.8,79.64)(0.49,0.08){1}{\line(1,0){0.49}}
\multiput(50.31,79.56)(0.49,0.09){1}{\line(1,0){0.49}} \multiput(49.82,79.46)(0.49,0.1){1}{\line(1,0){0.49}}
\multiput(49.34,79.35)(0.49,0.11){1}{\line(1,0){0.49}} \multiput(48.85,79.23)(0.48,0.12){1}{\line(1,0){0.48}}
\multiput(48.37,79.11)(0.48,0.13){1}{\line(1,0){0.48}} \multiput(47.89,78.97)(0.48,0.14){1}{\line(1,0){0.48}}
\multiput(47.42,78.82)(0.48,0.15){1}{\line(1,0){0.48}} \multiput(46.95,78.67)(0.47,0.16){1}{\line(1,0){0.47}}
\multiput(46.48,78.5)(0.47,0.16){1}{\line(1,0){0.47}} \multiput(46.01,78.33)(0.47,0.17){1}{\line(1,0){0.47}}
\multiput(45.55,78.14)(0.23,0.09){2}{\line(1,0){0.23}} \multiput(45.09,77.95)(0.23,0.1){2}{\line(1,0){0.23}}
\multiput(44.64,77.75)(0.23,0.1){2}{\line(1,0){0.23}} \multiput(44.19,77.54)(0.23,0.11){2}{\line(1,0){0.23}}
\multiput(43.74,77.32)(0.22,0.11){2}{\line(1,0){0.22}} \multiput(43.3,77.09)(0.22,0.11){2}{\line(1,0){0.22}}
\multiput(42.86,76.86)(0.22,0.12){2}{\line(1,0){0.22}} \multiput(42.43,76.61)(0.22,0.12){2}{\line(1,0){0.22}}
\multiput(42,76.36)(0.21,0.13){2}{\line(1,0){0.21}} \multiput(41.58,76.09)(0.21,0.13){2}{\line(1,0){0.21}}
\multiput(41.16,75.82)(0.21,0.14){2}{\line(1,0){0.21}} \multiput(40.75,75.54)(0.21,0.14){2}{\line(1,0){0.21}}
\multiput(40.35,75.25)(0.2,0.14){2}{\line(1,0){0.2}} \multiput(39.95,74.96)(0.2,0.15){2}{\line(1,0){0.2}}
\multiput(39.55,74.66)(0.13,0.1){3}{\line(1,0){0.13}} \multiput(39.16,74.34)(0.13,0.1){3}{\line(1,0){0.13}}
\multiput(38.78,74.03)(0.13,0.11){3}{\line(1,0){0.13}} \multiput(38.41,73.7)(0.13,0.11){3}{\line(1,0){0.13}}
\multiput(38.04,73.37)(0.12,0.11){3}{\line(1,0){0.12}} \multiput(37.68,73.03)(0.12,0.11){3}{\line(1,0){0.12}}
\multiput(37.32,72.68)(0.12,0.12){3}{\line(1,0){0.12}} \multiput(36.97,72.32)(0.12,0.12){3}{\line(0,1){0.12}}
\multiput(36.63,71.96)(0.11,0.12){3}{\line(0,1){0.12}} \multiput(36.3,71.59)(0.11,0.12){3}{\line(0,1){0.12}}
\multiput(35.97,71.22)(0.11,0.13){3}{\line(0,1){0.13}} \multiput(35.65,70.83)(0.11,0.13){3}{\line(0,1){0.13}}
\multiput(35.34,70.45)(0.1,0.13){3}{\line(0,1){0.13}} \multiput(35.04,70.05)(0.1,0.13){3}{\line(0,1){0.13}}
\multiput(34.74,69.65)(0.15,0.2){2}{\line(0,1){0.2}} \multiput(34.46,69.25)(0.14,0.2){2}{\line(0,1){0.2}}
\multiput(34.18,68.84)(0.14,0.21){2}{\line(0,1){0.21}} \multiput(33.91,68.42)(0.14,0.21){2}{\line(0,1){0.21}}
\multiput(33.64,68)(0.13,0.21){2}{\line(0,1){0.21}} \multiput(33.39,67.57)(0.13,0.21){2}{\line(0,1){0.21}}
\multiput(33.14,67.14)(0.12,0.22){2}{\line(0,1){0.22}} \multiput(32.91,66.7)(0.12,0.22){2}{\line(0,1){0.22}}
\multiput(32.68,66.26)(0.11,0.22){2}{\line(0,1){0.22}} \multiput(32.46,65.81)(0.11,0.22){2}{\line(0,1){0.22}}
\multiput(32.25,65.36)(0.11,0.23){2}{\line(0,1){0.23}} \multiput(32.05,64.91)(0.1,0.23){2}{\line(0,1){0.23}}
\multiput(31.85,64.45)(0.1,0.23){2}{\line(0,1){0.23}} \multiput(31.67,63.99)(0.09,0.23){2}{\line(0,1){0.23}}
\multiput(31.5,63.52)(0.17,0.47){1}{\line(0,1){0.47}} \multiput(31.33,63.05)(0.16,0.47){1}{\line(0,1){0.47}}
\multiput(31.18,62.58)(0.16,0.47){1}{\line(0,1){0.47}} \multiput(31.03,62.11)(0.15,0.48){1}{\line(0,1){0.48}}
\multiput(30.89,61.63)(0.14,0.48){1}{\line(0,1){0.48}} \multiput(30.77,61.15)(0.13,0.48){1}{\line(0,1){0.48}}
\multiput(30.65,60.66)(0.12,0.48){1}{\line(0,1){0.48}} \multiput(30.54,60.18)(0.11,0.49){1}{\line(0,1){0.49}}
\multiput(30.44,59.69)(0.1,0.49){1}{\line(0,1){0.49}} \multiput(30.35,59.2)(0.09,0.49){1}{\line(0,1){0.49}}
\multiput(30.28,58.71)(0.08,0.49){1}{\line(0,1){0.49}} \multiput(30.21,58.22)(0.07,0.49){1}{\line(0,1){0.49}}
\multiput(30.15,57.72)(0.06,0.49){1}{\line(0,1){0.49}} \multiput(30.1,57.23)(0.05,0.49){1}{\line(0,1){0.49}}
\multiput(30.06,56.73)(0.04,0.5){1}{\line(0,1){0.5}} \multiput(30.03,56.24)(0.03,0.5){1}{\line(0,1){0.5}}
\multiput(30.01,55.74)(0.02,0.5){1}{\line(0,1){0.5}} \multiput(30,55.24)(0.01,0.5){1}{\line(0,1){0.5}}
\put(30,54.75){\line(0,1){0.5}} \multiput(30,54.75)(0.01,-0.5){1}{\line(0,-1){0.5}}
\multiput(30.01,54.25)(0.02,-0.5){1}{\line(0,-1){0.5}} \multiput(30.03,53.75)(0.03,-0.5){1}{\line(0,-1){0.5}}
\multiput(30.06,53.26)(0.04,-0.5){1}{\line(0,-1){0.5}} \multiput(30.1,52.76)(0.05,-0.49){1}{\line(0,-1){0.49}}
\multiput(30.15,52.27)(0.06,-0.49){1}{\line(0,-1){0.49}} \multiput(30.21,51.77)(0.07,-0.49){1}{\line(0,-1){0.49}}
\multiput(30.28,51.28)(0.08,-0.49){1}{\line(0,-1){0.49}} \multiput(30.35,50.79)(0.09,-0.49){1}{\line(0,-1){0.49}}
\multiput(30.44,50.3)(0.1,-0.49){1}{\line(0,-1){0.49}} \multiput(30.54,49.81)(0.11,-0.49){1}{\line(0,-1){0.49}}
\multiput(30.65,49.33)(0.12,-0.48){1}{\line(0,-1){0.48}} \multiput(30.77,48.84)(0.13,-0.48){1}{\line(0,-1){0.48}}
\multiput(30.89,48.36)(0.14,-0.48){1}{\line(0,-1){0.48}} \multiput(31.03,47.89)(0.15,-0.48){1}{\line(0,-1){0.48}}
\multiput(31.18,47.41)(0.16,-0.47){1}{\line(0,-1){0.47}} \multiput(31.33,46.94)(0.16,-0.47){1}{\line(0,-1){0.47}}
\multiput(31.5,46.47)(0.17,-0.47){1}{\line(0,-1){0.47}} \multiput(31.67,46)(0.09,-0.23){2}{\line(0,-1){0.23}}
\multiput(31.85,45.54)(0.1,-0.23){2}{\line(0,-1){0.23}} \multiput(32.05,45.08)(0.1,-0.23){2}{\line(0,-1){0.23}}
\multiput(32.25,44.63)(0.11,-0.23){2}{\line(0,-1){0.23}} \multiput(32.46,44.18)(0.11,-0.22){2}{\line(0,-1){0.22}}
\multiput(32.68,43.73)(0.11,-0.22){2}{\line(0,-1){0.22}} \multiput(32.91,43.29)(0.12,-0.22){2}{\line(0,-1){0.22}}
\multiput(33.14,42.85)(0.12,-0.22){2}{\line(0,-1){0.22}} \multiput(33.39,42.42)(0.13,-0.21){2}{\line(0,-1){0.21}}
\multiput(33.64,41.99)(0.13,-0.21){2}{\line(0,-1){0.21}} \multiput(33.91,41.57)(0.14,-0.21){2}{\line(0,-1){0.21}}
\multiput(34.18,41.15)(0.14,-0.21){2}{\line(0,-1){0.21}} \multiput(34.46,40.74)(0.14,-0.2){2}{\line(0,-1){0.2}}
\multiput(34.74,40.34)(0.15,-0.2){2}{\line(0,-1){0.2}} \multiput(35.04,39.94)(0.1,-0.13){3}{\line(0,-1){0.13}}
\multiput(35.34,39.54)(0.1,-0.13){3}{\line(0,-1){0.13}} \multiput(35.65,39.16)(0.11,-0.13){3}{\line(0,-1){0.13}}
\multiput(35.97,38.77)(0.11,-0.13){3}{\line(0,-1){0.13}} \multiput(36.3,38.4)(0.11,-0.12){3}{\line(0,-1){0.12}}
\multiput(36.63,38.03)(0.11,-0.12){3}{\line(0,-1){0.12}} \multiput(36.97,37.67)(0.12,-0.12){3}{\line(0,-1){0.12}}
\multiput(37.32,37.31)(0.12,-0.12){3}{\line(1,0){0.12}} \multiput(37.68,36.97)(0.12,-0.11){3}{\line(1,0){0.12}}
\multiput(38.04,36.62)(0.12,-0.11){3}{\line(1,0){0.12}} \multiput(38.41,36.29)(0.13,-0.11){3}{\line(1,0){0.13}}
\multiput(38.78,35.96)(0.13,-0.11){3}{\line(1,0){0.13}} \multiput(39.16,35.65)(0.13,-0.1){3}{\line(1,0){0.13}}
\multiput(39.55,35.33)(0.13,-0.1){3}{\line(1,0){0.13}} \multiput(39.95,35.03)(0.2,-0.15){2}{\line(1,0){0.2}}
\multiput(40.35,34.74)(0.2,-0.14){2}{\line(1,0){0.2}} \multiput(40.75,34.45)(0.21,-0.14){2}{\line(1,0){0.21}}
\multiput(41.16,34.17)(0.21,-0.14){2}{\line(1,0){0.21}} \multiput(41.58,33.9)(0.21,-0.13){2}{\line(1,0){0.21}}
\multiput(42,33.64)(0.21,-0.13){2}{\line(1,0){0.21}} \multiput(42.43,33.38)(0.22,-0.12){2}{\line(1,0){0.22}}
\multiput(42.86,33.14)(0.22,-0.12){2}{\line(1,0){0.22}} \multiput(43.3,32.9)(0.22,-0.11){2}{\line(1,0){0.22}}
\multiput(43.74,32.67)(0.22,-0.11){2}{\line(1,0){0.22}} \multiput(44.19,32.45)(0.23,-0.11){2}{\line(1,0){0.23}}
\multiput(44.64,32.24)(0.23,-0.1){2}{\line(1,0){0.23}} \multiput(45.09,32.04)(0.23,-0.1){2}{\line(1,0){0.23}}
\multiput(45.55,31.85)(0.23,-0.09){2}{\line(1,0){0.23}} \multiput(46.01,31.66)(0.47,-0.17){1}{\line(1,0){0.47}}
\multiput(46.48,31.49)(0.47,-0.16){1}{\line(1,0){0.47}} \multiput(46.95,31.32)(0.47,-0.16){1}{\line(1,0){0.47}}
\multiput(47.42,31.17)(0.48,-0.15){1}{\line(1,0){0.48}} \multiput(47.89,31.02)(0.48,-0.14){1}{\line(1,0){0.48}}
\multiput(48.37,30.88)(0.48,-0.13){1}{\line(1,0){0.48}} \multiput(48.85,30.76)(0.48,-0.12){1}{\line(1,0){0.48}}
\multiput(49.34,30.64)(0.49,-0.11){1}{\line(1,0){0.49}} \multiput(49.82,30.53)(0.49,-0.1){1}{\line(1,0){0.49}}
\multiput(50.31,30.43)(0.49,-0.09){1}{\line(1,0){0.49}} \multiput(50.8,30.35)(0.49,-0.08){1}{\line(1,0){0.49}}
\multiput(51.29,30.27)(0.49,-0.07){1}{\line(1,0){0.49}} \multiput(51.78,30.2)(0.49,-0.06){1}{\line(1,0){0.49}}
\multiput(52.27,30.14)(0.49,-0.05){1}{\line(1,0){0.49}} \multiput(52.77,30.09)(0.5,-0.04){1}{\line(1,0){0.5}}
\multiput(53.27,30.05)(0.5,-0.03){1}{\line(1,0){0.5}} \multiput(53.76,30.02)(0.5,-0.02){1}{\line(1,0){0.5}}
\multiput(54.26,30)(0.5,-0.01){1}{\line(1,0){0.5}} \put(54.76,29.99){\line(1,0){0.5}}
\multiput(55.25,29.99)(0.5,0.01){1}{\line(1,0){0.5}} \multiput(55.75,30)(0.5,0.02){1}{\line(1,0){0.5}}
\multiput(56.25,30.02)(0.5,0.03){1}{\line(1,0){0.5}} \multiput(56.74,30.05)(0.5,0.04){1}{\line(1,0){0.5}}
\multiput(57.24,30.09)(0.49,0.05){1}{\line(1,0){0.49}} \multiput(57.73,30.14)(0.49,0.06){1}{\line(1,0){0.49}}
\multiput(58.23,30.2)(0.49,0.07){1}{\line(1,0){0.49}} \multiput(58.72,30.27)(0.49,0.08){1}{\line(1,0){0.49}}
\multiput(59.21,30.35)(0.49,0.09){1}{\line(1,0){0.49}} \multiput(59.7,30.43)(0.49,0.1){1}{\line(1,0){0.49}}
\multiput(60.19,30.53)(0.49,0.11){1}{\line(1,0){0.49}} \multiput(60.67,30.64)(0.48,0.12){1}{\line(1,0){0.48}}
\multiput(61.16,30.76)(0.48,0.13){1}{\line(1,0){0.48}} \multiput(61.64,30.88)(0.48,0.14){1}{\line(1,0){0.48}}
\multiput(62.11,31.02)(0.48,0.15){1}{\line(1,0){0.48}} \multiput(62.59,31.17)(0.47,0.16){1}{\line(1,0){0.47}}
\multiput(63.06,31.32)(0.47,0.16){1}{\line(1,0){0.47}} \multiput(63.53,31.49)(0.47,0.17){1}{\line(1,0){0.47}}
\multiput(64,31.66)(0.23,0.09){2}{\line(1,0){0.23}} \multiput(64.46,31.85)(0.23,0.1){2}{\line(1,0){0.23}}
\multiput(64.92,32.04)(0.23,0.1){2}{\line(1,0){0.23}} \multiput(65.37,32.24)(0.23,0.11){2}{\line(1,0){0.23}}
\multiput(65.82,32.45)(0.22,0.11){2}{\line(1,0){0.22}} \multiput(66.27,32.67)(0.22,0.11){2}{\line(1,0){0.22}}
\multiput(66.71,32.9)(0.22,0.12){2}{\line(1,0){0.22}} \multiput(67.15,33.14)(0.22,0.12){2}{\line(1,0){0.22}}
\multiput(67.58,33.38)(0.21,0.13){2}{\line(1,0){0.21}} \multiput(68.01,33.64)(0.21,0.13){2}{\line(1,0){0.21}}
\multiput(68.43,33.9)(0.21,0.14){2}{\line(1,0){0.21}} \multiput(68.84,34.17)(0.21,0.14){2}{\line(1,0){0.21}}
\multiput(69.26,34.45)(0.2,0.14){2}{\line(1,0){0.2}} \multiput(69.66,34.74)(0.2,0.15){2}{\line(1,0){0.2}}
\multiput(70.06,35.03)(0.13,0.1){3}{\line(1,0){0.13}} \multiput(70.46,35.33)(0.13,0.1){3}{\line(1,0){0.13}}
\multiput(70.84,35.65)(0.13,0.11){3}{\line(1,0){0.13}} \multiput(71.23,35.96)(0.13,0.11){3}{\line(1,0){0.13}}
\multiput(71.6,36.29)(0.12,0.11){3}{\line(1,0){0.12}} \multiput(71.97,36.62)(0.12,0.11){3}{\line(1,0){0.12}}
\multiput(72.33,36.97)(0.12,0.12){3}{\line(1,0){0.12}} \multiput(72.69,37.31)(0.12,0.12){3}{\line(0,1){0.12}}
\multiput(73.03,37.67)(0.11,0.12){3}{\line(0,1){0.12}} \multiput(73.37,38.03)(0.11,0.12){3}{\line(0,1){0.12}}
\multiput(73.71,38.4)(0.11,0.13){3}{\line(0,1){0.13}} \multiput(74.03,38.77)(0.11,0.13){3}{\line(0,1){0.13}}
\multiput(74.35,39.16)(0.1,0.13){3}{\line(0,1){0.13}} \multiput(74.66,39.54)(0.1,0.13){3}{\line(0,1){0.13}}
\multiput(74.97,39.94)(0.15,0.2){2}{\line(0,1){0.2}} \multiput(75.26,40.34)(0.14,0.2){2}{\line(0,1){0.2}}
\multiput(75.55,40.74)(0.14,0.21){2}{\line(0,1){0.21}} \multiput(75.83,41.15)(0.14,0.21){2}{\line(0,1){0.21}}
\multiput(76.1,41.57)(0.13,0.21){2}{\line(0,1){0.21}} \multiput(76.36,41.99)(0.13,0.21){2}{\line(0,1){0.21}}
\multiput(76.62,42.42)(0.12,0.22){2}{\line(0,1){0.22}} \multiput(76.86,42.85)(0.12,0.22){2}{\line(0,1){0.22}}
\multiput(77.1,43.29)(0.11,0.22){2}{\line(0,1){0.22}} \multiput(77.33,43.73)(0.11,0.22){2}{\line(0,1){0.22}}
\multiput(77.55,44.18)(0.11,0.23){2}{\line(0,1){0.23}} \multiput(77.76,44.63)(0.1,0.23){2}{\line(0,1){0.23}}
\multiput(77.96,45.08)(0.1,0.23){2}{\line(0,1){0.23}} \multiput(78.15,45.54)(0.09,0.23){2}{\line(0,1){0.23}}
\multiput(78.34,46)(0.17,0.47){1}{\line(0,1){0.47}} \multiput(78.51,46.47)(0.16,0.47){1}{\line(0,1){0.47}}
\multiput(78.68,46.94)(0.16,0.47){1}{\line(0,1){0.47}} \multiput(78.83,47.41)(0.15,0.48){1}{\line(0,1){0.48}}
\multiput(78.98,47.89)(0.14,0.48){1}{\line(0,1){0.48}} \multiput(79.11,48.36)(0.13,0.48){1}{\line(0,1){0.48}}
\multiput(79.24,48.84)(0.12,0.48){1}{\line(0,1){0.48}} \multiput(79.36,49.33)(0.11,0.49){1}{\line(0,1){0.49}}
\multiput(79.47,49.81)(0.1,0.49){1}{\line(0,1){0.49}} \multiput(79.57,50.3)(0.09,0.49){1}{\line(0,1){0.49}}
\multiput(79.65,50.79)(0.08,0.49){1}{\line(0,1){0.49}} \multiput(79.73,51.28)(0.07,0.49){1}{\line(0,1){0.49}}
\multiput(79.8,51.77)(0.06,0.49){1}{\line(0,1){0.49}} \multiput(79.86,52.27)(0.05,0.49){1}{\line(0,1){0.49}}
\multiput(79.91,52.76)(0.04,0.5){1}{\line(0,1){0.5}} \multiput(79.95,53.26)(0.03,0.5){1}{\line(0,1){0.5}}
\multiput(79.98,53.75)(0.02,0.5){1}{\line(0,1){0.5}} \multiput(80,54.25)(0.01,0.5){1}{\line(0,1){0.5}}

\linethickness{0.3mm} \put(120,54.75){\line(0,1){0.5}} \multiput(119.99,55.75)(0.01,-0.5){1}{\line(0,-1){0.5}}
\multiput(119.97,56.24)(0.02,-0.5){1}{\line(0,-1){0.5}} \multiput(119.94,56.74)(0.03,-0.5){1}{\line(0,-1){0.5}}
\multiput(119.9,57.23)(0.04,-0.5){1}{\line(0,-1){0.5}} \multiput(119.85,57.73)(0.05,-0.49){1}{\line(0,-1){0.49}}
\multiput(119.79,58.22)(0.06,-0.49){1}{\line(0,-1){0.49}}
\multiput(119.72,58.71)(0.07,-0.49){1}{\line(0,-1){0.49}}
\multiput(119.64,59.21)(0.08,-0.49){1}{\line(0,-1){0.49}}
\multiput(119.56,59.69)(0.09,-0.49){1}{\line(0,-1){0.49}}
\multiput(119.46,60.18)(0.1,-0.49){1}{\line(0,-1){0.49}} \multiput(119.35,60.67)(0.11,-0.49){1}{\line(0,-1){0.49}}
\multiput(119.23,61.15)(0.12,-0.48){1}{\line(0,-1){0.48}}
\multiput(119.1,61.63)(0.13,-0.48){1}{\line(0,-1){0.48}} \multiput(118.97,62.11)(0.14,-0.48){1}{\line(0,-1){0.48}}
\multiput(118.82,62.58)(0.15,-0.48){1}{\line(0,-1){0.48}}
\multiput(118.67,63.06)(0.16,-0.47){1}{\line(0,-1){0.47}}
\multiput(118.5,63.52)(0.16,-0.47){1}{\line(0,-1){0.47}} \multiput(118.33,63.99)(0.17,-0.47){1}{\line(0,-1){0.47}}
\multiput(118.14,64.45)(0.09,-0.23){2}{\line(0,-1){0.23}}
\multiput(117.95,64.91)(0.1,-0.23){2}{\line(0,-1){0.23}} \multiput(117.75,65.36)(0.1,-0.23){2}{\line(0,-1){0.23}}
\multiput(117.54,65.82)(0.11,-0.23){2}{\line(0,-1){0.23}}
\multiput(117.32,66.26)(0.11,-0.22){2}{\line(0,-1){0.22}}
\multiput(117.09,66.7)(0.11,-0.22){2}{\line(0,-1){0.22}} \multiput(116.85,67.14)(0.12,-0.22){2}{\line(0,-1){0.22}}
\multiput(116.61,67.57)(0.12,-0.22){2}{\line(0,-1){0.22}}
\multiput(116.35,68)(0.13,-0.21){2}{\line(0,-1){0.21}} \multiput(116.09,68.42)(0.13,-0.21){2}{\line(0,-1){0.21}}
\multiput(115.82,68.84)(0.14,-0.21){2}{\line(0,-1){0.21}}
\multiput(115.54,69.25)(0.14,-0.21){2}{\line(0,-1){0.21}}
\multiput(115.25,69.65)(0.14,-0.2){2}{\line(0,-1){0.2}} \multiput(114.96,70.05)(0.15,-0.2){2}{\line(0,-1){0.2}}
\multiput(114.66,70.45)(0.1,-0.13){3}{\line(0,-1){0.13}} \multiput(114.34,70.84)(0.1,-0.13){3}{\line(0,-1){0.13}}
\multiput(114.03,71.22)(0.11,-0.13){3}{\line(0,-1){0.13}}
\multiput(113.7,71.59)(0.11,-0.13){3}{\line(0,-1){0.13}} \multiput(113.37,71.96)(0.11,-0.12){3}{\line(0,-1){0.12}}
\multiput(113.03,72.32)(0.11,-0.12){3}{\line(0,-1){0.12}}
\multiput(112.68,72.68)(0.12,-0.12){3}{\line(0,-1){0.12}}
\multiput(112.32,73.03)(0.12,-0.12){3}{\line(1,0){0.12}} \multiput(111.96,73.37)(0.12,-0.11){3}{\line(1,0){0.12}}
\multiput(111.59,73.7)(0.12,-0.11){3}{\line(1,0){0.12}} \multiput(111.22,74.03)(0.13,-0.11){3}{\line(1,0){0.13}}
\multiput(110.84,74.34)(0.13,-0.11){3}{\line(1,0){0.13}} \multiput(110.45,74.66)(0.13,-0.1){3}{\line(1,0){0.13}}
\multiput(110.05,74.96)(0.13,-0.1){3}{\line(1,0){0.13}} \multiput(109.65,75.25)(0.2,-0.15){2}{\line(1,0){0.2}}
\multiput(109.25,75.54)(0.2,-0.14){2}{\line(1,0){0.2}} \multiput(108.84,75.82)(0.21,-0.14){2}{\line(1,0){0.21}}
\multiput(108.42,76.09)(0.21,-0.14){2}{\line(1,0){0.21}} \multiput(108,76.35)(0.21,-0.13){2}{\line(1,0){0.21}}
\multiput(107.57,76.61)(0.21,-0.13){2}{\line(1,0){0.21}} \multiput(107.14,76.85)(0.22,-0.12){2}{\line(1,0){0.22}}
\multiput(106.7,77.09)(0.22,-0.12){2}{\line(1,0){0.22}} \multiput(106.26,77.32)(0.22,-0.11){2}{\line(1,0){0.22}}
\multiput(105.82,77.54)(0.22,-0.11){2}{\line(1,0){0.22}} \multiput(105.36,77.75)(0.23,-0.11){2}{\line(1,0){0.23}}
\multiput(104.91,77.95)(0.23,-0.1){2}{\line(1,0){0.23}} \multiput(104.45,78.14)(0.23,-0.1){2}{\line(1,0){0.23}}
\multiput(103.99,78.33)(0.23,-0.09){2}{\line(1,0){0.23}} \multiput(103.52,78.5)(0.47,-0.17){1}{\line(1,0){0.47}}
\multiput(103.06,78.67)(0.47,-0.16){1}{\line(1,0){0.47}} \multiput(102.58,78.82)(0.47,-0.16){1}{\line(1,0){0.47}}
\multiput(102.11,78.97)(0.48,-0.15){1}{\line(1,0){0.48}} \multiput(101.63,79.1)(0.48,-0.14){1}{\line(1,0){0.48}}
\multiput(101.15,79.23)(0.48,-0.13){1}{\line(1,0){0.48}} \multiput(100.67,79.35)(0.48,-0.12){1}{\line(1,0){0.48}}
\multiput(100.18,79.46)(0.49,-0.11){1}{\line(1,0){0.49}} \multiput(99.69,79.56)(0.49,-0.1){1}{\line(1,0){0.49}}
\multiput(99.21,79.64)(0.49,-0.09){1}{\line(1,0){0.49}} \multiput(98.71,79.72)(0.49,-0.08){1}{\line(1,0){0.49}}
\multiput(98.22,79.79)(0.49,-0.07){1}{\line(1,0){0.49}} \multiput(97.73,79.85)(0.49,-0.06){1}{\line(1,0){0.49}}
\multiput(97.23,79.9)(0.49,-0.05){1}{\line(1,0){0.49}} \multiput(96.74,79.94)(0.5,-0.04){1}{\line(1,0){0.5}}
\multiput(96.24,79.97)(0.5,-0.03){1}{\line(1,0){0.5}} \multiput(95.75,79.99)(0.5,-0.02){1}{\line(1,0){0.5}}
\multiput(95.25,80)(0.5,-0.01){1}{\line(1,0){0.5}} \put(94.75,80){\line(1,0){0.5}}
\multiput(94.25,79.99)(0.5,0.01){1}{\line(1,0){0.5}} \multiput(93.76,79.97)(0.5,0.02){1}{\line(1,0){0.5}}
\multiput(93.26,79.94)(0.5,0.03){1}{\line(1,0){0.5}} \multiput(92.77,79.9)(0.5,0.04){1}{\line(1,0){0.5}}
\multiput(92.27,79.85)(0.49,0.05){1}{\line(1,0){0.49}} \multiput(91.78,79.79)(0.49,0.06){1}{\line(1,0){0.49}}
\multiput(91.29,79.72)(0.49,0.07){1}{\line(1,0){0.49}} \multiput(90.79,79.64)(0.49,0.08){1}{\line(1,0){0.49}}
\multiput(90.31,79.56)(0.49,0.09){1}{\line(1,0){0.49}} \multiput(89.82,79.46)(0.49,0.1){1}{\line(1,0){0.49}}
\multiput(89.33,79.35)(0.49,0.11){1}{\line(1,0){0.49}} \multiput(88.85,79.23)(0.48,0.12){1}{\line(1,0){0.48}}
\multiput(88.37,79.1)(0.48,0.13){1}{\line(1,0){0.48}} \multiput(87.89,78.97)(0.48,0.14){1}{\line(1,0){0.48}}
\multiput(87.42,78.82)(0.48,0.15){1}{\line(1,0){0.48}} \multiput(86.94,78.67)(0.47,0.16){1}{\line(1,0){0.47}}
\multiput(86.48,78.5)(0.47,0.16){1}{\line(1,0){0.47}} \multiput(86.01,78.33)(0.47,0.17){1}{\line(1,0){0.47}}
\multiput(85.55,78.14)(0.23,0.09){2}{\line(1,0){0.23}} \multiput(85.09,77.95)(0.23,0.1){2}{\line(1,0){0.23}}
\multiput(84.64,77.75)(0.23,0.1){2}{\line(1,0){0.23}} \multiput(84.18,77.54)(0.23,0.11){2}{\line(1,0){0.23}}
\multiput(83.74,77.32)(0.22,0.11){2}{\line(1,0){0.22}} \multiput(83.3,77.09)(0.22,0.11){2}{\line(1,0){0.22}}
\multiput(82.86,76.85)(0.22,0.12){2}{\line(1,0){0.22}} \multiput(82.43,76.61)(0.22,0.12){2}{\line(1,0){0.22}}
\multiput(82,76.35)(0.21,0.13){2}{\line(1,0){0.21}} \multiput(81.58,76.09)(0.21,0.13){2}{\line(1,0){0.21}}
\multiput(81.16,75.82)(0.21,0.14){2}{\line(1,0){0.21}} \multiput(80.75,75.54)(0.21,0.14){2}{\line(1,0){0.21}}
\multiput(80.35,75.25)(0.2,0.14){2}{\line(1,0){0.2}} \multiput(79.95,74.96)(0.2,0.15){2}{\line(1,0){0.2}}
\multiput(79.55,74.66)(0.13,0.1){3}{\line(1,0){0.13}} \multiput(79.16,74.34)(0.13,0.1){3}{\line(1,0){0.13}}
\multiput(78.78,74.03)(0.13,0.11){3}{\line(1,0){0.13}} \multiput(78.41,73.7)(0.13,0.11){3}{\line(1,0){0.13}}
\multiput(78.04,73.37)(0.12,0.11){3}{\line(1,0){0.12}} \multiput(77.68,73.03)(0.12,0.11){3}{\line(1,0){0.12}}
\multiput(77.32,72.68)(0.12,0.12){3}{\line(1,0){0.12}} \multiput(76.97,72.32)(0.12,0.12){3}{\line(0,1){0.12}}
\multiput(76.63,71.96)(0.11,0.12){3}{\line(0,1){0.12}} \multiput(76.3,71.59)(0.11,0.12){3}{\line(0,1){0.12}}
\multiput(75.97,71.22)(0.11,0.13){3}{\line(0,1){0.13}} \multiput(75.66,70.84)(0.11,0.13){3}{\line(0,1){0.13}}
\multiput(75.34,70.45)(0.1,0.13){3}{\line(0,1){0.13}} \multiput(75.04,70.05)(0.1,0.13){3}{\line(0,1){0.13}}
\multiput(74.75,69.65)(0.15,0.2){2}{\line(0,1){0.2}} \multiput(74.46,69.25)(0.14,0.2){2}{\line(0,1){0.2}}
\multiput(74.18,68.84)(0.14,0.21){2}{\line(0,1){0.21}} \multiput(73.91,68.42)(0.14,0.21){2}{\line(0,1){0.21}}
\multiput(73.65,68)(0.13,0.21){2}{\line(0,1){0.21}} \multiput(73.39,67.57)(0.13,0.21){2}{\line(0,1){0.21}}
\multiput(73.15,67.14)(0.12,0.22){2}{\line(0,1){0.22}} \multiput(72.91,66.7)(0.12,0.22){2}{\line(0,1){0.22}}
\multiput(72.68,66.26)(0.11,0.22){2}{\line(0,1){0.22}} \multiput(72.46,65.82)(0.11,0.22){2}{\line(0,1){0.22}}
\multiput(72.25,65.36)(0.11,0.23){2}{\line(0,1){0.23}} \multiput(72.05,64.91)(0.1,0.23){2}{\line(0,1){0.23}}
\multiput(71.86,64.45)(0.1,0.23){2}{\line(0,1){0.23}} \multiput(71.67,63.99)(0.09,0.23){2}{\line(0,1){0.23}}
\multiput(71.5,63.52)(0.17,0.47){1}{\line(0,1){0.47}} \multiput(71.33,63.06)(0.16,0.47){1}{\line(0,1){0.47}}
\multiput(71.18,62.58)(0.16,0.47){1}{\line(0,1){0.47}} \multiput(71.03,62.11)(0.15,0.48){1}{\line(0,1){0.48}}
\multiput(70.9,61.63)(0.14,0.48){1}{\line(0,1){0.48}} \multiput(70.77,61.15)(0.13,0.48){1}{\line(0,1){0.48}}
\multiput(70.65,60.67)(0.12,0.48){1}{\line(0,1){0.48}} \multiput(70.54,60.18)(0.11,0.49){1}{\line(0,1){0.49}}
\multiput(70.44,59.69)(0.1,0.49){1}{\line(0,1){0.49}} \multiput(70.36,59.21)(0.09,0.49){1}{\line(0,1){0.49}}
\multiput(70.28,58.71)(0.08,0.49){1}{\line(0,1){0.49}} \multiput(70.21,58.22)(0.07,0.49){1}{\line(0,1){0.49}}
\multiput(70.15,57.73)(0.06,0.49){1}{\line(0,1){0.49}} \multiput(70.1,57.23)(0.05,0.49){1}{\line(0,1){0.49}}
\multiput(70.06,56.74)(0.04,0.5){1}{\line(0,1){0.5}} \multiput(70.03,56.24)(0.03,0.5){1}{\line(0,1){0.5}}
\multiput(70.01,55.75)(0.02,0.5){1}{\line(0,1){0.5}} \multiput(70,55.25)(0.01,0.5){1}{\line(0,1){0.5}}
\put(70,54.75){\line(0,1){0.5}} \multiput(70,54.75)(0.01,-0.5){1}{\line(0,-1){0.5}}
\multiput(70.01,54.25)(0.02,-0.5){1}{\line(0,-1){0.5}} \multiput(70.03,53.76)(0.03,-0.5){1}{\line(0,-1){0.5}}
\multiput(70.06,53.26)(0.04,-0.5){1}{\line(0,-1){0.5}} \multiput(70.1,52.77)(0.05,-0.49){1}{\line(0,-1){0.49}}
\multiput(70.15,52.27)(0.06,-0.49){1}{\line(0,-1){0.49}} \multiput(70.21,51.78)(0.07,-0.49){1}{\line(0,-1){0.49}}
\multiput(70.28,51.29)(0.08,-0.49){1}{\line(0,-1){0.49}} \multiput(70.36,50.79)(0.09,-0.49){1}{\line(0,-1){0.49}}
\multiput(70.44,50.31)(0.1,-0.49){1}{\line(0,-1){0.49}} \multiput(70.54,49.82)(0.11,-0.49){1}{\line(0,-1){0.49}}
\multiput(70.65,49.33)(0.12,-0.48){1}{\line(0,-1){0.48}} \multiput(70.77,48.85)(0.13,-0.48){1}{\line(0,-1){0.48}}
\multiput(70.9,48.37)(0.14,-0.48){1}{\line(0,-1){0.48}} \multiput(71.03,47.89)(0.15,-0.48){1}{\line(0,-1){0.48}}
\multiput(71.18,47.42)(0.16,-0.47){1}{\line(0,-1){0.47}} \multiput(71.33,46.94)(0.16,-0.47){1}{\line(0,-1){0.47}}
\multiput(71.5,46.48)(0.17,-0.47){1}{\line(0,-1){0.47}} \multiput(71.67,46.01)(0.09,-0.23){2}{\line(0,-1){0.23}}
\multiput(71.86,45.55)(0.1,-0.23){2}{\line(0,-1){0.23}} \multiput(72.05,45.09)(0.1,-0.23){2}{\line(0,-1){0.23}}
\multiput(72.25,44.64)(0.11,-0.23){2}{\line(0,-1){0.23}} \multiput(72.46,44.18)(0.11,-0.22){2}{\line(0,-1){0.22}}
\multiput(72.68,43.74)(0.11,-0.22){2}{\line(0,-1){0.22}} \multiput(72.91,43.3)(0.12,-0.22){2}{\line(0,-1){0.22}}
\multiput(73.15,42.86)(0.12,-0.22){2}{\line(0,-1){0.22}} \multiput(73.39,42.43)(0.13,-0.21){2}{\line(0,-1){0.21}}
\multiput(73.65,42)(0.13,-0.21){2}{\line(0,-1){0.21}} \multiput(73.91,41.58)(0.14,-0.21){2}{\line(0,-1){0.21}}
\multiput(74.18,41.16)(0.14,-0.21){2}{\line(0,-1){0.21}} \multiput(74.46,40.75)(0.14,-0.2){2}{\line(0,-1){0.2}}
\multiput(74.75,40.35)(0.15,-0.2){2}{\line(0,-1){0.2}} \multiput(75.04,39.95)(0.1,-0.13){3}{\line(0,-1){0.13}}
\multiput(75.34,39.55)(0.1,-0.13){3}{\line(0,-1){0.13}} \multiput(75.66,39.16)(0.11,-0.13){3}{\line(0,-1){0.13}}
\multiput(75.97,38.78)(0.11,-0.13){3}{\line(0,-1){0.13}} \multiput(76.3,38.41)(0.11,-0.12){3}{\line(0,-1){0.12}}
\multiput(76.63,38.04)(0.11,-0.12){3}{\line(0,-1){0.12}} \multiput(76.97,37.68)(0.12,-0.12){3}{\line(0,-1){0.12}}
\multiput(77.32,37.32)(0.12,-0.12){3}{\line(1,0){0.12}} \multiput(77.68,36.97)(0.12,-0.11){3}{\line(1,0){0.12}}
\multiput(78.04,36.63)(0.12,-0.11){3}{\line(1,0){0.12}} \multiput(78.41,36.3)(0.13,-0.11){3}{\line(1,0){0.13}}
\multiput(78.78,35.97)(0.13,-0.11){3}{\line(1,0){0.13}} \multiput(79.16,35.66)(0.13,-0.1){3}{\line(1,0){0.13}}
\multiput(79.55,35.34)(0.13,-0.1){3}{\line(1,0){0.13}} \multiput(79.95,35.04)(0.2,-0.15){2}{\line(1,0){0.2}}
\multiput(80.35,34.75)(0.2,-0.14){2}{\line(1,0){0.2}} \multiput(80.75,34.46)(0.21,-0.14){2}{\line(1,0){0.21}}
\multiput(81.16,34.18)(0.21,-0.14){2}{\line(1,0){0.21}} \multiput(81.58,33.91)(0.21,-0.13){2}{\line(1,0){0.21}}
\multiput(82,33.65)(0.21,-0.13){2}{\line(1,0){0.21}} \multiput(82.43,33.39)(0.22,-0.12){2}{\line(1,0){0.22}}
\multiput(82.86,33.15)(0.22,-0.12){2}{\line(1,0){0.22}} \multiput(83.3,32.91)(0.22,-0.11){2}{\line(1,0){0.22}}
\multiput(83.74,32.68)(0.22,-0.11){2}{\line(1,0){0.22}} \multiput(84.18,32.46)(0.23,-0.11){2}{\line(1,0){0.23}}
\multiput(84.64,32.25)(0.23,-0.1){2}{\line(1,0){0.23}} \multiput(85.09,32.05)(0.23,-0.1){2}{\line(1,0){0.23}}
\multiput(85.55,31.86)(0.23,-0.09){2}{\line(1,0){0.23}} \multiput(86.01,31.67)(0.47,-0.17){1}{\line(1,0){0.47}}
\multiput(86.48,31.5)(0.47,-0.16){1}{\line(1,0){0.47}} \multiput(86.94,31.33)(0.47,-0.16){1}{\line(1,0){0.47}}
\multiput(87.42,31.18)(0.48,-0.15){1}{\line(1,0){0.48}} \multiput(87.89,31.03)(0.48,-0.14){1}{\line(1,0){0.48}}
\multiput(88.37,30.9)(0.48,-0.13){1}{\line(1,0){0.48}} \multiput(88.85,30.77)(0.48,-0.12){1}{\line(1,0){0.48}}
\multiput(89.33,30.65)(0.49,-0.11){1}{\line(1,0){0.49}} \multiput(89.82,30.54)(0.49,-0.1){1}{\line(1,0){0.49}}
\multiput(90.31,30.44)(0.49,-0.09){1}{\line(1,0){0.49}} \multiput(90.79,30.36)(0.49,-0.08){1}{\line(1,0){0.49}}
\multiput(91.29,30.28)(0.49,-0.07){1}{\line(1,0){0.49}} \multiput(91.78,30.21)(0.49,-0.06){1}{\line(1,0){0.49}}
\multiput(92.27,30.15)(0.49,-0.05){1}{\line(1,0){0.49}} \multiput(92.77,30.1)(0.5,-0.04){1}{\line(1,0){0.5}}
\multiput(93.26,30.06)(0.5,-0.03){1}{\line(1,0){0.5}} \multiput(93.76,30.03)(0.5,-0.02){1}{\line(1,0){0.5}}
\multiput(94.25,30.01)(0.5,-0.01){1}{\line(1,0){0.5}} \put(94.75,30){\line(1,0){0.5}}
\multiput(95.25,30)(0.5,0.01){1}{\line(1,0){0.5}} \multiput(95.75,30.01)(0.5,0.02){1}{\line(1,0){0.5}}
\multiput(96.24,30.03)(0.5,0.03){1}{\line(1,0){0.5}} \multiput(96.74,30.06)(0.5,0.04){1}{\line(1,0){0.5}}
\multiput(97.23,30.1)(0.49,0.05){1}{\line(1,0){0.49}} \multiput(97.73,30.15)(0.49,0.06){1}{\line(1,0){0.49}}
\multiput(98.22,30.21)(0.49,0.07){1}{\line(1,0){0.49}} \multiput(98.71,30.28)(0.49,0.08){1}{\line(1,0){0.49}}
\multiput(99.21,30.36)(0.49,0.09){1}{\line(1,0){0.49}} \multiput(99.69,30.44)(0.49,0.1){1}{\line(1,0){0.49}}
\multiput(100.18,30.54)(0.49,0.11){1}{\line(1,0){0.49}} \multiput(100.67,30.65)(0.48,0.12){1}{\line(1,0){0.48}}
\multiput(101.15,30.77)(0.48,0.13){1}{\line(1,0){0.48}} \multiput(101.63,30.9)(0.48,0.14){1}{\line(1,0){0.48}}
\multiput(102.11,31.03)(0.48,0.15){1}{\line(1,0){0.48}} \multiput(102.58,31.18)(0.47,0.16){1}{\line(1,0){0.47}}
\multiput(103.06,31.33)(0.47,0.16){1}{\line(1,0){0.47}} \multiput(103.52,31.5)(0.47,0.17){1}{\line(1,0){0.47}}
\multiput(103.99,31.67)(0.23,0.09){2}{\line(1,0){0.23}} \multiput(104.45,31.86)(0.23,0.1){2}{\line(1,0){0.23}}
\multiput(104.91,32.05)(0.23,0.1){2}{\line(1,0){0.23}} \multiput(105.36,32.25)(0.23,0.11){2}{\line(1,0){0.23}}
\multiput(105.82,32.46)(0.22,0.11){2}{\line(1,0){0.22}} \multiput(106.26,32.68)(0.22,0.11){2}{\line(1,0){0.22}}
\multiput(106.7,32.91)(0.22,0.12){2}{\line(1,0){0.22}} \multiput(107.14,33.15)(0.22,0.12){2}{\line(1,0){0.22}}
\multiput(107.57,33.39)(0.21,0.13){2}{\line(1,0){0.21}} \multiput(108,33.65)(0.21,0.13){2}{\line(1,0){0.21}}
\multiput(108.42,33.91)(0.21,0.14){2}{\line(1,0){0.21}} \multiput(108.84,34.18)(0.21,0.14){2}{\line(1,0){0.21}}
\multiput(109.25,34.46)(0.2,0.14){2}{\line(1,0){0.2}} \multiput(109.65,34.75)(0.2,0.15){2}{\line(1,0){0.2}}
\multiput(110.05,35.04)(0.13,0.1){3}{\line(1,0){0.13}} \multiput(110.45,35.34)(0.13,0.1){3}{\line(1,0){0.13}}
\multiput(110.84,35.66)(0.13,0.11){3}{\line(1,0){0.13}} \multiput(111.22,35.97)(0.13,0.11){3}{\line(1,0){0.13}}
\multiput(111.59,36.3)(0.12,0.11){3}{\line(1,0){0.12}} \multiput(111.96,36.63)(0.12,0.11){3}{\line(1,0){0.12}}
\multiput(112.32,36.97)(0.12,0.12){3}{\line(1,0){0.12}} \multiput(112.68,37.32)(0.12,0.12){3}{\line(0,1){0.12}}
\multiput(113.03,37.68)(0.11,0.12){3}{\line(0,1){0.12}} \multiput(113.37,38.04)(0.11,0.12){3}{\line(0,1){0.12}}
\multiput(113.7,38.41)(0.11,0.13){3}{\line(0,1){0.13}} \multiput(114.03,38.78)(0.11,0.13){3}{\line(0,1){0.13}}
\multiput(114.34,39.16)(0.1,0.13){3}{\line(0,1){0.13}} \multiput(114.66,39.55)(0.1,0.13){3}{\line(0,1){0.13}}
\multiput(114.96,39.95)(0.15,0.2){2}{\line(0,1){0.2}} \multiput(115.25,40.35)(0.14,0.2){2}{\line(0,1){0.2}}
\multiput(115.54,40.75)(0.14,0.21){2}{\line(0,1){0.21}} \multiput(115.82,41.16)(0.14,0.21){2}{\line(0,1){0.21}}
\multiput(116.09,41.58)(0.13,0.21){2}{\line(0,1){0.21}} \multiput(116.35,42)(0.13,0.21){2}{\line(0,1){0.21}}
\multiput(116.61,42.43)(0.12,0.22){2}{\line(0,1){0.22}} \multiput(116.85,42.86)(0.12,0.22){2}{\line(0,1){0.22}}
\multiput(117.09,43.3)(0.11,0.22){2}{\line(0,1){0.22}} \multiput(117.32,43.74)(0.11,0.22){2}{\line(0,1){0.22}}
\multiput(117.54,44.18)(0.11,0.23){2}{\line(0,1){0.23}} \multiput(117.75,44.64)(0.1,0.23){2}{\line(0,1){0.23}}
\multiput(117.95,45.09)(0.1,0.23){2}{\line(0,1){0.23}} \multiput(118.14,45.55)(0.09,0.23){2}{\line(0,1){0.23}}
\multiput(118.33,46.01)(0.17,0.47){1}{\line(0,1){0.47}} \multiput(118.5,46.48)(0.16,0.47){1}{\line(0,1){0.47}}
\multiput(118.67,46.94)(0.16,0.47){1}{\line(0,1){0.47}} \multiput(118.82,47.42)(0.15,0.48){1}{\line(0,1){0.48}}
\multiput(118.97,47.89)(0.14,0.48){1}{\line(0,1){0.48}} \multiput(119.1,48.37)(0.13,0.48){1}{\line(0,1){0.48}}
\multiput(119.23,48.85)(0.12,0.48){1}{\line(0,1){0.48}} \multiput(119.35,49.33)(0.11,0.49){1}{\line(0,1){0.49}}
\multiput(119.46,49.82)(0.1,0.49){1}{\line(0,1){0.49}} \multiput(119.56,50.31)(0.09,0.49){1}{\line(0,1){0.49}}
\multiput(119.64,50.79)(0.08,0.49){1}{\line(0,1){0.49}} \multiput(119.72,51.29)(0.07,0.49){1}{\line(0,1){0.49}}
\multiput(119.79,51.78)(0.06,0.49){1}{\line(0,1){0.49}} \multiput(119.85,52.27)(0.05,0.49){1}{\line(0,1){0.49}}
\multiput(119.9,52.77)(0.04,0.5){1}{\line(0,1){0.5}} \multiput(119.94,53.26)(0.03,0.5){1}{\line(0,1){0.5}}
\multiput(119.97,53.76)(0.02,0.5){1}{\line(0,1){0.5}} \multiput(119.99,54.25)(0.01,0.5){1}{\line(0,1){0.5}}

\put(110,10){\makebox(0,0)[cc]{}}

\put(30,70){\makebox(0,0)[cc]{$R^{*}$}}

\put(60,70){\makebox(0,0)[cc]{}}

\put(35,35){\makebox(0,0)[cc]{}}

\put(50,15){\makebox(0,0)[cc]{}}

\put(120,70){\makebox(0,0)[cc]{R}}

\put(40,40){\makebox(0,0)[cc]{A}}

\put(75,55){\makebox(0,0)[cc]{B}}

\put(110,40){\makebox(0,0)[cc]{C}}

\put(135,10){\makebox(0,0)[cc]{}}

\end{picture}

\noindent Indichiamo con $R^{\ast}$ e $R$ l'insieme dei gioielli
e delle pietre preziose selezionati utilizzando rispettivamente la
strategia di selezione $S^{\ast}$ ed una qualsiasi altra strategia
$S$ tale per cui il $P_{s}(R)=5$ kg. I prezzi di mercato dei raccolti
$R^{\ast}$ ed $R$, indicati rispettivamente con $P_{r}(R^{\ast})$
e $P_{r}(R)$ sono calcolabili semplicemente come la somma del prezzo
di ogni singolo gioiello in essi contenuti, ovvero\[
P_{r}(R^{\ast})=\sum\limits _{g\in R^{\ast}}p_{r}(g)=\sum\limits _{g\in A}p_{r}(g)+\sum\limits _{g\in B}p_{r}(g)\]
 e\[
P_{r}(R)=\sum\limits _{g\in R}p_{r}(g)=\sum\limits _{g\in B}p_{r}(g)+\sum\limits _{g\in C}p_{r}(g).\]
 Vogliamo ora dimostrare che \[
P_{r}(R^{\ast})>P_{r}(R).\]
 A tal fine consideriamo la differenza \begin{equation}
P_{r}(R^{\ast})-P_{r}(R)=\sum\limits _{g\in A}p_{r}(g)-\sum\limits _{g\in C}p_{r}(g).\end{equation}
 Poiché la strategia $S^{\ast}$ prevede di includere $g$ in $R^{\ast}$
se e solo se $\frac{p_{r}(g)}{p_{s}(g)}>k_{\alpha}^{\ast}$, per ogni
$x\in R^{\ast}$ (e quindi anche per ogni $g\in A\subset R^{\ast}$)
sarà vero che $p_{r}(g)>p_{s}(g)k_{\alpha}^{\ast}$. Di conseguenza
varrà la seguente disuguaglianza \[
P_{r}(R^{\ast})-P_{r}(R)>k_{\alpha}^{\ast}\sum\limits _{g\in A}p_{s}(g)-\sum\limits _{g\in C}p_{r}(g).\]
 D'altra parte, visto che l'insieme $C$ è disgiunto da $R^{\ast}$,
per qualsiasi $g\in C$ deve valere che $\frac{p_{r}(g)}{p_{s}(g)}\leq k_{\alpha}^{\ast}$,
ovvero $p_{r}(g)\leq p_{s}(g)k_{\alpha}^{\ast}$ e di conseguenza\begin{eqnarray*}
P_{r}(R^{\ast})-P_{r}(R) & > & k_{\alpha}^{\ast}\sum\limits _{g\in A}p_{s}(g)-\sum\limits _{g\in C}p_{r}(g)\\
 & \geq & k_{\alpha}^{\ast}\sum\limits _{g\in A}p_{s}(g)-k_{\alpha}^{\ast}\sum\limits _{g\in C}p_{s}(g)\\
 & = & k_{\alpha}^{\ast}\left(\sum\limits _{g\in A}p_{s}(g)-\sum\limits _{g\in C}p_{s}(g)\right)\end{eqnarray*}
 Infine, notiamo che la quantità fra parentesi è uguale 0:\ \begin{eqnarray*}
\sum\limits _{g\in A}p_{s}(g)-\sum\limits _{g\in C}p_{s}(g) & = & \sum\limits _{g\in A}p_{s}(g)+\sum\limits _{g\in B}p_{s}(g)-\sum\limits _{g\in B}p_{s}(g)-\sum\limits _{g\in C}p_{s}(g)\\
 & = & \sum\limits _{g\in R^{\ast}}p_{s}(g)-\sum\limits _{g\in R}p_{s}(g)\\
 & = & P_{s}(R^{\ast})-P_{s}(R)=5-5=0\end{eqnarray*}
 Abbiamo dunque dimostrato che \[
P_{r}(R^{\ast})>P_{r}(R).\]


\noindent L'Esempio \ref{esempio grotta} può essere ripreso ed adattato
al problema di scelta del test ottimale. Infatti valgono le seguenti
analogie: 
\begin{itemize}
\item L'insieme dei gioielli e delle pietre prezione (raccolto) $R$ messe
nel sacco corrispondono alla regione critica $R$, ovvero all'insieme
delle osservazioni campionarie tali per cui l'ipotesi nulla $H_{0}$
va rifiutata. 
\item Il limite di peso $\alpha=5$ kg che coincide col peso del raccolto
$P_{s}(R)=\sum\limits _{g\in R}p_{s}(g)$ corrisponde al livello di
significatività $\alpha$ ovvero a $P_{H_{0}}(R)$. 
\item $P_{s}$ che nell'esempio denota la funzione peso di un qualsiasi
insieme di pietre preziose corrisponde alla probabilità sotto l'ipotesi
nulla $P_{H_{0}}$. $p_{s}$ dal canto suo corrisponde alla funzione
di densità sotto l'ipotesi nulla. 
\item Allo stesso modo $P_{r}$, che corrisponde al prezzo di un qualsiasi
insieme di pietre preziose, rappresenta la probabilità sotto l'ipotesi
alternativa $H_{A}$ di rifiutare l'ipotesi nulla. Tale probabilità
è rappresentata da $P_{H_{A}}(R)$ e va massimizzata per dato $\alpha$.
Nell'Esempio \ref{esempio grotta} abbiamo massimizzato il valore
del raccolto, ovvero $P_{r}(R)$. Analogamente a $p_{s}$, $p_{r}$
corrisponde alla funzione di densità sotto l'ipotesi alternativa. 
\item La strategia $S$, ovvero il criterio utilizzato per la costruzione
del raccolto (selezione dei gioielli da inserire nel sacco) corrisponde
alla statistica $S$ da utilizzarsi per la costruzione della regione
critica $R$. La strategia ottimale dell'Esempio \ref{esempio grotta}
corrisponde alla strategia \[
S^{\ast}(g)=\frac{p_{r}(g)}{p_{s}(g)}\]
 utilizzata per la costruzione della regione critica (riempire il
sacco) \[
R^{\ast}=\left\{ g\ |\ S^{\ast}(g)>k_{1-\alpha}^{\ast}\right\} \]
 con $k_{1-\alpha}^{\ast}$ scelto in maniera tale che \[
P_{s}(R)=\alpha=5\text{ kg.}\]
 Se adattato alla scelta del test ottimale la statistica ottimale
$S^{\ast}$ diventa semplicemente il rapporto \[
S^{\ast}(x_{1},...,x_{n})=\frac{f_{\theta_{A}}(x_{1},...,x_{n})}{f_{\theta_{0}}(x_{1},...,x_{n})}\]
 delle due funzioni di densità del campione sotto l'ipotesi alternativa
(numeratore) e sotto l'ipotesi nulla (denominatore). Il criterio per
la costruzione della regione critica $R^{\ast}$ corrispondente è
dunque \begin{equation}
R^{\ast}=\left\{ (x_{1},...,x_{n})\ |\ S^{\ast}(x_{1},...,x_{n})=\frac{f_{\theta_{A}}(x_{1},...,x_{n})}{f_{\theta_{0}}(x_{1},...,x_{n})}>k_{1-\alpha}^{\ast}\right\} .\label{criterio neyman pearson}\end{equation}
 L'interpretazione della relazione (\ref{criterio neyman pearson})
è molto semplice ed intuitiva. Essa afferma che nella costruzione
della regione critica (l'insieme delle osservazioni per le quali rigettare
l'ipotesi nulla) occorre tener conto del rapporto delle probabilità
sotto le due ipotesi. La regione critica dovrà essere costituita da
quelle osservazioni che forniscono la maggiore evidenza a favore dell'ipotesi
alternativa (contro l'ipotesi nulla). La regione critica ottimale
sarà dunque composta dalle realizzazioni con un alto rapporto $\frac{f_{\theta_{A}}(x_{1},...,x_{n})}{f_{\theta_{0}}(x_{1},...,x_{n})}$.
La soglia $k_{1-\alpha}^{\ast}$ è determinata dalla condizione che
l'errore di prima specie sia uguale al livello desiderato\[
P_{H_{0}}(R^{\ast})=P_{H_{0}}(S^{\ast}>k_{1-\alpha}^{\ast})=\alpha.\]
 Così facendo, per un dato livello di errore di primo tipo $\alpha$,
la potenza $\beta$ del test è massima e l'errore di secondo tipo
$1-\beta$ minimo. 
\end{itemize}
%TCIMACRO{%
%\TeXButton{TeX tabella 1}{\begin{table}[tbp]
%\vspace{-1.2cm}
%\caption{Elenco gioielli} \vspace{0.2cm} 
%\label{table:esempio1_neyman_pearson} \centering\begin{tabular}{|c|r|r|r|}
%\hline
%\textbf{Gioiello} & \textbf{Peso (grammi)} & \textbf{Prezzo in Fr.} & 
%\textbf{Prezzo/Peso} \\ \hline\hline
%$g_{1}$ & 671 & 8'000 & 11'923 \\ 
%$g_{2}$ & 1'717 & 1'000 & 582 \\ 
%$g_{3}$ & 1'034 & 7'000 & 6'770 \\ 
%$g_{4}$ & 1'756 & 7'000 & 3'986 \\ 
%$g_{5}$ & 1'199 & 2'000 & 1'668 \\ 
%$g_{6}$ & 886 & 1'000 & 1'129 \\ 
%$g_{7}$ & 1'166 & 1'000 & 858 \\ 
%$g_{8}$ & 1'040 & 2'000 & 1'923 \\ 
%$g_{9}$ & 932 & 5'000 & 5'365 \\ 
%$g_{10}$ & 1'380 & 7'000 & 5'072 \\ 
%$g_{11}$ & 1'769 & 10'000 & 5'653 \\ 
%$g_{12}$ & 1'686 & 2'000 & 1'186 \\ 
%$g_{13}$ & 902 & 6'000 & 6'652 \\ 
%$g_{14}$ & 1'257 & 3'000 & 2'387 \\ 
%$g_{15}$ & 1'768 & 3'000 & 1'697 \\ 
%$g_{16}$ & 528 & 5'000 & 9'470 \\ 
%$g_{17}$ & 1'676 & 6'000 & 3'580 \\ 
%$g_{18}$ & 1'523 & 10'000 & 6'566 \\ 
%$g_{19}$ & 1'666 & 9'000 & 5'402 \\ 
%$g_{20}$ & 1'456 & 3'000 & 2'060 \\ 
%$g_{21}$ & 871 & 10'000 & 11'481 \\ 
%$g_{22}$ & 988 & 4'000 & 4'049 \\ 
%$g_{23}$ & 1'190 & 6'000 & 5'042 \\ 
%$g_{24}$ & 540 & 7'000 & 12'963 \\ 
%$g_{25}$ & 831 & 5'000 & 6'017 \\ 
%$g_{26}$ & 802 & 6'000 & 7'481 \\ 
%$g_{27}$ & 900 & 8'000 & 8'889 \\ 
%$g_{28}$ & 1'679 & 6'000 & 3'574 \\ 
%$g_{29}$ & 1'166 & 6'000 & 5'146 \\ 
%$g_{30}$ & 1'980 & 5'000 & 2'525 \\ 
%$g_{31}$ & 850 & 2'000 & 2'353 \\ 
%$g_{32}$ & 676 & 10'000 & 14'793 \\ 
%$g_{33}$ & 1'399 & 3'000 & 2'144 \\ 
%$g_{34}$ & 1'883 & 3'000 & 1'593 \\ 
%$g_{35}$ & 2'535 & 7'000 & 2'761 \\ 
%$g_{36}$ & 814 & 9'000 & 11'057 \\ 
%$g_{37}$ & 853 & 2'000 & 2'345 \\ 
%$g_{38}$ & 1'488 & 2'000 & 1'344 \\ 
%$g_{39}$ & 1'430 & 2'000 & 1'399 \\ 
%$g_{40}$ & 1'113 & 1'000 & 898 \\ \hline
%Totale & 50'000 & 202'000 &  \\ \hline\hline
%\end{tabular}\end{table}}}%
%BeginExpansion
%
\begin{table}
\vspace{-1.2cm}
 \caption{Elenco gioielli}


\vspace{0.2cm}
 \label{table:esempio1_neyman_pearson} \centering\begin{tabular}{|c|r|r|r|}
\hline 
\textbf{Gioiello}  & \textbf{Peso (grammi)}  & \textbf{Prezzo in Fr.}  & \textbf{Prezzo/Peso} \tabularnewline
\hline
\hline 
$g_{1}$  & 671  & 8'000  & 11'923 \tabularnewline
$g_{2}$  & 1'717  & 1'000  & 582 \tabularnewline
$g_{3}$  & 1'034  & 7'000  & 6'770 \tabularnewline
$g_{4}$  & 1'756  & 7'000  & 3'986 \tabularnewline
$g_{5}$  & 1'199  & 2'000  & 1'668 \tabularnewline
$g_{6}$  & 886  & 1'000  & 1'129 \tabularnewline
$g_{7}$  & 1'166  & 1'000  & 858 \tabularnewline
$g_{8}$  & 1'040  & 2'000  & 1'923 \tabularnewline
$g_{9}$  & 932  & 5'000  & 5'365 \tabularnewline
$g_{10}$  & 1'380  & 7'000  & 5'072 \tabularnewline
$g_{11}$  & 1'769  & 10'000  & 5'653 \tabularnewline
$g_{12}$  & 1'686  & 2'000  & 1'186 \tabularnewline
$g_{13}$  & 902  & 6'000  & 6'652 \tabularnewline
$g_{14}$  & 1'257  & 3'000  & 2'387 \tabularnewline
$g_{15}$  & 1'768  & 3'000  & 1'697 \tabularnewline
$g_{16}$  & 528  & 5'000  & 9'470 \tabularnewline
$g_{17}$  & 1'676  & 6'000  & 3'580 \tabularnewline
$g_{18}$  & 1'523  & 10'000  & 6'566 \tabularnewline
$g_{19}$  & 1'666  & 9'000  & 5'402 \tabularnewline
$g_{20}$  & 1'456  & 3'000  & 2'060 \tabularnewline
$g_{21}$  & 871  & 10'000  & 11'481 \tabularnewline
$g_{22}$  & 988  & 4'000  & 4'049 \tabularnewline
$g_{23}$  & 1'190  & 6'000  & 5'042 \tabularnewline
$g_{24}$  & 540  & 7'000  & 12'963 \tabularnewline
$g_{25}$  & 831  & 5'000  & 6'017 \tabularnewline
$g_{26}$  & 802  & 6'000  & 7'481 \tabularnewline
$g_{27}$  & 900  & 8'000  & 8'889 \tabularnewline
$g_{28}$  & 1'679  & 6'000  & 3'574 \tabularnewline
$g_{29}$  & 1'166  & 6'000  & 5'146 \tabularnewline
$g_{30}$  & 1'980  & 5'000  & 2'525 \tabularnewline
$g_{31}$  & 850  & 2'000  & 2'353 \tabularnewline
$g_{32}$  & 676  & 10'000  & 14'793 \tabularnewline
$g_{33}$  & 1'399  & 3'000  & 2'144 \tabularnewline
$g_{34}$  & 1'883  & 3'000  & 1'593 \tabularnewline
$g_{35}$  & 2'535  & 7'000  & 2'761 \tabularnewline
$g_{36}$  & 814  & 9'000  & 11'057 \tabularnewline
$g_{37}$  & 853  & 2'000  & 2'345 \tabularnewline
$g_{38}$  & 1'488  & 2'000  & 1'344 \tabularnewline
$g_{39}$  & 1'430  & 2'000  & 1'399 \tabularnewline
$g_{40}$  & 1'113  & 1'000  & 898 \tabularnewline
\hline 
Totale  & 50'000  & 202'000  & \tabularnewline
\hline
\end{tabular}
\end{table}


%EndExpansion


%TCIMACRO{%
%\TeXButton{TeX tabella2}{\begin{table}[tbp] 
%\vspace{-1.2cm} 
%\caption{Elenco gioielli ordinati secondo $P_{r}/P_{s}$} \vspace{0.2cm} 
%\label{table:esempio2_neyman_pearson}
%\centering
%\begin{tabular}{|c|r|r|r|}
%\hline
%\textbf{Gioiello} & \textbf{Prezzo/Peso} & \textbf{Peso Cumulato} & \textbf{Prezzo Cumulato} \\ \hline\hline
%$g_{32}$ & 14'792.9 & 676 & 10'000 \\ 
%$g_{24}$ & 12'963.0 & 1'216 & 17'000 \\ 
%$g_{1}$ & 11'922.5 & 1'887 & 25'000 \\ 
%$g_{21}$ & 11'481.1 & 2'758 & 35'000 \\ 
%$g_{36}$ & 11'056.5 & 3'572 & 44'000 \\ 
%$g_{16}$ & 9'469.7 & 4'100 & 49'000 \\ 
%$g_{27}$ & \textbf{8'888.9} & \textbf{5'000} & \textbf{57'000} \\ 
%$g_{26}$ & 7'481.3 & 5'802 & 63'000 \\ 
%$g_{3}$ & 6'769.8 & 6'836 & 70'000 \\ 
%$g_{13}$ & 6'651.9 & 7'738 & 76'000 \\ 
%$g_{18}$ & 6'566.0 & 9'261 & 86'000 \\ 
%$g_{25}$ & 6'016.8 & 10'092 & 91'000 \\ 
%$g_{11}$ & 5'652.9 & 11'861 & 101'000 \\ 
%$g_{19}$ & 5'402.2 & 13'527 & 110'000 \\ 
%$g_{9}$ & 5'364.8 & 14'459 & 115'000 \\ 
%$g_{29}$ & 5'145.8 & 15'625 & 121'000 \\ 
%$g_{10}$ & 5'072.5 & 17'005 & 128'000 \\ 
%$g_{23}$ & 5'042.0 & 18'195 & 134'000 \\ 
%$g_{22}$ & 4'048.6 & 19'183 & 138'000 \\ 
%$g_{4}$ & 3'986.3 & 20'939 & 145'000 \\ 
%$g_{17}$ & 3'580.0 & 22'615 & 151'000 \\ 
%$g_{28}$ & 3'573.6 & 24'294 & 157'000 \\ 
%$g_{35}$ & 2'761.3 & 26'829 & 164'000 \\ 
%$g_{30}$ & 2'525.3 & 28'809 & 169'000 \\ 
%$g_{14}$ & 2'386.6 & 30'066 & 172'000 \\ 
%$g_{31}$ & 2'352.9 & 30'916 & 174'000 \\ 
%$g_{37}$ & 2'344.7 & 31'769 & 176'000 \\ 
%$g_{33}$ & 2'144.4 & 33'168 & 179'000 \\ 
%$g_{20}$ & 2'060.4 & 34'624 & 182'000 \\ 
%$g_{8}$ & 1'923.1 & 35'664 & 184'000 \\ 
%$g_{15}$ & 1'696.8 & 37'432 & 187'000 \\ 
%$g_{5}$ & 1'668.1 & 38'631 & 189'000 \\ 
%$g_{34}$ & 1'593.2 & 40'514 & 192'000 \\ 
%$g_{39}$ & 1'398.6 & 41'944 & 194'000 \\ 
%$g_{38}$ & 1'344.1 & 43'432 & 196'000 \\ 
%$g_{12}$ & 1'186.2 & 45'118 & 198'000 \\ 
%$g_{6}$ & 1'128.7 & 46'004 & 199'000 \\ 
%$g_{40}$ & 898.5 & 47'117 & 200'000 \\ 
%$g_{7}$ & 857.6 & 48'283 & 201'000 \\ 
%$g_{2}$ & 582.4 & 50'000 & 202'000 \\ \hline
%\end{tabular}\end{table}}}%
%BeginExpansion
%
\begin{table}
\vspace{-1.2cm}
 \caption{Elenco gioielli ordinati secondo $P_{r}/P_{s}$}


\vspace{0.2cm}
 \label{table:esempio2_neyman_pearson} \centering \begin{tabular}{|c|r|r|r|}
\hline 
\textbf{Gioiello}  & \textbf{Prezzo/Peso}  & \textbf{Peso Cumulato}  & \textbf{Prezzo Cumulato} \tabularnewline
\hline
\hline 
$g_{32}$  & 14'792.9  & 676  & 10'000 \tabularnewline
$g_{24}$  & 12'963.0  & 1'216  & 17'000 \tabularnewline
$g_{1}$  & 11'922.5  & 1'887  & 25'000 \tabularnewline
$g_{21}$  & 11'481.1  & 2'758  & 35'000 \tabularnewline
$g_{36}$  & 11'056.5  & 3'572  & 44'000 \tabularnewline
$g_{16}$  & 9'469.7  & 4'100  & 49'000 \tabularnewline
$g_{27}$  & \textbf{8'888.9}  & \textbf{5'000}  & \textbf{57'000} \tabularnewline
$g_{26}$  & 7'481.3  & 5'802  & 63'000 \tabularnewline
$g_{3}$  & 6'769.8  & 6'836  & 70'000 \tabularnewline
$g_{13}$  & 6'651.9  & 7'738  & 76'000 \tabularnewline
$g_{18}$  & 6'566.0  & 9'261  & 86'000 \tabularnewline
$g_{25}$  & 6'016.8  & 10'092  & 91'000 \tabularnewline
$g_{11}$  & 5'652.9  & 11'861  & 101'000 \tabularnewline
$g_{19}$  & 5'402.2  & 13'527  & 110'000 \tabularnewline
$g_{9}$  & 5'364.8  & 14'459  & 115'000 \tabularnewline
$g_{29}$  & 5'145.8  & 15'625  & 121'000 \tabularnewline
$g_{10}$  & 5'072.5  & 17'005  & 128'000 \tabularnewline
$g_{23}$  & 5'042.0  & 18'195  & 134'000 \tabularnewline
$g_{22}$  & 4'048.6  & 19'183  & 138'000 \tabularnewline
$g_{4}$  & 3'986.3  & 20'939  & 145'000 \tabularnewline
$g_{17}$  & 3'580.0  & 22'615  & 151'000 \tabularnewline
$g_{28}$  & 3'573.6  & 24'294  & 157'000 \tabularnewline
$g_{35}$  & 2'761.3  & 26'829  & 164'000 \tabularnewline
$g_{30}$  & 2'525.3  & 28'809  & 169'000 \tabularnewline
$g_{14}$  & 2'386.6  & 30'066  & 172'000 \tabularnewline
$g_{31}$  & 2'352.9  & 30'916  & 174'000 \tabularnewline
$g_{37}$  & 2'344.7  & 31'769  & 176'000 \tabularnewline
$g_{33}$  & 2'144.4  & 33'168  & 179'000 \tabularnewline
$g_{20}$  & 2'060.4  & 34'624  & 182'000 \tabularnewline
$g_{8}$  & 1'923.1  & 35'664  & 184'000 \tabularnewline
$g_{15}$  & 1'696.8  & 37'432  & 187'000 \tabularnewline
$g_{5}$  & 1'668.1  & 38'631  & 189'000 \tabularnewline
$g_{34}$  & 1'593.2  & 40'514  & 192'000 \tabularnewline
$g_{39}$  & 1'398.6  & 41'944  & 194'000 \tabularnewline
$g_{38}$  & 1'344.1  & 43'432  & 196'000 \tabularnewline
$g_{12}$  & 1'186.2  & 45'118  & 198'000 \tabularnewline
$g_{6}$  & 1'128.7  & 46'004  & 199'000 \tabularnewline
$g_{40}$  & 898.5  & 47'117  & 200'000 \tabularnewline
$g_{7}$  & 857.6  & 48'283  & 201'000 \tabularnewline
$g_{2}$  & 582.4  & 50'000  & 202'000 \tabularnewline
\hline
\end{tabular}
\end{table}


%EndExpansion


\newpage{}


\section{Esempio}

Vogliamo applicare il lemma di Neyman e Pearson alla seguente, classica
situazione. Supponiamo di osservare un campione di numerosità $n$
estratto da una popolazione $X\sim N(\mu,\sigma^{2})$ con $\sigma^{2}$
conosciuto. La famiglia parametrica $\mathcal{P}$ è dunque data da
\[
\mathcal{P}=\left\{ f_{\mu}(x)=\frac{1}{\sqrt{2\pi}\sigma}\exp(-\frac{1}{2\sigma^{2}}\left(x-\mu\right)^{2}),\ \mu\in\mathbb{R}\right\} \text{.}\]
 Supponiamo di voler testare l'ipotesi nulla \[
H_{0}:\mu=\mu_{0}\]
 contro l'ipotesi alternativa \[
H_{A}:\mu=\mu_{1}\]
 dove $\mu_{1}>\mu_{0}$. Qual è sotto queste condizioni il test più
potente?\ Per rispondere a questa domanda applichiamo i risultati
del lemma di Neyman e Pearson. La funzione di densità congiunta di
$(X_{1},...,X_{n})$ è semplicemente il prodotto delle densità di
$X_{1},...,X_{n}$\[
f_{\mu}(x_{i})=\frac{1}{\sqrt{2\pi}\sigma}\exp(-\frac{1}{2\sigma^{2}}\left(x_{i}-\mu\right)^{2})\]
 e\begin{eqnarray*}
f_{\mu}(x_{1},...,x_{n}) & = & \left(\frac{1}{\sqrt{2\pi}\sigma}\right)^{n}\exp(-\frac{1}{2\sigma^{2}}\left[\left(x_{1}-\mu\right)^{2}+...+\left(x_{n}-\mu\right)^{2}\right])\\
 & = & \left(\frac{1}{\sqrt{2\pi}\sigma}\right)^{n}\exp(-\frac{1}{2\sigma^{2}}\sum\limits _{i=1}^{n}\left(x_{i}-\mu\right)^{2}).\end{eqnarray*}
 La statistica ottimale $S$ definita dal rapporto fra le densità
del campione sotto l'ipotesi alternativa e quella nulla è data da\begin{eqnarray*}
S(x_{1},...,x_{n}) & = & \frac{f_{H_{A}}(x_{1},...,x_{n})}{f_{H_{0}}(x_{1},...,x_{n})}\\
 & = & \frac{\left(\frac{1}{\sqrt{2\pi}\sigma}\right)^{n}\exp(-\frac{1}{2\sigma^{2}}\sum\limits _{i=1}^{n}\left(x_{i}-\mu_{1}\right)^{2})}{\left(\frac{1}{\sqrt{2\pi}\sigma}\right)^{n}\exp(-\frac{1}{2\sigma^{2}}\sum\limits _{i=1}^{n}\left(x_{i}-\mu_{0}\right)^{2})}\\
 & = & \exp\left(-\frac{1}{2\sigma^{2}}\left[\sum\limits _{i=1}^{n}\left(x_{i}-\mu_{1}\right)^{2}-\sum\limits _{i=1}^{n}\left(x_{i}-\mu_{0}\right)^{2}\right]\right)\\
 & = & \exp\left(-\frac{1}{2\sigma^{2}}\left[n(\mu_{1}^{2}-\mu_{0}^{2})-2\underset{n\overline{x}}{\underbrace{\sum\limits _{i=1}^{n}x_{i}}}\mu_{1}+2\underset{n\overline{x}}{\underbrace{\sum\limits _{i=1}^{n}x_{i}}}\mu_{0}\right]\right)\end{eqnarray*}
 La regione critica sappiamo essere definita dalla seguente formula$.$\[
R=\left\{ (x_{1},...,x_{n})\ |\ S(x_{1},...,x_{n})>k_{\alpha}\right\} .\]
 Otteniamo quindi \begin{equation}
R=\left\{ (x_{1},...,x_{n})\ |\ \exp\left(-\frac{1}{2\sigma^{2}}\left[n(\mu_{1}^{2}-\mu_{0}^{2})-2n\left(\mu_{1}-\mu_{0}\right)\overline{x}\right]\right)>k_{\alpha}\right\} ,\label{a1}\end{equation}
 con $k_{\alpha}$ da determinare tramite il vincolo $P_{H_{0}}(R)=\alpha.$
Poiché $n$, $\mu_{0}$, $\mu_{1}$ sono conosciuti possiamo riscrivere
la (\ref{a1}) come\begin{eqnarray*}
R & = & \left\{ (x_{1},...,x_{n})\ |\ -\frac{1}{2\sigma^{2}}\left[n(\mu_{1}^{2}-\mu_{0}^{2})-2n\left(\mu_{1}-\mu_{0}\right)\overline{x}\right]>\ln(k_{\alpha})\right\} \\
 & = & \left\{ (x_{1},...,x_{n})\ |\ \left[n(\mu_{1}^{2}-\mu_{0}^{2})-2n\left(\mu_{1}-\mu_{0}\right)\overline{x}\right]<-2\sigma^{2}\ln(k_{\alpha})\right\} \\
 & = & \left\{ (x_{1},...,x_{n})\ |\ -2n\left(\mu_{1}-\mu_{0}\right)\overline{x}<-2\sigma^{2}\ln(k_{\alpha})-n(\mu_{1}^{2}-\mu_{0}^{2})\right\} \\
 & = & \left\{ (x_{1},...,x_{n})\ |\ \overline{x}>\left[2\sigma^{2}\ln(k_{\alpha})+n(\mu_{1}^{2}-\mu_{0}^{2})\right]/2n\left(\mu_{1}-\mu_{0}\right)\right\} \\
 & = & \left\{ (x_{1},...,x_{n})\ |\ \overline{x}>\widetilde{k}_{\alpha}\right\} .\end{eqnarray*}
 Abbiamo sorprendentemente ottenuto il test basato sulla media campionaria
incontrato ripetutamente in questo capitolo. La soglia $\widetilde{k}_{\alpha}$
deve essere semplicemente scelta in modo che $P_{H_{0}}(R)=\alpha$.
Il passaggio da $k_{\alpha}$ a $\widetilde{k}_{\alpha}$ è stato
causato dalle trasformazioni che abbiamo applicato alla (\ref{a1}).
Tuttavia queste trasformazoni non modificano la regione critica $R$,
modificano solo la formula utilizzata per rappresentarla.

\bigskip{}


\noindent Il risultato così ottenuto ha la seguente interpretazione.
Quando la popolazione è distribuita secondo la legge normale con $\sigma^{2}$
conosciuto il test sulla media è il miglior test (il più potente).
Non a caso avevamo visto nel lungo Esempio \ref{esempio caseificio p1}
che il test basato su $\overline{X}$ risultava essere più potente
rispetto al test basato su $X_{\min}$. Notiamo inoltre che il risultato
è indipendente dal valore di $\mu_{1}$. Questo significa che sotto
l'ipotesi di normalità il test basato sulla media è il più potente
non solo rispetto all'ipotesi alternativa semplice $H_{A}:\mu=\mu_{1}$
ma anche rispetto all'ipotesi alternativa multipla $H_{A}:\mu>\mu_{0}$.\newpage{}


\subsection{Calcolo della potenza}

Il calcolo della potenza del test basato sulla media è particolarmente
istruttivo per analizzare la dipendenza di $\beta$ da $\mu_{0}$,
$\mu_{1}$, $n$ ed $\alpha$. Sia dunque $X\sim N(\mu,\sigma^{2})$
con $\sigma^{2}$ conosciuto e \[
H_{0}:\mu=\mu_{0}\]
 mentre l'ipotesi alternativa \[
H_{A}:\mu=\mu_{1},\ \ \ \ \mu_{1}>\mu_{0}.\]
 Prendendo il test basato sulla media abbiamo per il caso unilaterale
destro che \[
R=\left\{ (x_{1},...,x_{n})\ |\ \overline{x}>k_{1-\alpha}\right\} \]
 con la soglia critica $k_{1-\alpha}$ determinata tramite la solita
equazione \[
P_{H_{0}}(\overline{X}>k_{1-\alpha})=\alpha.\]
 Poiché sotto l'ipotesi nulla $\overline{X}\sim N(\mu_{0},\frac{\sigma^{2}}{n})$
applichiamo la standardizzazione seguente\[
P_{H_{0}}\left(\underset{Z\sim N(0,1)}{\underbrace{\frac{\overline{X}-\mu_{0}}{\sigma/\sqrt{n}}}}>\frac{k_{1-\alpha}-\mu_{0}}{\sigma/\sqrt{n}}\right)=\alpha\]
 Utilizzando la relazione $P\left(Z>\frac{\sqrt{n}\left(k_{1-\alpha}-\mu_{0}\right)}{\sigma}\right)=1-P\left(Z\leq\frac{\sqrt{n}\left(k_{1-\alpha}-\mu_{0}\right)}{\sigma}\right)$
otteniamo\begin{equation}
P\left(Z\leq\frac{k_{1-\alpha}-\mu_{0}}{\sigma/\sqrt{n}}\right)=1-\alpha\text{.}\label{uguaglianza quantile standard}\end{equation}
 Poiché $z_{1-\alpha}$ è soluzione della precedente equazione, cioé\[
P\left(Z\leq z_{1-\alpha}\right)=1-\alpha,\]
 ricaviamo il valore della soglia critica $k_{1-\alpha}$ uguagliando
l'espressione nella (\ref{uguaglianza quantile standard}) a $z_{1-\alpha}$
\begin{eqnarray}
\frac{k_{1-\alpha}-\mu_{0}}{\sigma/\sqrt{n}} & = & z_{1-\alpha}\notag\\
k_{1-\alpha} & = & \mu_{0}+z_{1-\alpha}\frac{\sigma}{\sqrt{n}}\text{.}\label{valore critico test sulla media normale}\end{eqnarray}
 La soglia critica $k_{1-\alpha}$ dipende dunque 
\begin{itemize}
\item da $\mu_{0}$, il valore di $\mu$ sotto l'ipotesi nulla, 
\item dal livelo di significatività $\alpha$ che determinina indirettamente
$z_{1-\alpha}$, 
\item dalla numerosità del campione (quantità d'informazione disponibile). 
\end{itemize}
\noindent Una volta che $k_{1-\alpha}$ è stato fissato \emph{esso
rimane costante}.\ Il calcolo della potenza del test presuppone il
calcolo della probabilità $P(\overline{X}>k_{1-\alpha}\ |\ H_{A}$
è vera$)$, cioè\begin{eqnarray*}
\beta & = & P_{H_{A}}(\overline{X}>k_{1-\alpha})\\
 & = & P_{H_{A}}\left(\underset{Z\sim N(0,1)}{\underbrace{\frac{\overline{X}-\mu_{1}}{\sigma/\sqrt{n}}}}>\frac{k_{1-\alpha}-\mu_{1}}{\sigma/\sqrt{n}}\right)\\
 & = & P\left(Z>\frac{k_{1-\alpha}-\mu_{1}}{\sigma/\sqrt{n}}\right)\\
 & = & 1-P\left(Z\leq\frac{k_{1-\alpha}-\mu_{1}}{\sigma/\sqrt{n}}\right)\end{eqnarray*}
 Sostituendo l'espressione ricavata in precedenza per $k_{1-\alpha}$
otteniamo la formula finale \begin{eqnarray}
\beta & = & 1-P\left(Z\leq z_{1-\alpha}-\left(\mu_{1}-\mu_{0}\right)\frac{\sqrt{n}}{\sigma}\right)\label{formula potenza media}\\
 & = & 1-\Phi\left(z_{1-\alpha}-\left(\mu_{1}-\mu_{0}\right)\frac{\sqrt{n}}{\sigma}\right)\notag\end{eqnarray}
 dove $\Phi$ rappresenta la funzione di ripartizione della normale
standard, cioé \[
\Phi\left(x\right)=\int\limits _{-\infty}^{x}\frac{1}{\sqrt{2\pi}}\exp\left(-\frac{1}{2}x^{2}\right)dx.\]
 Osserviamo che la potenza $\beta$ del test dipende oltre che 
\begin{itemize}
\item dal valore di $\mu$ sotto l'ipotesi nulla $H_{0}$, 
\item dal livello di significatività $\alpha$ 
\item dalla numerosità del campione 
\end{itemize}
\noindent anche da 
\begin{itemize}
\item $\mu_{1}$, il valore di $\mu$ sotto l'ipotesi alternativa $H_{A}$. 
\end{itemize}
\noindent La formula (\ref{formula potenza media}) ci permette di
analizzare il comportamento della potenza in funzione dei vari parametri
$\mu_{1},n,\alpha$.

\bigskip{}

\begin{enumerate}
\item $\mu_{1},n$ fissi: modifichiamo solo $\alpha$.


Quando il livello di significatività $\alpha$ aumenta, $1-\alpha$
diminuisce e con esso $z_{1-\alpha}$. Poiché $\Phi$ è una funzione
monotona crescente, $\beta$ aumenterà. Quindi quando \[
\alpha\uparrow\ \rightarrow\beta\uparrow\text{ e }1-\beta\downarrow.\]


\item $\alpha,n$ fissi: cambia solo $\mu_{1}$.


Quando $\mu_{1}$ aumenta l'alternativa si allontana dall'ipotesi
nulla. Caeteris paribus $\Phi$ diminuirà e quindi $\beta$ tenderà
ad aumentare. L'errore di secondo tipo $1-\beta$ diminuirà. Più l'ipotesi
alternativa si allontana dall'ipotesi nulla e più la potenza aumenta
(l'errore di seconda specie diminuisce):\ il test discrimina meglio
fra l'ipotesi nulla e l'alternativa.

\item $\mu_{1},\alpha$ fissi: cambia solo $n$.


Con l'aumentare del numero $n$ di osservazioni la funzione $\Phi$
diminuisce e la potenza $\beta$ del test aumenta. L'errore di seconda
specie diminuisce. Ciò è in linea con l'intuizione. Se ho più informazione
a disposizione riuscirò a discriminare in maniera migliore tra le
due ipotesi.

\end{enumerate}
\bigskip{}


\noindent Questi calcoli di potenza vengono eseguiti prima di fare
una stima. Ad esempio, supponiamo che per dato errore di prima specie
$\alpha=5\%$ e ipotesi alternativa $\mu_{1}$ si desideri avere un
errore di seconda specie $1-\beta=20\%$. La relazione data dalla
formula (\ref{formula potenza media}) ci permette di determinare
la numerosità del campione necessario \begin{eqnarray*}
\beta & = & 1-\Phi\left(z_{1-\alpha}-\left(\mu_{1}-\mu_{0}\right)\frac{\sqrt{n}}{\sigma}\right)\\
1-\beta & = & \Phi\left(z_{1-\alpha}-\left(\mu_{1}-\mu_{0}\right)\frac{\sqrt{n}}{\sigma}\right).\end{eqnarray*}
 Poiché $z_{1-\beta}$ soddisfa $1-\beta=\Phi\left(z_{1-\beta}\right)$
uguagliamo $z_{1-\beta}$ a $z_{1-\alpha}-\left(\mu_{1}-\mu_{0}\right)\frac{\sqrt{n}}{\sigma}$
ed otteniamo\[
n=\left(\frac{z_{1-\beta}-z_{1-\alpha}}{\left(\mu_{1}-\mu_{0}\right)/\sigma}\right)^{2}\]
 che in questo caso per $\left(\mu_{1}-\mu_{0}\right)/\sigma=0.1$
diventa\[
n=\left(\frac{-0.841-1.645}{0.1}\right)^{2}=618.\]



\chapter{TEST}


\section{Test sulla media con $X$ non normale}

Il test sulla media fino ad ora considerato si basa sull'ipotesi di
normalità della popolazione $X$. Vogliamo ora rinunciare all'ipotesi
di normalità ed assumere unicamente che $X\sim F$ (non necessariamente
normale quindi) con $E(X)=\mu$\ e $V(X)=\sigma^{2}$. Per contro
manteniamo l'ipotesi di $i.i.d.$ (indipendenza e medesima distribuzione)\ delle
osservazioni $X_{1},...,X_{n}$. Come andrà effettuato ora il test
sulla media? Supponiamo di voler testare \begin{eqnarray*}
H_{0} & : & \mu=\mu_{0}\\
H_{A} & : & \mu>\mu_{0}\end{eqnarray*}
 dato un livello di significatività $\alpha$ del $5\%$. Sebbene
grazie alle proprietà del valore atteso e della varianza possiamo
affermare che $\overline{X}\sim(\mu,\frac{\sigma^{2}}{n})$, la distribuzione
di $\overline{X}$ non è più conosciuta. Questo pone un problema per
la determinazione della regione critica ed in particolare della soglia
$k_{1-\alpha}$:\[
P_{H_{0}}(\overline{X}>k_{0.95})=0.05.\]


\bigskip{}


\noindent Fortunatamente, per $n$ sufficientemente grandi, il teorema
del limite centrale viene in nostro soccorso permettendoci di calcolare
il valore di $k_{0.05}$ come se $X$ fosse $N(\mu,\sigma^{2})$ e
quindi come se $\overline{X}\sim N(\mu,\frac{\sigma^{2}}{n})$. Infatti
sappiamo che per un campione $X_{1},...,X_{n}$ di$\ n$ osservazioni
indipendenti di $X\sim(\mu,\sigma^{2})$ \[
\frac{\overline{X}_{n}-\mu}{\sigma/\sqrt{n}}\underset{n\rightarrow\infty}{\sim}N(0,1).\]
 Ma questo significa che, sotto l'ipotesi nulla\[
P_{H_{0}}\left(\underset{\text{circa }Z}{\underbrace{\frac{\overline{X}_{n}-\mu_{0}}{\sigma/\sqrt{n}}}}>\frac{k_{0.95}-\mu_{0}}{\sigma/\sqrt{n}}\right)\underset{\text{circa}}{=}P\left(Z>\frac{k_{0.95}-\mu_{0}}{\sigma/\sqrt{n}}\right)=0.05.\]
 In pratica quindi, il teorema del limite centrale, per $n$ sufficientemente
grandi, ci permette di eseguire il test sulla media come se la popolazione
$X$ sia normale.


\section{Test di Student (t-test)}

Vogliamo riprendere nuovamente il test sulla media riportandoci al
caso in cui la popolazione $X$ è normale $N(\mu,\sigma^{2})$. Questa
volta consideriamo la situazione in cui la varianza $\sigma^{2}$
della popolazione è sconosciuta. In questo contesto $\sigma^{2}$
è detto parametro di disturbo (nuisance parameter) in quanto non è
il parametro di immediato interesse. Le nostre ipotesi sono sempre\begin{eqnarray*}
H_{0} & : & \mu=\mu_{0},\\
H_{A} & : & \mu>\mu_{0}.\end{eqnarray*}
 Bisogna stimare $\mu$ e $\sigma^{2}$ simultaneamente\begin{eqnarray*}
\widehat{\mu} & = & \overline{X}=\frac{1}{n}\sum_{i=1}^{n}X_{i}\text{ (buon stimatore di }\mu),\\
\widehat{\sigma}^{2} & = & \frac{1}{n-1}\sum_{i=1}^{n}(X_{i}-\overline{X})^{2}\text{ (buon stimatore di }\sigma^{2}\text{, }E(\widehat{\sigma}^{2})=\sigma^{2}).\end{eqnarray*}
 Sappiamo che se $\sigma^{2}$ fosse conosciuto potremmo effettuare
il test abituale andando a calcolare per un dato livello di significatività
il valore critico $k_{1-\alpha}$:\begin{equation}
P_{H_{0}}\left(\underset{Z\sim N(0,1)}{\underbrace{\frac{\overline{X}-\mu_{0}}{\sigma/\sqrt{n}}}}>\frac{k_{1-\alpha}-\mu_{0}}{\sigma/\sqrt{n}}\right)=\alpha.\label{rapporto t1}\end{equation}
 Potremmo pensare di fare la stessa cosa sostituendo a $\sigma$ sconosciuto
la stima $\widehat{\sigma}$. In tal caso però la quantità $\frac{\overline{X}-\mu_{0}}{\widehat{\sigma}/\sqrt{n}}$
consiste nel rapporto di due variabili casuali che riscriviamo come
segue \[
\frac{\overline{X}-\mu_{0}}{\widehat{\sigma}/\sqrt{n}}=\frac{\frac{\overline{X}-\mu_{0}}{\sigma/\sqrt{n}}}{\widehat{\sigma}/\sigma}\]

\begin{itemize}
\item Numeratore: variabile casuale $\frac{\overline{X}-\mu_{0}}{\sigma/\sqrt{n}}$
distribuita sotto l'ipotesi nulla $H_{0}$ come una normale standard,
$\frac{\overline{X}-\mu_{0}}{\sigma/\sqrt{n}}\sim N(0,1)$. 
\item Denominatore: variabile casuale $\widehat{\sigma}/\sigma\underset{H_{0}}{\sim}\ ?$
(la distribuzione è sconosciuta!) 
\end{itemize}
\noindent Sostituendo $\widehat{\sigma}$ a $\sigma$ nella (\ref{rapporto t1})
e considerando quanto detto otteniamo \begin{equation}
P_{H_{0}}\left(\underset{\sim\ ?}{\underbrace{\frac{\frac{\overline{X}-\mu_{0}}{\sigma/\sqrt{n}}}{\widehat{\sigma}/\sigma}}}>\frac{k_{1-\alpha}-\mu_{0}}{\widehat{\sigma}/\sqrt{n}}\right)=\alpha.\label{rapporto t2}\end{equation}
 La nostra statistica rappresenta quindi il rapporto tra 2 variabili
casuali. La soluzione a questo problema è in due tappe: 
\begin{enumerate}
\item Derivazione della distribuzione del denominatore 
\item Derivazione della distribuzione del rapporto 
\end{enumerate}
\noindent Vedremo che la distribuzione del denominatore dipende direttamente
dalla distribuzione $\chi_{m}^{2}$ (Chi-2).


\subsection{La distribuzione $\chi_{m}^{2}$}

La distribuzione Chi-2, notata $\chi_{m}^{2}$, con $m$ gradi di
libertà è definita come la somma del quadrato di $m$ variabili aleatorie
normali standard indipendenti. $Z_{1},Z_{2},...,Z_{m}$ $i.i.d.$
$N(0,1)$. \[
V=\sum\limits _{n=1}^{m}Z_{n}^{2}\sim\chi_{m}^{2}.\]

\begin{itemize}
\item Funzione di densità:\[
f(v,m)=\frac{1}{2^{\frac{m}{2}}\Gamma(\frac{m}{2})}\exp(-\frac{v}{2})v^{\frac{m}{2}-1}\]
 dove\[
\Gamma(y)=\int\limits _{0}^{\infty}\exp(-u)u^{y-1}du\]

\item Calcolo:\[
P(V\leq x)=\int\limits _{0}^{x}f(v,m)dv\]
 oppure in Excel o Openoffice tramite la funzione $CHIDIST(x,m)$.
Attenzione: la funzione $CHIDIST(x,m)=P(V>x)$. 
\end{itemize}

\subsection{La distribuzione di Student (o distribuzione-t)}

\begin{definizione} Distribuzione-t. Siano $Z\sim N(0,1)$ e $V\sim\chi_{m}^{2}$
due variabili aleatorie indipendenti. Il raporto \[
\frac{Z}{\sqrt{\frac{V}{m}}}\sim t_{m}\]
 segue una distribuzione di student a $m$ gradi di libertà. \end{definizione}

\noindent La distribuzione-t è simile alla normale, simmetrica rispetto
allo zero, ma possiede delle code più pesanti (tendono meno velocemente
a zero rispetto alla distribuzione normale). Come per la distribuzione
normale standard esistono delle tavole per il calcolo dell' $\alpha-$quantile.
A differenza della distribuzione normale, per la distribuzione $t$
occorre specificare oltre alla probabilità $\alpha$ anche i gradi
di libertà $m$ desiderati.


\subsection{Il $t$-test}

Torniamo ora al rapporto della statistica utilizzata nella (\ref{rapporto t2})
\[
\frac{\frac{\overline{X}-\mu_{0}}{\sigma/\sqrt{n}}}{\widehat{\sigma}/\sigma}=\frac{Z\sim N(0,1)}{\sqrt{\frac{\widehat{\sigma}^{2}}{\sigma^{2}}}}.\]
 Per quanto riguarda il denominatore, ed in particolare il rapporto
$\widehat{\sigma}^{2}/\sigma^{2}$ notiamo che\[
\frac{\widehat{\sigma}^{2}}{\sigma^{2}}=\frac{\frac{1}{n-1}\sum\limits _{i=1}^{n}(X_{i}-\overline{X})^{2}}{\sigma^{2}}=\frac{\frac{1}{\sigma^{2}}\sum\limits _{i=1}^{n}(X_{i}-\overline{X})^{2}}{n-1}=\frac{V\sim\chi_{n-1}^{2}}{n-1}.\]
 Riassumendo abbiamo dunque che \[
\frac{\frac{\overline{X}-\mu_{0}}{\sigma/\sqrt{n}}}{\widehat{\sigma}/\sigma}=\frac{N(0,1)}{\sqrt{\frac{\chi_{n-1}^{2}}{n-1}}}\sim t_{n-1.}\]
 La nostra statistica è dunque distribuita come una variabile casuale
$t$ a $n-1$ gradi di libertà%
\footnote{È immediato vedere che la statistica \begin{eqnarray*}
W & = & \frac{1}{\sigma^{2}}\sum\limits _{i=1}^{n}(X_{i}-\mu)^{2}\\
 & = & \sum\limits _{i=1}^{n}\left(\frac{X_{i}-\mu}{\sigma}\right)^{2}\end{eqnarray*}
 è una $\chi_{n}^{2}$. Tuttavia $\mu$ è sconosciuto e va sostituito
con $\overline{X}$. Poiché \[
\sum\limits _{i=1}^{n}\left(X_{i}-\overline{X}\right)=0\]
 abbiamo in realtà solo $n-1$ gradi di libertà nella \textquotedblright{}scelta\textquotedblright{}\ di
$X_{1}-\overline{X}$, $X_{2}-\overline{X}$, ..., $X_{n}-\overline{X}$:
l'ultima osservazione non può essere scelta come si vuole in quanto
la somma deve essere $0$.%
}.

\bigskip{}


\noindent La struttura del test di Student è dunque identica a quella
del test sulla media con la sola differenza che la varianza sconosciuta
va sostituita con lo stimatore $\widehat{\sigma}^{2}=\frac{1}{n-1}\sum_{i=1}^{n}(X_{i}-\overline{X})^{2}$.
Il calcolo della soglia critica $k_{\alpha}$ andrà poi modificato
come segue. Sotto l'ipotesi nulla \begin{eqnarray*}
P_{H_{0}}\left(\underset{\sim t_{n-1}}{\underbrace{\frac{\overline{X}-\mu_{0}}{\widehat{\sigma}/\sqrt{n}}}}>\frac{k_{1-\alpha}-\mu_{0}}{\widehat{\sigma}/\sqrt{n}}\right) & = & \alpha\\
P\left(t_{n-1}>\frac{k_{1-\alpha}-\mu_{0}}{\widehat{\sigma}/\sqrt{n}}\right) & = & \alpha\end{eqnarray*}
 Il procedimento è \emph{identico} a quello con la normale:\begin{eqnarray*}
1-P\left(t_{n-1}\leq\frac{k_{1-\alpha}-\mu_{0}}{\widehat{\sigma}/\sqrt{n}}\right) & = & \alpha\\
P\left(t_{n-1}\leq\frac{k_{1-\alpha}-\mu_{0}}{\widehat{\sigma}/\sqrt{n}}\right) & = & 1-\alpha.\end{eqnarray*}
 È dunque necessario derivare l' $1-\alpha$-quantile della distribuzione
di Student a $n-1$ gradi di libertà che notiamo con $t_{1-\alpha,n-1}$.
Infine, uguagliando $t_{1-\alpha,n-1}$ a $\frac{k_{1-\alpha}-\mu_{0}}{\sigma/\sqrt{n}}$
si ottiene il valore di $k_{\alpha}$:\begin{equation}
k_{\alpha}=\mu_{0}+t_{1-\alpha,n-1}\widehat{\sigma}/\sqrt{n}.\label{valore critico test sulla media t}\end{equation}
 Confrontanto la (\ref{valore critico test sulla media t}) con la
versione corrispondente (\ref{valore critico test sulla media normale})
nel caso in cui la varianza $\sigma^{2}$ è conosciuta notiamo che
la vera deviazione standard $\sigma$ è stata sostituita con la deviazione
standard stimata e l' $1-\alpha$-quantile della distribuzione normale
è stato rimpiazzato dall'$1-\alpha$-quantile della distribuzione
$t$ a $n-1$ gradi di libertà.


\section{Altri test}


\subsection{Test su due campioni: uguaglianza di due medie}

Il test che tratteremo in questo paragrafo riguarda il confronto fra
due gruppi di osservazioni campionate da due popolazioni distinte.
Le osservazioni della prima popolazione sono indicate con $X_{1},...,X_{m}$
mentre quelle della seconda con $Y_{1},...,Y_{n}$. Gli interi $m$
ed $n$ indicano la numerosità del primo e rispettivamente del secondo
campione. In medicina, psicologia, economia e nelle scienze sociali
in genere capita sovente di dover determinare l'efficacia di un nuovo
medicamento, la validità di un nuovo metodo d'insegnamento, l'effetto
di una campagna pubblicitaria, ecc. Per questo motivo si è soliti
raccogliere dati su due popolazioni fra loro ben distinte, notate
appunto $X$ e $Y$.\vspace{1cm}


\begin{center}
\begin{tabular}{c|cc}
 & \textquotedblright{}treatment\textquotedblright{}  & controllo \tabularnewline
\hline 
medicina  & nuovo farmaco  & placebo \tabularnewline
didattica  & nuovo programma  & vecchio programma \tabularnewline
marketing  & dopo la campagna pubb.  & prima della campagna pubb.\tabularnewline
\end{tabular}
\par\end{center}

\vspace{1cm}


\noindent Il parametro d'interesse in questo caso è il valore atteso
delle due popolazioni. Infatti, se le due popolazioni hanno valore
atteso diverso significa che l'azione da noi intrapresa ha avuto l'effetto
sperato. Generalmente si è soliti utilizzare l'ipotesi nulla: le due
popolazioni possiedono lo stesso valore atteso. La speranza è dunque
quella di rifiutare l'ipotesi nulla. Studieremo ora come effettuare
il test quando le due popolazioni possiedono la stessa varianza (parleremo
in tal caso di omoschedasticità) e quando invece possiedono varianza
diversa (caso questo di eteroschedasticità).


\subsubsection{Caso 1: homoschedasticità delle due popolazioni}

Assumiamo le seguenti ipotesi sulle due popolazioni e sui rispettivi
campioni: 
\begin{enumerate}
\item Le osservazioni $X_{1},...,X_{m}$ formano un campione di osservazioni
$i.i.d.$ (indipendenti ed identicamente distribuite) estratte dalla
popolazione $X\sim N(\mu_{x},\sigma_{x}^{2})$ 
\item Le osservazioni $Y_{1},...,Y_{n}$ formano un campione di osservazioni
$i.i.d.$ (indipendenti ed identicamente distribuite) estratte dalla
popolazione $Y\sim N(\mu_{y},\sigma_{y}^{2})$ 
\item La varianza della popolazione $X$ è la stessa della popolazione $Y$:
$\sigma_{x}^{2}=\sigma_{y}^{2}=\sigma^{2}$. $\sigma^{2}$ è sconosciuta. 
\item Per ogni $X_{i}$ in $X_{1},...,X_{m}$ e $Y_{j}$ in $Y_{1},...,Y_{n}$
vale che $X_{i}$ e $Y_{j}$ sono fra loro indipendenti. 
\end{enumerate}
\noindent Calcoliamo ora la varianza di $\overline{X}$, $\overline{Y}$
e $cov(\overline{X},\overline{Y})$:\begin{eqnarray*}
V(\overline{X}) & = & \frac{\sigma_{x}^{2}}{m}=\frac{\sigma^{2}}{m}\\
V(\overline{Y}) & = & \frac{\sigma_{y}^{2}}{n}=\frac{\sigma^{2}}{n}\end{eqnarray*}
 \begin{eqnarray*}
cov(\overline{X},\overline{Y}) & = & cov(\frac{1}{m}\sum\limits _{i=1}^{m}X_{i},\frac{1}{n}\sum\limits _{j=1}^{n}Y_{j})\\
 & = & \frac{1}{m}cov(\sum\limits _{i=1}^{m}X_{i},\frac{1}{n}\sum\limits _{j=1}^{n}Y_{j})\\
 & = & \frac{1}{m}\frac{1}{n}cov(\sum\limits _{i=1}^{m}X_{i},\sum\limits _{j=1}^{n}Y_{j})\\
 & = & \frac{1}{m}\frac{1}{n}\sum\limits _{i=1}^{m}cov(X_{i},\sum\limits _{j=1}^{n}Y_{j})\\
 & = & \frac{1}{m}\frac{1}{n}\sum\limits _{i=1}^{m}\sum\limits _{j=1}^{n}\underset{0\text{ per ogni }i,j}{\underbrace{cov(X_{i},Y_{j})}}\\
 & = & 0\end{eqnarray*}
 La varianza di $\overline{X}-\overline{Y}$ sarà dunque uguale a
\begin{eqnarray*}
V(\overline{X}-\overline{Y}) & = & V(\overline{X})+V(\overline{Y})-2cov(\overline{X},\overline{Y})\\
 & = & \frac{\sigma^{2}}{m}+\frac{\sigma^{2}}{n}=\left(\frac{1}{m}+\frac{1}{n}\right)\sigma^{2}\ .\end{eqnarray*}
 Sotto l'ipotesi nulla la differenza $\overline{X}-\overline{Y}$
sarà distribuita secondo la legge normale, con valore atteso $0$
e varianza $\left(\frac{1}{m}+\frac{1}{n}\right)\sigma^{2}$. Poiché
$\sigma^{2}$ è sconosciuto andrà stimato. Lo stimatore da utilizzarsi
in questo caso è\[
\widehat{\sigma}^{2}=\frac{1}{m+n-2}\left(\sum_{i=1}^{m}\left(x_{i}-\overline{x}\right)^{2}+\sum_{j=1}^{n}\left(y_{i}-\overline{y}\right)^{2}\right)\]


$H_{0}:\mu_{x}=\mu_{y}$

\[
\tau=\frac{\overline{X}-\overline{Y}}{\sqrt{\left(\frac{1}{m}+\frac{1}{n}\right)\widehat{\sigma}^{2}}}\]
 sotto l'ipotesi nulla \[
\tau\sim t_{m+n-2}\]
 gradi di libertà.


\subsubsection{Caso 2: eteroschedasticità delle due popolazioni}

Le ipotesi riguardanti la normalità delle due popolazioni $X$ e $Y$
così come le ipotesi di indipendenza fra i rispettivi campioni rimangono
invariate. Solo l'ipotesi numero tre riguardante l'uguaglianza delle
varianze delle due popolazioni viene a cadere nel senso che non sarà
necessariamente vero che $\sigma_{x}^{2}=\sigma_{y}^{2}$. L'ipotesi
nulla rimane immutata, cioè $H_{0}:\mu_{x}=\mu_{y}$. In questo caso
avremo \begin{eqnarray*}
V(\overline{X}) & = & \frac{\sigma_{x}^{2}}{m}\\
V(\overline{Y}) & = & \frac{\sigma_{y}^{2}}{n}\end{eqnarray*}
 \[
cov(\overline{X},\overline{Y})=0\]
 La varianza di $\overline{X}-\overline{Y}$ sarà dunque uguale a
\begin{eqnarray*}
V(\overline{X}-\overline{Y}) & = & V(\overline{X})+V(\overline{Y})-2cov(\overline{X},\overline{Y})\\
 & = & \frac{\sigma_{x}^{2}}{m}+\frac{\sigma_{y}^{2}}{n}.\end{eqnarray*}
 Le varianze delle due popolazioni saranno stimate utilizzando lo
stimatore usuale, ovvero\begin{eqnarray*}
\widehat{\sigma}_{x}^{2} & = & \frac{1}{m-1}\sum_{i=1}^{m}\left(x_{i}-\overline{x}\right)^{2}\\
\widehat{\sigma}_{y}^{2} & = & \frac{1}{n-1}\sum_{j=1}^{n}\left(y_{j}-\overline{y}\right)^{2}\end{eqnarray*}
 Sotto l'ipotesi nulla, la distribuzione della statistica \[
\tau=\frac{\overline{X}-\overline{Y}}{\sqrt{\frac{\widehat{\sigma}_{x}^{2}}{m}+\frac{\widehat{\sigma}_{y}^{2}}{n}}}\]
 non è conosciuta. Tuttavia vale il seguente risultato:\[
\tau\text{ circa}\sim t_{k}\]
 dove $k=\min(m-1,n-1)$.

\begin{remark} In caso di eteroschedasticità la distribuzione della
statistica $\tau$ non è conosciuta ma è approssimabile tramite una
distribuzione $t$ a $k=\min(m-1,n-1)$ gradi di libertà (problema
di Behrens-Fisher). \end{remark}


\subsection{Test per la dispersione su singolo campione}

È questo un test utilizzato per verificare un'ipotesi sulla varianza
della popolazione. Supponiamo che il campione composto dalle $n$
osservazioni indipendenti ed identicamente distribuite $X_{1},...,X_{n}$
sia stato estratto dalla popolazione $X\sim N(\mu,\sigma^{2})$ con
$\mu$ e $\sigma^{2}$ entrambi sconosciuti. Supponiamo inoltre di
voler testare l'ipotesi nulla \[
H_{0}:\sigma=\sigma_{0}\]
 contro l'ipotesi alternativa\[
H_{A}:\sigma>\sigma_{0}.\]
 In questo caso $\sigma$ è il parametro d'interesse mentre $\mu$
è il parametro di disturbo (nel $t$-test visto in precedenza era
$\sigma$ ad essere il parametro di disturbo e $\mu$ quello d'interesse).
Prendiamo quale statistica del test\[
S(X_{1},...,X_{n})=\frac{\widehat{\sigma}^{2}}{\sigma_{0}^{2}},\]
 con $\sigma^{2}$ stimata col \textquotedblright{}solito\textquotedblright{}\
stimatore \[
\widehat{\sigma}^{2}=\frac{1}{n-1}\sum_{i=1}^{n}\left(X_{i}-\overline{X}\right)^{2}.\]
 Quindi un rapporto $\frac{\widehat{\sigma}^{2}}{\sigma_{0}^{2}}>1$
sarà evidenza negativa contro l'ipotesi nulla (tanto più estremo sarà
questo rapporto e tanto maggiore sarà l'evidenza contro $H_{0}$)
mentre se $\frac{\widehat{\sigma}^{2}}{\sigma_{0}^{2}}\approx1$ non
si rifiuterà l'ipotesi nulla. Si può dimostrare che sotto l'ipotesi
nulla \[
(n-1)S(X_{1},...,X_{n})=\left(n-1\right)\frac{\widehat{\sigma}^{2}}{\sigma_{0}^{2}}=\sum_{i=1}^{n}\left(\frac{X_{i}-\overline{X}}{\sigma_{0}}\right)^{2}\underset{H_{0}}{\sim}\chi_{n-1}^{2}\]


Costruzione della regione critica (zona di rifiuto di $H_{0}$) ad
un livello di significatività $\alpha$:\[
R=\left\{ \left(x_{1},...,x_{n}\right)\ |\ (n-1)S>k_{1-\alpha}\right\} \]
 con \[
P_{H_{0}}\left(\underset{\chi_{n-1}^{2}}{\underbrace{(n-1)S\ }}>\ k_{1-\alpha}\right)=\alpha\text{ cioè }k_{1-\alpha}=\chi_{n-1,1-\alpha}^{2}\]
 Quindi se $\left(n-1\right)\frac{\widehat{\sigma}^{2}}{\sigma_{0}^{2}}>k_{1-\alpha}$
rifiuto $H_{0}$ altrimenti non rifiuto.


\subsection{Test per la dispersione su due campioni (F-Test)}

Assumiamo le seguenti ipotesi sulle due popolazioni e sui rispettivi
campioni: 
\begin{enumerate}
\item Le osservazioni $X_{1},...,X_{m}$ formano un campione di osservazioni
$i.i.d.$ (indipendenti ed identicamente distribuite) estratte dalla
popolazione $X\sim N(\mu_{x},\sigma_{x}^{2})$ 
\item Le osservazioni $Y_{1},...,Y_{n}$ formano un campione di osservazioni
$i.i.d.$ (indipendenti ed identicamente distribuite) estratte dalla
popolazione $Y\sim N(\mu_{y},\sigma_{y}^{2})$ 
\item Per ogni $X_{i}$ in $X_{1},...,X_{m}$ e $Y_{j}$ in $Y_{1},...,Y_{n}$
vale che $X_{i}$ e $Y_{j}$ sono fra loro indipendenti. 
\item $\mu_{x},\sigma_{x}^{2}$ e $\mu_{y},\sigma_{y}^{2}$ sono sconosciuti. 
\end{enumerate}
\noindent Desideriamo testare l'ipotesi nulla:\[
H_{0}:\sigma_{x}=\sigma_{y}\]
 contro l'ipotesi alternativa \[
H_{A}:\sigma_{x}>\sigma_{y}.\]
 Stimiamo le varianze $\sigma_{x}^{2}$ e $\sigma_{y}^{2}$ delle
due popolazioni con lo stimatore abituale:\begin{eqnarray*}
\widehat{\sigma}_{x}^{2} & = & \frac{1}{m-1}\sum_{i=1}^{m}\left(X_{i}-\overline{X}\right)^{2}\\
\widehat{\sigma}_{y}^{2} & = & \frac{1}{n-1}\sum_{j=1}^{n}\left(Y_{j}-\overline{Y}\right)^{2}.\end{eqnarray*}
 Sotto l'ipotesi nulla la quantità \[
S(X_{1},...,X_{m};Y_{1},...,Y_{n})=\frac{\widehat{\sigma}_{x}^{2}}{\widehat{\sigma}_{y}^{2}}\underset{H_{0}}{\sim}F_{m-1,n-1}.\]


\begin{definizione} Distribuzione $F_{l,k}$. Chiamiamo Distribuzione
$F$ con $l$ gradi di libertà a numeratore e $k$ gradi di libertà
a denominatore il rapporto fra due variabili aleatorie $U$ e $V$
standardizzate e tali che 
\begin{itemize}
\item $U\sim\chi_{l}^{2}$ 
\item $V\sim\chi_{k}^{2}$ 
\item $U$ e $V$ fra loro indipendenti 
\end{itemize}
\[
h=\frac{\frac{U}{l}}{\frac{V}{k}}\sim F_{l,k}\text{ {\small(rapporto di due }}\chi^{2}\text{{\small\ standardizzate).}}\]
 \end{definizione}

Costruzione della regione critica (zona di rifiuto di $H_{0}$) ad
un livello di significatività $\alpha$:\[
R=\left\{ \left(x_{1},...,x_{n},y_{1},...,y_{n}\right)\ |\ \frac{\widehat{\sigma}_{x}^{2}}{\widehat{\sigma}_{y}^{2}}>k_{1-\alpha}\right\} \]
 con \[
P_{H_{0}}\left(\underset{F_{m-1,n-1}}{\underbrace{\frac{\widehat{\sigma}_{x}^{2}}{\widehat{\sigma}_{y}^{2}}\ }}>\ k_{1-\alpha}\right)=\alpha\text{ cioè }k_{\alpha}=F_{m-1,n-1;1-\alpha}.\]



\subsection{Test di conformità}

Il test di conformità (\textquotedblright{}goodness-of-fit\textquotedblright{}\ test)
non è un test su un'ipotesi parametrica. Ciò che si desidera verificare
è se la distribuzione dei dati è uguale ad una distribuzione data
(ad esempio normale, di Pareto, esponenziale, ecc.) che indicheremo
con $F$.

\begin{esempio} Distribuzione dei redditi. Vogliamo vedere se la
distribuzione dei dati $X_{1},...,X_{n}$ è compatibile con l'ipotesi
che la popolazione $X\sim F$, dove in questo caso $F$ è la distribuzione
di Pareto la cui funzione di densità sappiamo essere uguale a\[
f(x)=k\frac{x_{0}^{k}}{x^{k+1}}\ \ \ \text{per }x\geq x_{0},\]
 e $x_{0}$ e $k$ sono due parametri supposti conosciuti. La funzione
di ripartizione di $X$ è data da\[
F(x)=1-\left(\frac{x}{x_{0}}\right)^{-k}.\]
 Al fine di costruire il test dovremo, partendo dalle osservazioni,
costruire delle classi di reddito, che noteremo con $c_{1},c_{2},...,c_{K}$.
\end{esempio}

\bigskip{}


$\hspace{1em}*{-2.2cm}\begin{tabular}{|c|c|c|c|c|c|}
\hline  {\small Classe}  &  \ensuremath{\begin{array}{c}
\text{{\small Intervallo}}\\
\text{{\small Mia Fr.}}\end{array}} &  {\small\# osservazioni}  &  \ensuremath{\begin{array}{c}
\text{{\small\# osservazioni}}\\
\text{{\small atteso sotto Ho}}\end{array}} &  {\small Deviazioni}  &  \ensuremath{\frac{\left({\small O}_{i}-{\small E}_{i}\right)^{2}}{{\small E}_{i}}}\\
\hline\hline \ensuremath{c_{1}} &  \ensuremath{\left[{\small0,30}\right)} &  \ensuremath{O_{1}} &  \ensuremath{n\ p_{1}=E_{1}} &  \ensuremath{O_{1}-E_{1}} &  \ensuremath{\frac{\left({\small O}_{1}-{\small E}_{1}\right)^{2}}{{\small E}_{1}}}\\
\ensuremath{c_{2}} &  \ensuremath{\left[{\small30,50}\right)} &  \ensuremath{O_{2}} &  \ensuremath{n\ p_{2}=E_{2}} &  \ensuremath{O_{2}-E_{2}} &  \ensuremath{\frac{\left({\small O}_{2}-{\small E}_{2}\right)^{2}}{{\small E}_{2}}}\\
\ensuremath{\vdots} &  \ensuremath{\vdots} &  \ensuremath{\vdots} &  \ensuremath{\vdots} &  \ensuremath{\vdots} &  \ensuremath{\vdots}\\
\ensuremath{c_{k}} &  \ensuremath{\left[{\small100,120}\right)} &  \ensuremath{O_{k}} &  \ensuremath{n\ p_{k}=E_{k}} &  \ensuremath{O_{k}-E_{k}} &  \ensuremath{\frac{\left({\small O}_{k}-{\small E}_{k}\right)^{2}}{{\small E}_{k}}}\\
\ensuremath{\vdots} &  \ensuremath{\vdots} &  \ensuremath{\vdots} &  \ensuremath{\vdots} &  \ensuremath{\vdots} &  \ensuremath{\vdots}\\
\ensuremath{c_{K}} &  \ensuremath{\left[{\small200,+}\right)} &  \ensuremath{O_{K}} &  \ensuremath{n\ p_{K}=E_{K}} &  \ensuremath{O_{K}-E_{K}} &  \ensuremath{\frac{\left({\small O}_{K}-{\small E}_{K}\right)^{2}}{{\small E}_{K}}}\\
\hline {\small Totale}  &   &  \ensuremath{n=\sum_{k=1}^{K}O_{k}} &  \ensuremath{n} &  \ensuremath{0} &  \ensuremath{\chi^{2}=\sum_{k=1}^{K}\frac{\left({\small O}_{k}-{\small E}_{k}\right)^{2}}{{\small E}_{k}}}\\\hline \end{tabular}$

\bigskip{}


\noindent Le probabilità $p_{k}$ sono le probabilità teoriche di
osservare una realizzazione nell'intervallo corrispondente, ovvero
\[
p_{k}=P_{H_{0}}(l_{k-1}\leq X<l_{k}).\]
 Su $n$ estrazioni indipendenti il numero atteso di osservazioni
nell'intervallo $\left[l_{k-1},l_{k}\right)$ sarà semplicemente $n\ p_{k}$.
Il test consiste nel confrontare le frequenze assolute empiriche con
quelle teoriche. Se le differenze sono \textquotedblright{}grandi\textquotedblright{},
avremo evidenza contro l'ipotesi nulla. Occorre pertanto sapere la
distribuzione della somma dei quadrati delle differenze \textquotedblright{}standardizzate\textquotedblright{},
$\sum_{k=1}^{K}\frac{\left({\small O}_{k}-{\small E}_{k}\right)^{2}}{{\small E}_{k}}$.
Sotto l'ipotesi nulla $H_{0}$ la quantità \[
\sum_{k=1}^{K}\frac{\left({\small O}_{k}-{\small E}_{k}\right)^{2}}{{\small E}_{k}}=\chi_{K-1.}^{2}\]


\begin{remark} Affinché la statistica così costruita sia valida occorre
selezionare le classi in maniera tale che le frequenze teoriche $E_{i}$
siano maggiori o uguali a $5$. Per tale motivo è talvolta necessario
ridurre il numero di classi aumentando l'ampiezza degli intervalli.
\end{remark}

\begin{esempio} Osserviamo $n$ incidenti della circolazione. Ci
chiediamo se la distribuzione degli incidenti è uniforme rispetto
ai mesi dell'anno. Il numero di classi $K$ sarà quindi uguale a $12$.
Definiamo con $O_{k}:=$ \textquotedbl{}\# incidenti osservati nel
mese $k$\textquotedbl{}. La statistica \[
\chi^{2}=\sum_{k=1}^{12}\frac{\left({\small O}_{k}-\frac{{\small n}}{12}\right)^{2}}{\frac{{\small n}}{12}}\]
 è distribuita secondo una $\chi_{11}^{2}$.

Scelto il valore critico $k_{1-\alpha}=\chi_{11,1-\alpha}^{2}$ al
livello di significatività desiderato, rigetteremo l'ipotesi nulla
se \[
\sum_{k=1}^{12}\frac{\left({\small O}_{k}-\frac{{\small n}}{12}\right)^{2}}{\frac{{\small n}}{12}}>k_{1-\alpha}\]
 e non la rigetteremo altrimenti. \end{esempio}


\subsection{Test d'indipendenza}
\end{document}
